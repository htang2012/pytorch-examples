<!doctype html><html lang="en"><head><title data-rh="true">How Pytorch 2.0 Accelerates Deep Learning with Operator Fusion and CPU/GPU Code-Generation | by Shashank Prasanna | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2023-04-20T17:35:24.245Z"/><meta data-rh="true" name="title" content="How Pytorch 2.0 Accelerates Deep Learning with Operator Fusion and CPU/GPU Code-Generation | by Shashank Prasanna | Towards Data Science"/><meta data-rh="true" property="og:title" content="How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation"/><meta data-rh="true" property="al:android:url" content="medium://p/35132a85bd26"/><meta data-rh="true" property="al:ios:url" content="medium://p/35132a85bd26"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Computer programming is magical. We write code in human readable languages, and as though by magic, it gets translated into electric currents through silicon transistors making them behave like…"/><meta data-rh="true" property="og:description" content="A primer on deep learning compiler technologies in PyTorch for graph capture, intermediate representations, operator fusion, and more"/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/how-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/how-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1003/1*m3hHjaqAY_Rqwcvgfg4IoQ.png"/><meta data-rh="true" property="article:author" content="https://medium.com/@shashankprasanna"/><meta data-rh="true" name="author" content="Shashank Prasanna"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/35132a85bd26"/><meta data-rh="true" property="twitter:description" content="A primer on deep learning compiler technologies in PyTorch for graph capture, intermediate representations, operator fusion, and more"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1003/1*m3hHjaqAY_Rqwcvgfg4IoQ.png"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="17 min read"/><meta data-rh="true" name="twitter:tile:template:testing" content="2"/><meta data-rh="true" name="twitter:tile:image" content="https://miro.medium.com/v2/resize:fit:1003/1*m3hHjaqAY_Rqwcvgfg4IoQ.png"/><meta data-rh="true" name="twitter:tile:info1:icon" content="Person"/><meta data-rh="true" name="twitter:tile:info1:text" content="Shashank Prasanna"/><meta data-rh="true" name="twitter:tile:info2:icon" content="Calendar"/><meta data-rh="true" name="twitter:tile:info2:text" content="Apr 20, 2023"/><meta data-rh="true" name="twitter:cta" content="Read on Medium"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*VzTUkfeGymHP4Bvav-T-lA.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@shashankprasanna"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/how-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/35132a85bd26"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*m3hHjaqAY_Rqwcvgfg4IoQ.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26","dateCreated":"2023-04-20T17:35:24.245Z","datePublished":"2023-04-20T17:35:24.245Z","dateModified":"2023-04-22T07:26:20.877Z","headline":"How Pytorch 2.0 Accelerates Deep Learning with Operator Fusion and CPU\u002FGPU Code-Generation","name":"How Pytorch 2.0 Accelerates Deep Learning with Operator Fusion and CPU\u002FGPU Code-Generation","description":"Computer programming is magical. We write code in human readable languages, and as though by magic, it gets translated into electric currents through silicon transistors making them behave like…","identifier":"35132a85bd26","author":{"@type":"Person","name":"Shashank Prasanna","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@shashankprasanna"},"creator":["Shashank Prasanna"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:330\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26"}</script><style type="text/css" data-fela-rehydration="767" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="767" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px rgba(242, 242, 242, 1)}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:rgba(117, 117, 117, 1)}.ar:disabled{fill:rgba(117, 117, 117, 1)}.au{height:25px}.av{fill:rgba(41, 41, 41, 1)}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:rgba(250, 250, 250, 1)}.bb path{fill:rgba(117, 117, 117, 1)}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:rgba(41, 41, 41, 1)}.bk::placeholder{color:rgba(117, 117, 117, 1)}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:rgba(250, 250, 250, 1)}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:rgba(242, 242, 242, 1)}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:rgba(117, 117, 117, 1)}.du{font-size:13px}.dv{height:100%}.el{color:#FFFFFF}.em{fill:#FFFFFF}.eo{background:rgba(102, 138, 170, 1)}.ep{border-color:rgba(102, 138, 170, 1)}.et:disabled{cursor:inherit !important}.eu:disabled{opacity:0.3}.ev:disabled:hover{background:rgba(102, 138, 170, 1)}.ew:disabled:hover{border-color:rgba(102, 138, 170, 1)}.ex{border-radius:99em}.ey{border-width:1px}.ez{border-style:solid}.fa{box-sizing:border-box}.fb{text-decoration:none}.fe{margin-right:32px}.ff{position:relative}.fg{fill:rgba(117, 117, 117, 1)}.fj{background:transparent}.fk svg{margin-left:4px}.fl svg{fill:rgba(117, 117, 117, 1)}.fn{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fo{position:absolute}.fv{margin:0 24px}.fz{background:rgba(255, 255, 255, 1)}.ga{border:1px solid rgba(230, 230, 230, 1)}.gb{box-shadow:0 1px 4px rgba(230, 230, 230, 1)}.gc{max-height:100vh}.gd{overflow-y:auto}.ge{left:0}.gf{top:calc(100vh + 100px)}.gg{bottom:calc(100vh + 100px)}.gh{width:10px}.gi{pointer-events:none}.gj{word-break:break-word}.gk{word-wrap:break-word}.gl:after{display:block}.gm:after{content:""}.gn:after{clear:both}.go{line-height:1.23}.gp{letter-spacing:0}.gq{font-style:normal}.gr{font-weight:700}.hm{margin-bottom:-0.27em}.hn{line-height:1.394}.id{@media all and (max-width: 551.98px):8px}.ie{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.if{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.ig{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.ih{@media all and (min-width: 1080px):16px}.in{align-items:baseline}.io{width:48px}.ip{height:48px}.iq{border:2px solid rgba(255, 255, 255, 1)}.ir{z-index:0}.is{box-shadow:none}.it{border:1px solid rgba(0, 0, 0, 0.05)}.iv{margin-left:-12px}.iw{width:28px}.ix{height:28px}.iy{z-index:1}.iz{width:24px}.ja{margin-bottom:2px}.jb{flex-wrap:nowrap}.jc{font-size:16px}.jd{line-height:24px}.jf{margin:0 8px}.jg{display:inline}.jh{color:#1A8917}.ji{fill:rgba(102, 138, 170, 1)}.jl{flex:0 0 auto}.jo{flex-wrap:wrap}.jr{white-space:pre-wrap}.js{margin-right:4px}.jt{overflow:hidden}.ju{max-height:20px}.jv{text-overflow:ellipsis}.jw{display:-webkit-box}.jx{-webkit-line-clamp:1}.jy{-webkit-box-orient:vertical}.jz{word-break:break-all}.kb{padding-left:8px}.kc{padding-right:8px}.ld> *{flex-shrink:0}.le{overflow-x:scroll}.lf::-webkit-scrollbar{display:none}.lg{scrollbar-width:none}.lh{-ms-overflow-style:none}.li{width:74px}.lj{flex-direction:row}.lm{-webkit-user-select:none}.ln{border:0}.lq{outline:0}.lr{user-select:none}.ls> svg{pointer-events:none}.mb{cursor:progress}.mc{margin-top:0px}.md{opacity:1}.me{padding:4px 0}.mg{margin-left:4px}.mh{width:16px}.mi path{fill:rgba(41, 41, 41, 1)}.mj{padding:8px 2px}.mm svg path{fill:rgba(117, 117, 117, 1)}.mn svg{color:rgba(117, 117, 117, 1)}.ne{margin-left:auto}.nf{margin-right:auto}.ng{max-width:1003px}.nm{clear:both}.no{cursor:zoom-in}.np{z-index:auto}.nr{max-width:100%}.ns{height:auto}.nt{margin-top:10px}.nu{text-align:center}.nv{max-width:728px}.ny{line-height:1.58}.nz{letter-spacing:-0.004em}.oa{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.ot{margin-bottom:-0.46em}.ou{line-height:1.12}.ov{letter-spacing:-0.022em}.ow{font-weight:600}.pp{margin-bottom:-0.28em}.pv{max-width:945px}.qb{box-shadow:inset 0 0 0 1px rgba(230, 230, 230, 1)}.qc{padding:0px}.qd{padding:16px 20px}.qe{flex:1 1 auto}.qg{max-height:40px}.qh{-webkit-line-clamp:2}.qi{margin-top:8px}.qj{margin-top:12px}.qk{width:160px}.ql{background-image:url(https://miro.medium.com/v2/resize:fit:320/1*SAgQSIEprO1looCxAdf52w.png)}.qm{background-origin:border-box}.qn{background-size:cover}.qo{height:167px}.qp{background-position:50% 50%}.qq{text-decoration:underline}.qu{list-style-type:decimal}.qv{margin-left:30px}.qw{padding-left:0px}.rc{max-width:1036px}.rd{padding:2px 4px}.re{font-size:75%}.rf> strong{font-family:inherit}.rg{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.rh{max-width:454px}.ri{overflow-x:auto}.rj{padding:32px}.rk{border:1px solid #E5E5E5}.rl{background:#F9F9F9}.rm{color:#242424}.rn{line-height:1.4}.ro{margin-top:-0.2em}.rp{margin-bottom:-0.2em}.rq{white-space:pre}.rr{min-width:fit-content}.rs{max-width:1373px}.rt{max-width:1600px}.ru{margin:auto}.rv{padding-bottom:100%}.rw{height:0}.rx{max-width:1330px}.ry{line-height:1.18}.sm{margin-bottom:-0.31em}.sn{max-width:340px}.so{max-width:1214px}.sp{max-width:376px}.sq{max-width:380px}.sr{max-width:1034px}.ss{max-width:1371px}.st{max-width:1223px}.su{max-width:751px}.sv{max-width:898px}.sw{max-width:1198px}.sx{max-width:399px}.sy{max-width:1556px}.sz{max-width:879px}.ta{max-width:912px}.tb{max-width:1203px}.tc{list-style-type:disc}.td{max-width:1245px}.te{margin-bottom:26px}.tf{margin-top:6px}.tg{margin-right:8px}.th{padding:8px 16px}.ti{border-radius:100px}.tj{border:1px solid rgba(242, 242, 242, 1)}.tk{transition:background 300ms ease}.tm{white-space:nowrap}.tn{border-top:none}.tt{height:52px}.tu{max-height:52px}.tv{box-sizing:content-box}.tw{position:static}.ty{max-width:155px}.ue{margin-right:20px}.uk{align-items:flex-end}.ul{width:76px}.um{height:76px}.un{border:2px solid rgba(250, 250, 250, 1)}.uo{height:72px}.up{width:72px}.uq{margin-left:-16px}.ur{width:36px}.us{height:36px}.ut{width:auto}.uu{stroke:rgba(242, 242, 242, 1)}.uv{color:rgba(242, 242, 242, 1)}.uw{fill:rgba(242, 242, 242, 1)}.ux{background:rgba(242, 242, 242, 1)}.uy{border-color:rgba(242, 242, 242, 1)}.ve{font-weight:500}.vf{font-size:24px}.vg{line-height:30px}.vh{letter-spacing:-0.016em}.vi{margin-top:16px}.vj{height:0px}.vk{border-bottom:solid 1px #E5E5E5}.vq{margin-top:72px}.vr{padding:24px 0}.vs{margin-bottom:0px}.vt{margin-right:16px}.vu{display:inline-flex}.wa{margin-bottom:32px}.wb{margin-top:40px}.wc{align-items:stretch}.xm{flex-grow:0}.xs{display:grid}.xt{grid-template-columns:repeat(12, 1fr)}.xu{grid-template-rows:auto 1fr}.yf{grid-area:image}.yg{grid-area:content}.ym{border-radius:2px}.yn{aspect-ratio:2}.yo{object-fit:cover}.yp{object-position:49% 48%}.yq{background-color:#F9F9F9}.yw{height:20px}.yx{width:20px}.yy{padding-right:4px}.zt{padding-top:8px}.abj{margin-left:20px}.abk{justify-content:flex-end}.abl{flex:0 0 0}.abm{margin-top:32px}.abn{object-position:50% 50%}.abu{background:0}.abv{border-color:rgba(117, 117, 117, 1)}.aby:disabled:hover{color:rgba(41, 41, 41, 1)}.abz:disabled:hover{fill:rgba(41, 41, 41, 1)}.aca:disabled:hover{border-color:rgba(117, 117, 117, 1)}.acu{padding-bottom:40px}.acv{padding-top:88px}.acw{margin-bottom:40px}.acx{margin-top:4px}.acy{border-right:3px solid rgba(250, 250, 250, 1)}.acz{z-index:3}.ada{z-index:2}.adb{margin-left:-24px}.adc{margin-left:-36px}.add{border-radius:0 3px 3px 0}.ade{width:93px}.adl{margin-left:2px}.adm{margin-top:2px}.adn{cursor:initial}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.eq:hover{background:rgba(90, 118, 144, 1)}.er:hover{border-color:rgba(90, 118, 144, 1)}.es:hover{cursor:pointer}.fh:hover{color:rgba(41, 41, 41, 1)}.fi:hover{fill:rgba(41, 41, 41, 1)}.fm:hover svg{fill:rgba(41, 41, 41, 1)}.fp:hover{background-color:none}.iu:hover{background-color:rgba(0, 0, 0, 0.1)}.je:hover{text-decoration:underline}.jj:hover:not(:disabled){color:#156D12}.jk:hover:not(:disabled){fill:rgba(90, 118, 144, 1)}.lp:hover{fill:rgba(8, 8, 8, 1)}.mf:hover p{color:rgba(8, 8, 8, 1)}.mk:hover:not(:disabled) svg path{fill:rgba(8, 8, 8, 1)}.mo:hover svg{color:rgba(8, 8, 8, 1)}.tl:hover{background-color:rgba(230, 230, 230, 1)}.uz:hover{background:rgba(242, 242, 242, 1)}.va:hover{border-color:rgba(242, 242, 242, 1)}.vb:hover{cursor:wait}.vc:hover{color:rgba(242, 242, 242, 1)}.vd:hover{fill:rgba(242, 242, 242, 1)}.abw:hover{color:rgba(8, 8, 8, 1)}.abx:hover{border-color:rgba(41, 41, 41, 1)}.bc:focus-within path{fill:rgba(41, 41, 41, 1)}.lo:focus{fill:rgba(8, 8, 8, 1)}.ml:focus svg path{fill:rgba(8, 8, 8, 1)}.mp:focus svg{color:rgba(8, 8, 8, 1)}.nq:focus{transform:scale(1.01)}.lt:active{border-style:none}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.ek{padding:5px 12px}.fd{display:flex}.fu{margin-bottom:68px}.fy{max-width:680px}.hi{font-size:42px}.hj{margin-top:1.19em}.hk{line-height:52px}.hl{letter-spacing:-0.011em}.ia{font-size:22px}.ib{margin-top:0.92em}.ic{line-height:28px}.im{align-items:center}.kp{border-top:solid 1px rgba(242, 242, 242, 1)}.kq{border-bottom:solid 1px rgba(242, 242, 242, 1)}.kr{margin:32px 0 0}.ks{padding:3px 8px}.lb> *{margin-right:24px}.lc> :last-child{margin-right:0}.ma{margin-top:0px}.nl{margin-top:56px}.op{font-size:20px}.oq{margin-top:2em}.or{line-height:32px}.os{letter-spacing:-0.003em}.pl{font-size:24px}.pm{margin-top:1.95em}.pn{line-height:30px}.po{letter-spacing:-0.016em}.pu{margin-top:0.86em}.qa{margin-top:32px}.qt{font-size:21px}.rb{margin-top:1.05em}.sj{margin-top:1.72em}.sk{line-height:24px}.sl{letter-spacing:0}.ts{margin-bottom:88px}.ud{display:inline-block}.uj{padding-top:72px}.vp{margin-top:40px}.vz{margin:0}.wp{width:calc(100% + 32px)}.wq{margin-left:-16px}.wr{margin-right:-16px}.xi{padding-left:16px}.xj{padding-right:16px}.xk{flex-basis:50%}.xl{max-width:50%}.xr{padding-bottom:56px}.yd{gap:24px 0}.ye{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.yl{display:block}.yv{margin-bottom:16px}.zh{padding-bottom:16px}.zi{flex:1 0 auto}.zr{max-height:48px}.zs{-webkit-line-clamp:2}.zy{padding-top:16px}.abh{max-width:56%}.abi{flex:1 0 0}.abq{margin-bottom:24px}.abt{flex-direction:row}.acf{width:min-width}.aco{margin-left:16px}.act{margin-top:96px}.adj{margin-top:24px}.adk{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.lz{margin-top:0px}.nw{margin-left:auto}.nx{text-align:center}.uc{display:inline-block}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.ly{margin-top:0px}.ub{display:inline-block}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.lw{margin-top:0px}.lx{margin-right:0px}.qf{padding:10px 12px 10px}.ua{display:inline-block}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.fq{margin-bottom:4px}.gs{font-size:32px}.gt{margin-top:1.01em}.gu{line-height:38px}.gv{letter-spacing:-0.014em}.ho{font-size:18px}.hp{margin-top:0.79em}.hq{line-height:24px}.ii{align-items:flex-start}.jm{flex-direction:column}.jp{margin-bottom:2px}.kd{margin:24px -24px 0}.ke{padding:0}.kt> *{margin-right:8px}.ku> :last-child{margin-right:24px}.lk{margin-left:0px}.lu{margin-top:0px}.lv{margin-right:0px}.mq{border:1px solid rgba(230, 230, 230, 1)}.mr{border-radius:99em}.ms{padding:0px 16px 0px 12px}.mt{height:38px}.mu{align-items:center}.mw svg{margin-right:8px}.nh{margin-top:40px}.ob{margin-top:1.56em}.oc{line-height:28px}.od{letter-spacing:-0.003em}.ox{font-size:20px}.oy{margin-top:1.2em}.oz{letter-spacing:0}.pq{margin-top:0.67em}.pw{margin-top:24px}.qx{margin-top:1.34em}.rz{font-size:16px}.sa{margin-top:1.23em}.to{margin-bottom:80px}.tz{display:inline-block}.uf{padding-top:48px}.vl{margin-top:32px}.vv{margin:0}.wd{width:calc(100% + 24px)}.we{margin-left:-12px}.wf{margin-right:-12px}.ws{padding-left:12px}.wt{padding-right:12px}.wu{flex-basis:100%}.wv{max-width:100%}.xn{padding-bottom:32px}.xv{gap:24px 0}.xw{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.yh{display:block}.yr{margin-bottom:16px}.yz{padding-bottom:16px}.za{flex:1 0 auto}.zj{max-height:48px}.zk{-webkit-line-clamp:2}.zu{padding-top:16px}.zz{max-width:56%}.aba{flex:1 0 0}.acb{width:100%}.acg{margin-left:0}.ach{margin-top:16px}.acp{margin-top:72px}.mv:hover{border-color:rgba(204, 204, 204, 1)}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{padding:5px 12px}.fc{display:flex}.ft{margin-bottom:68px}.fx{max-width:680px}.he{font-size:42px}.hf{margin-top:1.19em}.hg{line-height:52px}.hh{letter-spacing:-0.011em}.hx{font-size:22px}.hy{margin-top:0.92em}.hz{line-height:28px}.il{align-items:center}.kl{border-top:solid 1px rgba(242, 242, 242, 1)}.km{border-bottom:solid 1px rgba(242, 242, 242, 1)}.kn{margin:32px 0 0}.ko{padding:3px 8px}.kz> *{margin-right:24px}.la> :last-child{margin-right:0}.nk{margin-top:56px}.ol{font-size:20px}.om{margin-top:2em}.on{line-height:32px}.oo{letter-spacing:-0.003em}.ph{font-size:24px}.pi{margin-top:1.95em}.pj{line-height:30px}.pk{letter-spacing:-0.016em}.pt{margin-top:0.86em}.pz{margin-top:32px}.qs{font-size:21px}.ra{margin-top:1.05em}.sg{margin-top:1.72em}.sh{line-height:24px}.si{letter-spacing:0}.tr{margin-bottom:88px}.ui{padding-top:72px}.vo{margin-top:40px}.vy{margin:0}.wm{width:calc(100% + 32px)}.wn{margin-left:-16px}.wo{margin-right:-16px}.xe{padding-left:16px}.xf{padding-right:16px}.xg{flex-basis:50%}.xh{max-width:50%}.xq{padding-bottom:56px}.yb{gap:24px 0}.yc{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.yk{display:block}.yu{margin-bottom:16px}.zf{padding-bottom:16px}.zg{flex:1 0 auto}.zp{max-height:48px}.zq{-webkit-line-clamp:2}.zx{padding-top:16px}.abf{max-width:56%}.abg{flex:1 0 0}.abp{margin-bottom:24px}.abs{flex-direction:row}.ace{width:min-width}.acm{margin-left:16px}.acn{margin-top:0px}.acs{margin-top:96px}.adh{margin-top:24px}.adi{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:flex-end}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fs{margin-bottom:68px}.fw{max-width:680px}.ha{font-size:42px}.hb{margin-top:1.19em}.hc{line-height:52px}.hd{letter-spacing:-0.011em}.hu{font-size:22px}.hv{margin-top:0.92em}.hw{line-height:28px}.ik{align-items:center}.kh{border-top:solid 1px rgba(242, 242, 242, 1)}.ki{border-bottom:solid 1px rgba(242, 242, 242, 1)}.kj{margin:32px 0 0}.kk{padding:3px 8px}.kx> *{margin-right:24px}.ky> :last-child{margin-right:0}.nj{margin-top:56px}.oh{font-size:20px}.oi{margin-top:2em}.oj{line-height:32px}.ok{letter-spacing:-0.003em}.pd{font-size:24px}.pe{margin-top:1.95em}.pf{line-height:30px}.pg{letter-spacing:-0.016em}.ps{margin-top:0.86em}.py{margin-top:32px}.qr{font-size:21px}.qz{margin-top:1.05em}.sd{margin-top:1.72em}.se{line-height:24px}.sf{letter-spacing:0}.tq{margin-bottom:88px}.uh{padding-top:72px}.vn{margin-top:40px}.vx{margin:0}.wj{width:calc(100% + 28px)}.wk{margin-left:-14px}.wl{margin-right:-14px}.xa{padding-left:14px}.xb{padding-right:14px}.xc{flex-basis:50%}.xd{max-width:50%}.xp{padding-bottom:56px}.xz{gap:24px 0}.ya{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.yj{display:block}.yt{margin-bottom:16px}.zd{padding-bottom:16px}.ze{flex:1 0 auto}.zn{max-height:48px}.zo{-webkit-line-clamp:2}.zw{padding-top:16px}.abd{max-width:56%}.abe{flex:1 0 0}.abo{margin-bottom:24px}.abr{flex-direction:row}.acd{width:min-width}.ack{margin-left:16px}.acl{margin-top:0px}.acr{margin-top:96px}.adf{margin-top:24px}.adg{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fr{margin-bottom:4px}.gw{font-size:32px}.gx{margin-top:1.01em}.gy{line-height:38px}.gz{letter-spacing:-0.014em}.hr{font-size:18px}.hs{margin-top:0.79em}.ht{line-height:24px}.ij{align-items:flex-start}.jn{flex-direction:column}.jq{margin-bottom:2px}.kf{margin:24px 0 0}.kg{padding:0}.kv> *{margin-right:8px}.kw> :last-child{margin-right:8px}.ll{margin-left:0px}.mx{border:1px solid rgba(230, 230, 230, 1)}.my{border-radius:99em}.mz{padding:0px 16px 0px 12px}.na{height:38px}.nb{align-items:center}.nd svg{margin-right:8px}.ni{margin-top:40px}.oe{margin-top:1.56em}.of{line-height:28px}.og{letter-spacing:-0.003em}.pa{font-size:20px}.pb{margin-top:1.2em}.pc{letter-spacing:0}.pr{margin-top:0.67em}.px{margin-top:24px}.qy{margin-top:1.34em}.sb{font-size:16px}.sc{margin-top:1.23em}.tp{margin-bottom:80px}.ug{padding-top:48px}.vm{margin-top:32px}.vw{margin:0}.wg{width:calc(100% + 24px)}.wh{margin-left:-12px}.wi{margin-right:-12px}.ww{padding-left:12px}.wx{padding-right:12px}.wy{flex-basis:100%}.wz{max-width:100%}.xo{padding-bottom:32px}.xx{gap:24px 0}.xy{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.yi{display:block}.ys{margin-bottom:16px}.zb{padding-bottom:16px}.zc{flex:1 0 auto}.zl{max-height:48px}.zm{-webkit-line-clamp:2}.zv{padding-top:16px}.abb{max-width:56%}.abc{flex:1 0 0}.acc{width:100%}.aci{margin-left:0}.acj{margin-top:16px}.acq{margin-top:72px}.nc:hover{border-color:rgba(204, 204, 204, 1)}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="print">.tx{display:none}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.ka{max-height:none}</style><style type="text/css" data-fela-rehydration="767" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.nn{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="dt ag du be ak b am an ao ap aq ar as at s u j i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F35132a85bd26&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="ds"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="au av"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search Medium" value=""/></div></div></div><div class="h k w fc fd"><div class="fe ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------" rel="noopener follow"><div class="be b bf z dt ff fg ab q fh fi"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="ds l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fe ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dt ff fg ab q fh fi"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="fe h k j"><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ax fj am ab q ao fk fl fm" aria-label="user options menu"><div class="l ff"><img alt="" class="l fa bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fn bx l by bz fo n ax fp"></div></div><svg width="12px" height="12px" viewBox="0 0 15 15"><path d="M3.85 5.15a.5.5 0 0 0-.7.7l4.35 4.36 4.35-4.36a.5.5 0 1 0-.7-.7L7.5 8.79 3.85 5.15z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="l"><div class="fq fr fs ft fu l"><div class="ab ca"><div class="ch bg fv fw fx fy"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fo ge gf gg gh gi"></div><div class="gj gk gl gm gn"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class=""><h1 id="8b2a" class="pw-post-title go gp gq be gr gs gt gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm bj">How Pytorch 2.0 Accelerates Deep Learning with Operator Fusion and CPU/GPU Code-Generation</h1></div><div class=""><h2 id="d316" class="pw-subtitle-paragraph hn gp gq be b ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic cp dt">A primer on deep learning compiler technologies in PyTorch for graph capture, intermediate representations, operator fusion, and optimized C++ and GPU code generation</h2><div class="id ie if ig ih"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="ii ij ik il im ab"><div><div class="ab in"><a href="https://medium.com/@shashankprasanna?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="l io ip bx iq ir"><div class="l ff"><img alt="Shashank Prasanna" class="l fa bx dc dd cw" src="https://miro.medium.com/v2/resize:fill:88:88/2*LXFHFkYQQR1tyNWoHIcSXQ.jpeg" width="44" height="44" loading="lazy"/><div class="is bx l dc dd fo n it iu"></div></div></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><div class="iv ab ff"><div><div class="bl" aria-hidden="false"><div class="l iw ix bx iq iy"><div class="l ff"><img alt="Towards Data Science" class="l fa bx bq iz cw" src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="24" height="24" loading="lazy"/><div class="is bx l bq iz fo n it iu"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="ja ab q"><div class="ab q jb"><div class="ab q"><div><div class="bl" aria-hidden="false"><p class="be b jc jd bj"><a class="af ag ah ai aj ak al am an ao ap aq ar je" href="https://medium.com/@shashankprasanna?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow">Shashank Prasanna</a></p></div></div></div><span class="jf jg" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b jc jd dt"><span><a class="jh ji ah ai aj ak al am an ao ap aq ar eu jj jk" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0c596ca35b5&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=post_page-e0c596ca35b5----35132a85bd26---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l jl"><span class="be b bf z dt"><div class="ab cm jm jn jo"><div class="jp jq ab"><div class="be b bf z dt ab jr"><span class="js l jl">Published in</span><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b bf z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div><div class="h k"><span class="jf jg" aria-hidden="true"><span class="be b bf z dt">·</span></span></div></div><span class="be b bf z dt"><div class="ab ae">17 min read<div class="kb kc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div><span>Apr 20</span></div></span></div></span></div></div></div><div class="ab co kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks"><div class="h k w fc fd q"><div class="li l"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35132a85bd26&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=-----35132a85bd26---------------------clap_footer-----------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div></div><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class="mc"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">3</span></p></button></div></div></div><div class="ab q kt ku kv kw kx ky kz la lb lc ld le lf lg lh"><div class="mh k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35132a85bd26&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;source=-----35132a85bd26---------------------bookmark_footer-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af fg ah ai aj ak al mj an ao ap eu mk ml mm"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div></div><div class="fa vu cm"><div class="l ae"><div class="ab ca"><div class="vv vw vx vy vz nr ch bg"><div class="ab"><div class="bl bg" aria-hidden="false"><div><div class="bl" aria-hidden="false"><button class="af fg ah ai aj ak al mj an ao ap eu mn mo mf mp mq mr ms mt s mu mv mw mx my mz na u nb nc nd"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button class="af fg ah ai aj ak al mj an ao ap eu mn mo mf mp mq mr ms mt s mu mv mw mx my mz na u nb nc nd"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf ng"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*m3hHjaqAY_Rqwcvgfg4IoQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="402" loading="eager" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">illustration by author</figcaption></figure><p id="f273" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Computer programming is magical. We write code in human readable languages, and as though by magic, it gets translated into electric currents through silicon transistors making them behave like switches and allowing them to implement complex logic — just so we can enjoy cat videos on the internet. Between the programming language and hardware processors that run it, is an important piece of technology — the compiler. A compiler’s job is to translate and simplify our human readable language code into instructions that a processor understands.</p><p id="b65d" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Compilers play a very important role in deep learning to improve training and inference performance, improve energy efficiency, and target diverse AI accelerator hardware. In this blog post I’m going to discuss deep learning compiler technologies that powers PyTorch 2.0. I’ll walk you through the different phases of the compilation process and discuss various underlying technologies with code examples and visualizations.</p><h1 id="f83b" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">What is a deep learning compiler?</h1><p id="77b2" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">A deep learning compiler translates high-level code written in deep learning frameworks into optimized lower level hardware specific code to accelerate training and inference. It finds opportunities in deep learning models to optimize for performance by performing layer and operator fusion, better memory planning, and generating target specific optimized fused kernels to reduce function call overhead.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf pv"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*a1hW4NU7glf5AATR 640w, https://miro.medium.com/v2/resize:fit:720/0*a1hW4NU7glf5AATR 720w, https://miro.medium.com/v2/resize:fit:750/0*a1hW4NU7glf5AATR 750w, https://miro.medium.com/v2/resize:fit:786/0*a1hW4NU7glf5AATR 786w, https://miro.medium.com/v2/resize:fit:828/0*a1hW4NU7glf5AATR 828w, https://miro.medium.com/v2/resize:fit:1100/0*a1hW4NU7glf5AATR 1100w, https://miro.medium.com/v2/resize:fit:1400/0*a1hW4NU7glf5AATR 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*a1hW4NU7glf5AATR 640w, https://miro.medium.com/v2/resize:fit:720/0*a1hW4NU7glf5AATR 720w, https://miro.medium.com/v2/resize:fit:750/0*a1hW4NU7glf5AATR 750w, https://miro.medium.com/v2/resize:fit:786/0*a1hW4NU7glf5AATR 786w, https://miro.medium.com/v2/resize:fit:828/0*a1hW4NU7glf5AATR 828w, https://miro.medium.com/v2/resize:fit:1100/0*a1hW4NU7glf5AATR 1100w, https://miro.medium.com/v2/resize:fit:1400/0*a1hW4NU7glf5AATR 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="271" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">illustration by author</figcaption></figure><p id="86af" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Unlike traditional software compilers, deep learning compilers have to work with highly-parallelizable code often accelerated on specialized AI accelerator hardware (GPUs, TPUs, AWS Trainium/Inferentia, Intel Habana Gaudi etc.). To improve performance, a deep learning compil
r has to take advantage of hardware specific features such as mixed precision support, performance optimized kernels and minimize communication between host (CPU) and AI accelerator.</p><p id="6c4a" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">While deep learning algorithms are continuing to advance at a rapid pace, hardware AI accelerators have also been evolving alongside to keep up with deep learning algorithm performance and efficiency needs. I discuss the co-evolution of algorithms and AI accelerators in an earlier blog post:</p><div class="pw px py pz qa qb"><a rel="noopener follow" target="_blank" href="/ai-accelerators-machine-learning-algorithms-and-their-co-design-and-evolution-2676efd47179"><div class="qc ab jl"><div class="qd ab cn ca qe qf"><h2 class="be gr jc z jt qg jv jw qh jy ka gp bj">AI accelerators, machine learning algorithms and their co-design and evolution</h2><div class="qi l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">Efficient algorithms and methods in machine learning for AI accelerators — NVIDIA GPUs, Intel Habana Gaudi and AWS…</h3></div><div class="qj l"><p class="be b du z jt qg jv jw qh jy ka dt">towardsdatascience.com</p></div></div><div class="qk l"><div class="ql l qm qn qo qk qp nr qb"></div></div></div></a></div><p id="76a6" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">In this blog post I’ll focus on the software side of things, and particularly the subset of software closer to the hardware — deep learning compilers. First, let’s start by taking a look at different functions in a deep learning compiler.</p><h1 id="4a83" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">Deep learning compiler in PyTorch 2.0</h1><p id="fd49" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">PyTorch 2.0 includes new compiler technologies to improve model performance and runtime efficiency and target diverse hardware backends with a simple API: torch.compile(). While <a class="af qq" href="https://pytorch.org/get-started/pytorch-2.0/" rel="noopener ugc nofollow" target="_blank">other blog posts</a> and articles have<a class="af qq" href="https://pytorch.org/blog/pytorch-2.0-release/" rel="noopener ugc nofollow" target="_blank"> discussed</a> performance benefits of PyTorch 2.0 in detail, here I’m going to focus on what happens under the hood when you invoke the PyTorch 2.0 compiler. If you’re looking for quantified performance benefits, you can find a <a class="af qq" href="https://github.com/pytorch/pytorch/issues/93794" rel="noopener ugc nofollow" target="_blank">performance dashboard</a> of different models from huggingface, timm and torchbench.</p><p id="f7e7" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">At a high-level the default options for PyTorch 2.0 deep learning compiler performs the following key tasks:</p><ol class=""><li id="675b" class="ny nz gq oa b ho ob oc od hr oe of og qr oi oj ok qs om on oo qt oq or os ot qu qv qw bj"><strong class="oa gr">Graph capture</strong>: Computational graph representation for your models and functions. PyTorch technologies: TorchDynamo, Torch FX, FX IR</li><li id="9406" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj"><strong class="oa gr">Automatic differentiation</strong>: Backward graph tracing using automatic differentiation and lowering to primitives operators. PyTorch technologies: AOTAutograd, Aten IR</li><li id="a58b" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj"><strong class="oa gr">Optimizations</strong>: Forward and backward graph-level optimizations and operator fusion. PyTorch technologies: TorchInductor (default) or other compilers</li><li id="143e" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj"><strong class="oa gr">Code generation</strong>: Generating hardware specific C++/GPU Code. PyTorch technologies: TorchInductor, OpenAI Triton (default) other compilers</li></ol><p id="fba1" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Through these steps, the compiler transforms your code and generates intermediate representations (IRs) that are progressively “lowered”. Lowering is a term in the compiler lexicon that refers to mapping a broad set of operations (such as supported by PyTorch API) to a narrow set of operations (such as supported by hardware) through automatic transformation and re-writing by the compiler. The PyTorch 2.0 compiler flow:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rc"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*RHLzCi133K-GjD1U 640w, https://miro.medium.com/v2/resize:fit:720/0*RHLzCi133K-GjD1U 720w, https://miro.medium.com/v2/resize:fit:750/0*RHLzCi133K-GjD1U 750w, https://miro.medium.com/v2/resize:fit:786/0*RHLzCi133K-GjD1U 786w, https://miro.medium.com/v2/resize:fit:828/0*RHLzCi133K-GjD1U 828w, https://miro.medium.com/v2/resize:fit:1100/0*RHLzCi133K-GjD1U 1100w, https://miro.medium.com/v2/resize:fit:1400/0*RHLzCi133K-GjD1U 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*RHLzCi133K-GjD1U 640w, https://miro.medium.com/v2/resize:fit:720/0*RHLzCi133K-GjD1U 720w, https://miro.medium.com/v2/resize:fit:750/0*RHLzCi133K-GjD1U 750w, https://miro.medium.com/v2/resize:fit:786/0*RHLzCi133K-GjD1U 786w, https://miro.medium.com/v2/resize:fit:828/0*RHLzCi133K-GjD1U 828w, https://miro.medium.com/v2/resize:fit:1100/0*RHLzCi133K-GjD1U 1100w, https://miro.medium.com/v2/resize:fit:1400/0*RHLzCi133K-GjD1U 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="398" loading="lazy" role="presentation"/></picture></div></div></figure><p id="a69b" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">If you are new to compiler terminology don’t let all of this scare you yet. I’m not a compiler engineer either. Keep reading and things will become clear as I’ll break the process down using a simple example and visualizations.</p><h1 id="8938" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">A walk through the <code class="cw rd re rf rg b">torch.compile()</code> compiler process</h1><p id="7ffb" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">Note: This whole walkthrough is in a <a class="af qq" href="https://github.com/shashankprasanna/pytorch-examples/blob/main/pytorch-compile-blogpost/torch-compile-under-the-hood.ipynb" rel="noopener ugc nofollow" target="_blank">Jupyter Notebook hosted here</a></p><p id="3b6e" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">For the sake of simplicity, I’ll define a very simple function and run it through the PyTorch 2.0 compiler process. You can replace this function with a deep neural network model or an nn.Module subclass, but this example should help you appreciate what’s going on under the hood much better than a complex multi-million parameter model.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div class="ne nf rh"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*liAw71ABihW7bz7M 640w, https://miro.medium.com/v2/resize:fit:720/0*liAw71ABihW7bz7M 720w, https://miro.medium.com/v2/resize:fit:750/0*liAw71ABihW7bz7M 750w, https://miro.medium.com/v2/resize:fit:786/0*liAw71ABihW7bz7M 786w, https://miro.medium.com/v2/resize:fit:828/0*liAw71ABihW7bz7M 828w, https://miro.medium.com/v2/resize:fit:1100/0*liAw71ABihW7bz7M 1100w, https://miro.medium.com/v2/resize:fit:908/0*liAw71ABihW7bz7M 908w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 454px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*liAw71ABihW7bz7M 640w, https://miro.medium.com/v2/resize:fit:720/0*liAw71ABihW7bz7M 720w, https://miro.medium.com/v2/resize:fit:750/0*liAw71ABihW7bz7M 750w, https://miro.medium.com/v2/resize:fit:786/0*liAw71ABihW7bz7M 786w, https://miro.medium.com/v2/resize:fit:828/0*liAw71ABihW7bz7M 828w, https://miro.medium.com/v2/resize:fit:1100/0*liAw71ABihW7bz7M 1100w, https://miro.medium.com/v2/resize:fit:908/0*liAw71ABihW7bz7M 908w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 454px"/><img alt="" class="bg nr ns c" width="454" height="62" loading="lazy" role="presentation"/></picture></div></figure><p id="dc1f" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">PyTorch code for that function:</p><pre class="nh ni nj nk nl ri rg rj bo rk rl rm"><span id="588a" class="rn ov gq rg b bf ro rp l rq rr">def f(x):<br/>  return torch.sin(x)**2 + torch.cos(x)**2</span></pre><p id="4c95" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">If you paid attention in high-school trigonometry class, you know that the value of our function is always going to be 1 for all real valued x. Which means it’s derivative, a derivative of a constant, and must be equal to zero. This will come in handy to verify what the function and its derivatives are doing.</p><p id="4be5" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Now, it’s time to call <code class="cw rd re rf rg b">torch.compile()</code> . First let’s convince ourselves that compiling this function doesn’t change its output. For the same 1x1000 random vector the mean squared error between the output of our function and a vector of 1s should be zero for both the compiled and the uncompiled function (under some error tolerance).</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rs"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*96eA9Gw2_gXvuJfD 640w, https://miro.medium.com/v2/resize:fit:720/0*96eA9Gw2_gXvuJfD 720w, https://miro.medium.com/v2/resize:fit:750/0*96eA9Gw2_gXvuJfD 750w, https://miro.medium.com/v2/resize:fit:786/0*96eA9Gw2_gXvuJfD 786w, https://miro.medium.com/v2/resize:fit:828/0*96eA9Gw2_gXvuJfD 828w, https://miro.medium.com/v2/resize:fit:1100/0*96eA9Gw2_gXvuJfD 1100w, https://miro.medium.com/v2/resize:fit:1400/0*96eA9Gw2_gXvuJfD 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*96eA9Gw2_gXvuJfD 640w, https://miro.medium.com/v2/resize:fit:720/0*96eA9Gw2_gXvuJfD 720w, https://miro.medium.com/v2/resize:fit:750/0*96eA9Gw2_gXvuJfD 750w, https://miro.medium.com/v2/resize:fit:786/0*96eA9Gw2_gXvuJfD 786w, https://miro.medium.com/v2/resize:fit:828/0*96eA9Gw2_gXvuJfD 828w, https://miro.medium.com/v2/resize:fit:1100/0*96eA9Gw2_gXvuJfD 1100w, https://miro.medium.com/v2/resize:fit:1400/0*96eA9Gw2_gXvuJfD 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="301" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="7c12" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">All we did was add a single line of extra code <code class="cw rd re rf rg b">torch.compile()</code> to invoke our compiler. Let’s now take a look at what’s happening under the hood at each stage.</p><h1 id="f8a1" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">Graph capture: Computational graph representation for your PyTorch models or functions</h1><p id="3a23" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj"><strong class="oa gr">PyTorch technologies:</strong> TorchDynamo, FX Graphs, FX IR</p><p id="8930" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">The first step for the compiler is to determine what to compile. Enter TorchDynamo. TorchDynamo intercepts the execution of your Python code and transforms it into FX intermediate representation (IR), and stores it in a special data structure called FX Graph. What does this look like you ask? Glad you asked. Below, we’ll take a looks the code we use to generate this, but here is the transformation and output:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rt"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*dynQHA0FTypCdlYm 640w, https://miro.medium.com/v2/resize:fit:720/0*dynQHA0FTypCdlYm 720w, https://miro.medium.com/v2/resize:fit:750/0*dynQHA0FTypCdlYm 750w, https://miro.medium.com/v2/resize:fit:786/0*dynQHA0FTypCdlYm 786w, https://miro.medium.com/v2/resize:fit:828/0*dynQHA0FTypCdlYm 828w, https://miro.medium.com/v2/resize:fit:1100/0*dynQHA0FTypCdlYm 1100w, https://miro.medium.com/v2/resize:fit:1400/0*dynQHA0FTypCdlYm 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*dynQHA0FTypCdlYm 640w, https://miro.medium.com/v2/resize:fit:720/0*dynQHA0FTypCdlYm 720w, https://miro.medium.com/v2/resize:fit:750/0*dynQHA0FTypCdlYm 750w, https://miro.medium.com/v2/resize:fit:786/0*dynQHA0FTypCdlYm 786w, https://miro.medium.com/v2/resize:fit:828/0*dynQHA0FTypCdlYm 828w, https://miro.medium.com/v2/resize:fit:1100/0*dynQHA0FTypCdlYm 1100w, https://miro.medium.com/v2/resize:fit:1400/0*dynQHA0FTypCdlYm 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="260" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="3641" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">It’s important to note that Torch FX graphs are just containers for IR and don’t really specify what operators it should hold. In the next section we’ll see the FX graph container come up again with a different set of IRs. If you compare the function code and FX IR there’s very little difference between the two. In fact, it’s the same PyTorch code you wrote, but laid out in a format that the FX graph data structure expects. They both will provide the same result when executed.</p><p id="3781" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">If you call torch.compile() without any arguments, it’ll use the default settings which runs the entire compiler stack which includes the default hardware backend compiler called TorchInductor. But we’d be jumping ahead if we discussed TorchInductor now, so let’s park that topic for now, and we’ll come back to it when we’re ready. First we need to discuss graph capture and we can do that by intercepting the calls from torch.compile(). Here’s how we’ll do that: torch.compile() allows you to provide your own compiler too, but because I’m not a compiler engineer, and I don’t have the slightest clue how to write a compiler, I’ll provide a fake compiler function to capture the FX graph IR that TorchDynamo generates.</p><p id="c265" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Below is our fake compiler backend function called inspect_backend to torch.compile() and within that function I do two things:</p><ol class=""><li id="3632" class="ny nz gq oa b ho ob oc od hr oe of og qr oi oj ok qs om on oo qt oq or os ot qu qv qw bj">Print the FX IR code that was captured by TorchDynamo</li><li id="7b55" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj">Save the FX graph visualization</li></ol><figure class="nh ni nj nk nl nm"><div class="ru jt l ff"><div class="rv rw l"></div></div></figure><p id="8e3c" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">The output of that above code snippet are the FX IR code and the graph diagram showing our function <code class="cw rd re rf rg b">sin^2(x)+cos^2(x)</code></p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rx"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*yLlH36oYOsG-7_UN 640w, https://miro.medium.com/v2/resize:fit:720/0*yLlH36oYOsG-7_UN 720w, https://miro.medium.com/v2/resize:fit:750/0*yLlH36oYOsG-7_UN 750w, https://miro.medium.com/v2/resize:fit:786/0*yLlH36oYOsG-7_UN 786w, https://miro.medium.com/v2/resize:fit:828/0*yLlH36oYOsG-7_UN 828w, https://miro.medium.com/v2/resize:fit:1100/0*yLlH36oYOsG-7_UN 1100w, https://miro.medium.com/v2/resize:fit:1400/0*yLlH36oYOsG-7_UN 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*yLlH36oYOsG-7_UN 640w, https://miro.medium.com/v2/resize:fit:720/0*yLlH36oYOsG-7_UN 720w, https://miro.medium.com/v2/resize:fit:750/0*yLlH36oYOsG-7_UN 750w, https://miro.medium.com/v2/resize:fit:786/0*yLlH36oYOsG-7_UN 786w, https://miro.medium.com/v2/resize:fit:828/0*yLlH36oYOsG-7_UN 828w, https://miro.medium.com/v2/resize:fit:1100/0*yLlH36oYOsG-7_UN 1100w, https://miro.medium.com/v2/resize:fit:1400/0*yLlH36oYOsG-7_UN 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="441" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="1056" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Note that our fake compiler inspect_backend function is only invoked when we call the compiled function with some data i.e. when we call <code class="cw rd re rf rg b">compiled_model(x)</code>. In the above code snippet, we’re only evaluating the function or in deep learning terminology, doing a “forward-pass”. In the next section we’ll take advantage of the PyTorch’s automatic differentiation engine called torch.autograd to compute the derivative and the “backward-pass” graph.</p><h1 id="f05b" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">Automatic differentiation: Forward and backward computational graphs</h1><p id="7f6a" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj"><strong class="oa gr">PyTorch technologies:</strong> AOTAutograd, Core Aten IR</p><p id="afb1" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">TorchDynamo gave us the forward pass function evaluation as an FX graph, but what about the backward pass? For the sake of completeness, I’m going to digress from our primary topic and talk a bit about why we need to evaluate the gradients of a function with respect to its weights. If you’re already familiar with how mathematical optimization works skip this immediate section.</p><h2 id="5f8b" class="ry ov gq be ow rz sa dx oz sb sc dz pc oh sd se sf ol sg sh si op sj sk sl sm bj"><strong class="al">What is backward pass and backward graph?</strong></h2><p id="9992" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">The “learning” part of deep learning and machine learning is a mathematical optimization problem which is simply stated as: Find the value of a variable w that yields the lowest value of some function of w. Or more succinctly:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div class="ne nf sn"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*E99X6t0uLFW15wBiIJzUsw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*E99X6t0uLFW15wBiIJzUsw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*E99X6t0uLFW15wBiIJzUsw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*E99X6t0uLFW15wBiIJzUsw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*E99X6t0uLFW15wBiIJzUsw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*E99X6t0uLFW15wBiIJzUsw.png 1100w, https://miro.medium.com/v2/resize:fit:680/format:webp/1*E99X6t0uLFW15wBiIJzUsw.png 680w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 340px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*E99X6t0uLFW15wBiIJzUsw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*E99X6t0uLFW15wBiIJzUsw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*E99X6t0uLFW15wBiIJzUsw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*E99X6t0uLFW15wBiIJzUsw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*E99X6t0uLFW15wBiIJzUsw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*E99X6t0uLFW15wBiIJzUsw.png 1100w, https://miro.medium.com/v2/resize:fit:680/1*E99X6t0uLFW15wBiIJzUsw.png 680w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 340px"/><img alt="" class="bg nr ns c" width="340" height="84" loading="lazy" role="presentation"/></picture></div></figure><p id="c825" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">In machine learning f(w) is the loss function parametrized by weights. f(w) can be more clearly represented as some measure of error between the training labels and the model’s prediction labels based on the training data:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf so"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*3U_yTT5OHnFPjUJs 640w, https://miro.medium.com/v2/resize:fit:720/0*3U_yTT5OHnFPjUJs 720w, https://miro.medium.com/v2/resize:fit:750/0*3U_yTT5OHnFPjUJs 750w, https://miro.medium.com/v2/resize:fit:786/0*3U_yTT5OHnFPjUJs 786w, https://miro.medium.com/v2/resize:fit:828/0*3U_yTT5OHnFPjUJs 828w, https://miro.medium.com/v2/resize:fit:1100/0*3U_yTT5OHnFPjUJs 1100w, https://miro.medium.com/v2/resize:fit:1400/0*3U_yTT5OHnFPjUJs 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*3U_yTT5OHnFPjUJs 640w, https://miro.medium.com/v2/resize:fit:720/0*3U_yTT5OHnFPjUJs 720w, https://miro.medium.com/v2/resize:fit:750/0*3U_yTT5OHnFPjUJs 750w, https://miro.medium.com/v2/resize:fit:786/0*3U_yTT5OHnFPjUJs 786w, https://miro.medium.com/v2/resize:fit:828/0*3U_yTT5OHnFPjUJs 828w, https://miro.medium.com/v2/resize:fit:1100/0*3U_yTT5OHnFPjUJs 1100w, https://miro.medium.com/v2/resize:fit:1400/0*3U_yTT5OHnFPjUJs 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="66" loading="lazy" role="presentation"/></picture></div></div></figure><p id="5dd7" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Turns out, if we can calculate the “rate of reduction” of loss with respect to weights, we can update our weights to move one step closer to a smaller and smaller loss f(w). In other words, we must move closer to a model that better fits our training dataset. We can find next values of weights by calculating the steepest slope of the loss f(w) at a given w and perturb w to head in that direction. The slope of a function with respect to the weights, is its derivative with respect to the weights. Since there are more than one weight values, the derivative becomes a vector quantity called the gradient which is a vector of partial derivatives with components for each weight. The weights w are perturbed at each iteration by some function g() of the gradients as follows:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div class="ne nf sp"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*Lm8u9ZHiyDyIPcgF 640w, https://miro.medium.com/v2/resize:fit:720/0*Lm8u9ZHiyDyIPcgF 720w, https://miro.medium.com/v2/resize:fit:750/0*Lm8u9ZHiyDyIPcgF 750w, https://miro.medium.com/v2/resize:fit:786/0*Lm8u9ZHiyDyIPcgF 786w, https://miro.medium.com/v2/resize:fit:828/0*Lm8u9ZHiyDyIPcgF 828w, https://miro.medium.com/v2/resize:fit:1100/0*Lm8u9ZHiyDyIPcgF 1100w, https://miro.medium.com/v2/resize:fit:752/0*Lm8u9ZHiyDyIPcgF 752w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 376px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*Lm8u9ZHiyDyIPcgF 640w, https://miro.medium.com/v2/resize:fit:720/0*Lm8u9ZHiyDyIPcgF 720w, https://miro.medium.com/v2/resize:fit:750/0*Lm8u9ZHiyDyIPcgF 750w, https://miro.medium.com/v2/resize:fit:786/0*Lm8u9ZHiyDyIPcgF 786w, https://miro.medium.com/v2/resize:fit:828/0*Lm8u9ZHiyDyIPcgF 828w, https://miro.medium.com/v2/resize:fit:1100/0*Lm8u9ZHiyDyIPcgF 1100w, https://miro.medium.com/v2/resize:fit:752/0*Lm8u9ZHiyDyIPcgF 752w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 376px"/><img alt="" class="bg nr ns c" width="376" height="66" loading="lazy" role="presentation"/></picture></div></figure><p id="7e58" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Where the function g(.) depends on the optimizer (e.g. sgd, sgdm, rmsprop, adam etc.).</p><p id="bd79" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">For SGD the weight update step becomes:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div class="ne nf sq"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*JUk04O0RfHzlDgK6 640w, https://miro.medium.com/v2/resize:fit:720/0*JUk04O0RfHzlDgK6 720w, https://miro.medium.com/v2/resize:fit:750/0*JUk04O0RfHzlDgK6 750w, https://miro.medium.com/v2/resize:fit:786/0*JUk04O0RfHzlDgK6 786w, https://miro.medium.com/v2/resize:fit:828/0*JUk04O0RfHzlDgK6 828w, https://miro.medium.com/v2/resize:fit:1100/0*JUk04O0RfHzlDgK6 1100w, https://miro.medium.com/v2/resize:fit:760/0*JUk04O0RfHzlDgK6 760w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 380px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*JUk04O0RfHzlDgK6 640w, https://miro.medium.com/v2/resize:fit:720/0*JUk04O0RfHzlDgK6 720w, https://miro.medium.com/v2/resize:fit:750/0*JUk04O0RfHzlDgK6 750w, https://miro.medium.com/v2/resize:fit:786/0*JUk04O0RfHzlDgK6 786w, https://miro.medium.com/v2/resize:fit:828/0*JUk04O0RfHzlDgK6 828w, https://miro.medium.com/v2/resize:fit:1100/0*JUk04O0RfHzlDgK6 1100w, https://miro.medium.com/v2/resize:fit:760/0*JUk04O0RfHzlDgK6 760w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 380px"/><img alt="" class="bg nr ns c" width="380" height="65" loading="lazy" role="presentation"/></picture></div></figure><h2 id="f743" class="ry ov gq be ow rz sa dx oz sb sc dz pc oh sd se sf ol sg sh si op sj sk sl sm bj"><strong class="al">How does PyTorch 2.0 trace the backward pass graph?</strong></h2><p id="b06b" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">First let’s calculate what we expect the backward pass graph should look like and then compare it with what PyTorch generates. For our simple function, the forward graph and the backward graph should implement the following function. If sin and cos bother you, you can imagine f(x) being the loss function applied to a neural network.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf sr"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*q5Ia6sZqz6dQ5_6h 640w, https://miro.medium.com/v2/resize:fit:720/0*q5Ia6sZqz6dQ5_6h 720w, https://miro.medium.com/v2/resize:fit:750/0*q5Ia6sZqz6dQ5_6h 750w, https://miro.medium.com/v2/resize:fit:786/0*q5Ia6sZqz6dQ5_6h 786w, https://miro.medium.com/v2/resize:fit:828/0*q5Ia6sZqz6dQ5_6h 828w, https://miro.medium.com/v2/resize:fit:1100/0*q5Ia6sZqz6dQ5_6h 1100w, https://miro.medium.com/v2/resize:fit:1400/0*q5Ia6sZqz6dQ5_6h 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*q5Ia6sZqz6dQ5_6h 640w, https://miro.medium.com/v2/resize:fit:720/0*q5Ia6sZqz6dQ5_6h 720w, https://miro.medium.com/v2/resize:fit:750/0*q5Ia6sZqz6dQ5_6h 750w, https://miro.medium.com/v2/resize:fit:786/0*q5Ia6sZqz6dQ5_6h 786w, https://miro.medium.com/v2/resize:fit:828/0*q5Ia6sZqz6dQ5_6h 828w, https://miro.medium.com/v2/resize:fit:1100/0*q5Ia6sZqz6dQ5_6h 1100w, https://miro.medium.com/v2/resize:fit:1400/0*q5Ia6sZqz6dQ5_6h 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="109" loading="lazy" role="presentation"/></picture></div></div></figure><p id="f6fb" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">PyTorch uses reverse-mode <a class="af qq" href="https://en.wikipedia.org/wiki/Automatic_differentiation" rel="noopener ugc nofollow" target="_blank">automatic differentiation</a> to compute the gradients, and PyTorch’s implementation of automation differentiation is called Autograd. PyTorch 2.0 introduces AOTAutograd which traces the forward and backward graph ahead of time, i.e. prior to execution, and generates a joint forward and backward graph. It then partitions the forward and the backward graph into two separate graphs. Both the forward and the backward graphs are stored in the FX graph data structure and can be visualized as shown below.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf ss"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*xoGZ022j8SEMGofJ 640w, https://miro.medium.com/v2/resize:fit:720/0*xoGZ022j8SEMGofJ 720w, https://miro.medium.com/v2/resize:fit:750/0*xoGZ022j8SEMGofJ 750w, https://miro.medium.com/v2/resize:fit:786/0*xoGZ022j8SEMGofJ 786w, https://miro.medium.com/v2/resize:fit:828/0*xoGZ022j8SEMGofJ 828w, https://miro.medium.com/v2/resize:fit:1100/0*xoGZ022j8SEMGofJ 1100w, https://miro.medium.com/v2/resize:fit:1400/0*xoGZ022j8SEMGofJ 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*xoGZ022j8SEMGofJ 640w, https://miro.medium.com/v2/resize:fit:720/0*xoGZ022j8SEMGofJ 720w, https://miro.medium.com/v2/resize:fit:750/0*xoGZ022j8SEMGofJ 750w, https://miro.medium.com/v2/resize:fit:786/0*xoGZ022j8SEMGofJ 786w, https://miro.medium.com/v2/resize:fit:828/0*xoGZ022j8SEMGofJ 828w, https://miro.medium.com/v2/resize:fit:1100/0*xoGZ022j8SEMGofJ 1100w, https://miro.medium.com/v2/resize:fit:1400/0*xoGZ022j8SEMGofJ 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="470" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="8b6a" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">You can verify that the math checks out by working through the nodes on the graph. AOTAutograd generated backward pass indeed computes the derivative shown in the equation I shared earlier, which should equal zero since the original function only produces the identity.</p><p id="1433" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">We’ll now run AOTAutograd by extending our fake compiler function inspect_backend to call AOTAutograd and generate our backward graph. The updated inspect_backed defines a forward (fw) and backward (bw) compiler capture function that reads the forward and backward graph from AOTAutograd and prints the lowered ATen IR and saves the FX graph for the forward and backward graphs.</p><figure class="nh ni nj nk nl nm"><div class="ru jt l ff"><div class="rv rw l"></div></div></figure><p id="c0e9" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">This will generate the following forward AND backward graphs. Notice that the forward graph also looks slightly different from what we saw earlier in Figure x. For example torch.sin(x) in the FX graph IR and in our original code has been replaced by torch.ops.aten.sin.default(). What’s this funny thing called aten, you might ask, if you’re not already familiar with it. ATen stands for A Tensor library, which is a very creatively named low level library with a C++ interface that implements many of the fundamental operations that run on CPU and GPU.</p><p id="e678" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">In eager mode operation, your PyTorch operations are routed to this library which then calls the appropriate CPU or GPU implementation. AOTAutograd automatically generates code that replaces the higher level PyTorch API with ATen IR for the forward and backward graph which you can see in the output below:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf st"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*GkmAQooTat3ZRpsx 640w, https://miro.medium.com/v2/resize:fit:720/0*GkmAQooTat3ZRpsx 720w, https://miro.medium.com/v2/resize:fit:750/0*GkmAQooTat3ZRpsx 750w, https://miro.medium.com/v2/resize:fit:786/0*GkmAQooTat3ZRpsx 786w, https://miro.medium.com/v2/resize:fit:828/0*GkmAQooTat3ZRpsx 828w, https://miro.medium.com/v2/resize:fit:1100/0*GkmAQooTat3ZRpsx 1100w, https://miro.medium.com/v2/resize:fit:1400/0*GkmAQooTat3ZRpsx 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*GkmAQooTat3ZRpsx 640w, https://miro.medium.com/v2/resize:fit:720/0*GkmAQooTat3ZRpsx 720w, https://miro.medium.com/v2/resize:fit:750/0*GkmAQooTat3ZRpsx 750w, https://miro.medium.com/v2/resize:fit:786/0*GkmAQooTat3ZRpsx 786w, https://miro.medium.com/v2/resize:fit:828/0*GkmAQooTat3ZRpsx 828w, https://miro.medium.com/v2/resize:fit:1100/0*GkmAQooTat3ZRpsx 1100w, https://miro.medium.com/v2/resize:fit:1400/0*GkmAQooTat3ZRpsx 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="419" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="dac2" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">You can also see that in addition to the output of the forward pass, the forward graph outputs some additional tensors [add, sin, cos, primals_1] . These tensors are saved for the backward pass for gradient calculation. You can also see this in the computational graphs for the forward and backward pass in the figure shared earlier.</p><h1 id="21e2" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">What are the different types of IR in PyTorch?</h1><p id="df49" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">ATen IR is a list of operators supported by the ATen library as we discussed in the previous section, and you can see the full list of operations implemented in <a class="af qq" href="https://pytorch.org/cppdocs/api/namespace_at.html" rel="noopener ugc nofollow" target="_blank">ATen library here</a>. There are two other IR concepts in PyTorch you should be aware of: 1/ Core Aten IR 2/ Prims IR. Core Aten IR is a subset of the broader Aten IR and Prims IR and an even smaller subset of Core Aten IR. Let’s say you are designing a processor and want to support PyTorch code acceleration on your hardware. It’d be near impossible to support the full list of PyTorch API in hardware, so what you can do is build a compiler that only supports the smaller subset of fundamental operators defined in Core Aten IR or Prims IR, and let AOTAutograd decompose compound operators into the core operators as we’ll see in the next section.</p><h1 id="5d2c" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">What’s the difference between ATen IR, Core ATen IR, Prims IR?</h1><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf su"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*08kXPkgYt-RuI1rV 640w, https://miro.medium.com/v2/resize:fit:720/0*08kXPkgYt-RuI1rV 720w, https://miro.medium.com/v2/resize:fit:750/0*08kXPkgYt-RuI1rV 750w, https://miro.medium.com/v2/resize:fit:786/0*08kXPkgYt-RuI1rV 786w, https://miro.medium.com/v2/resize:fit:828/0*08kXPkgYt-RuI1rV 828w, https://miro.medium.com/v2/resize:fit:1100/0*08kXPkgYt-RuI1rV 1100w, https://miro.medium.com/v2/resize:fit:1400/0*08kXPkgYt-RuI1rV 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*08kXPkgYt-RuI1rV 640w, https://miro.medium.com/v2/resize:fit:720/0*08kXPkgYt-RuI1rV 720w, https://miro.medium.com/v2/resize:fit:750/0*08kXPkgYt-RuI1rV 750w, https://miro.medium.com/v2/resize:fit:786/0*08kXPkgYt-RuI1rV 786w, https://miro.medium.com/v2/resize:fit:828/0*08kXPkgYt-RuI1rV 828w, https://miro.medium.com/v2/resize:fit:1100/0*08kXPkgYt-RuI1rV 1100w, https://miro.medium.com/v2/resize:fit:1400/0*08kXPkgYt-RuI1rV 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="485" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="a7a5" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj"><a class="af qq" href="https://pytorch.org/docs/stable/ir.html#core-aten-ir" rel="noopener ugc nofollow" target="_blank">Core Aten IR</a> (formerly canonical Aten IR) is a subset of the Aten IR that can be used to compose all other operators in the Aten IR. Compilers that target specific hardware accelerators can focus on supporting only the Core Aten IR and mapping it to their low level hardware API. This makes it easier to add hardware support to PyTorch since they don’t have to implement support for the full PyTorch API which will continue to grow with more and more abstractions.</p><p id="0dea" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj"><a class="af qq" href="https://pytorch.org/docs/stable/ir.html#prims-ir" rel="noopener ugc nofollow" target="_blank">Prims IR</a> is an even smaller subset of the Core Aten IR that further decomposes Core Aten IR ops into fundamental operations making it even easier for compilers that target specific hardware to support PyTorch. But decomposing operators into lower and lower operations will most definitely lead to performance degradation due to excess memory writes and function call overhead. But the expectation is that hardware compilers can take these operators and fuse them back together to support hardware API to get back performance.</p><p id="296a" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">While we don’t need to further decompose our function into Core Aten IR and Prims IR I’ll demonstrate how below.</p><h1 id="cc1a" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">(Optional topic) Decomposition to Core Aten IR and Prims IR</h1><p id="b825" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">If you’re designing hardware or hardware compilers, it’d be near impossible to support the full list of PyTorch API in hardware, especially given the pace at which deep learning and AI are advancing. But the advantage for a hardware designer is that most deep learning functionality can be mapped into very few basic mathematical operations and the most computationally intensive ones are matrix-matrix and matrix-vector operations. Compound operators like those supported by PyTorch API can be decomposed into these fundamental operations using AOTAutograd as we’ll discuss in this section. If you don’t deal with low level hardware, you can skip this section.</p><p id="c3ad" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">You can update the AOTAutograd function to pass in a dictionary of decompositions that can lower the Aten IR into Core Aten IR and Prims IR. I’ll only share the relevant code snippet and output here since you can find the full notebook on GitHub. By default operators are not decomposed into Core Aten IR or Prims IR, but you can pass a dictionary of decompositions.</p><p id="ddf6" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">In the code snippet below, I’ve converted our function f into a loss function f_loss by including the computation of mean squared error (MSE) into our function. I’m doing this to demonstrate how AOTAutograd can decompose MSE into its fundamental operators.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf sv"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*57O6alQXLfSRFf16 640w, https://miro.medium.com/v2/resize:fit:720/0*57O6alQXLfSRFf16 720w, https://miro.medium.com/v2/resize:fit:750/0*57O6alQXLfSRFf16 750w, https://miro.medium.com/v2/resize:fit:786/0*57O6alQXLfSRFf16 786w, https://miro.medium.com/v2/resize:fit:828/0*57O6alQXLfSRFf16 828w, https://miro.medium.com/v2/resize:fit:1100/0*57O6alQXLfSRFf16 1100w, https://miro.medium.com/v2/resize:fit:1400/0*57O6alQXLfSRFf16 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*57O6alQXLfSRFf16 640w, https://miro.medium.com/v2/resize:fit:720/0*57O6alQXLfSRFf16 720w, https://miro.medium.com/v2/resize:fit:750/0*57O6alQXLfSRFf16 750w, https://miro.medium.com/v2/resize:fit:786/0*57O6alQXLfSRFf16 786w, https://miro.medium.com/v2/resize:fit:828/0*57O6alQXLfSRFf16 828w, https://miro.medium.com/v2/resize:fit:1100/0*57O6alQXLfSRFf16 1100w, https://miro.medium.com/v2/resize:fit:1400/0*57O6alQXLfSRFf16 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="429" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="7def" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">The output of the decomposition is that mse_loss gets decomposed into more fundamental operations: subtract , power(2) , mean.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf sw"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*dy_DIS_oy-WdQKCD 640w, https://miro.medium.com/v2/resize:fit:720/0*dy_DIS_oy-WdQKCD 720w, https://miro.medium.com/v2/resize:fit:750/0*dy_DIS_oy-WdQKCD 750w, https://miro.medium.com/v2/resize:fit:786/0*dy_DIS_oy-WdQKCD 786w, https://miro.medium.com/v2/resize:fit:828/0*dy_DIS_oy-WdQKCD 828w, https://miro.medium.com/v2/resize:fit:1100/0*dy_DIS_oy-WdQKCD 1100w, https://miro.medium.com/v2/resize:fit:1400/0*dy_DIS_oy-WdQKCD 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*dy_DIS_oy-WdQKCD 640w, https://miro.medium.com/v2/resize:fit:720/0*dy_DIS_oy-WdQKCD 720w, https://miro.medium.com/v2/resize:fit:750/0*dy_DIS_oy-WdQKCD 750w, https://miro.medium.com/v2/resize:fit:786/0*dy_DIS_oy-WdQKCD 786w, https://miro.medium.com/v2/resize:fit:828/0*dy_DIS_oy-WdQKCD 828w, https://miro.medium.com/v2/resize:fit:1100/0*dy_DIS_oy-WdQKCD 1100w, https://miro.medium.com/v2/resize:fit:1400/0*dy_DIS_oy-WdQKCD 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="410" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="a49f" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">This is because MSE or mean square error between two vectors x and y is defined as the following which only needs those 3 operations subtract, where power is an element-wise operation. If you write a compiler for your hardware, you likely already support these 3 operations and by decomposition your PyTorch code would run without further modifications.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div class="ne nf sx"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*VsqNyQSzZ3BkGLx0 640w, https://miro.medium.com/v2/resize:fit:720/0*VsqNyQSzZ3BkGLx0 720w, https://miro.medium.com/v2/resize:fit:750/0*VsqNyQSzZ3BkGLx0 750w, https://miro.medium.com/v2/resize:fit:786/0*VsqNyQSzZ3BkGLx0 786w, https://miro.medium.com/v2/resize:fit:828/0*VsqNyQSzZ3BkGLx0 828w, https://miro.medium.com/v2/resize:fit:1100/0*VsqNyQSzZ3BkGLx0 1100w, https://miro.medium.com/v2/resize:fit:798/0*VsqNyQSzZ3BkGLx0 798w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 399px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*VsqNyQSzZ3BkGLx0 640w, https://miro.medium.com/v2/resize:fit:720/0*VsqNyQSzZ3BkGLx0 720w, https://miro.medium.com/v2/resize:fit:750/0*VsqNyQSzZ3BkGLx0 750w, https://miro.medium.com/v2/resize:fit:786/0*VsqNyQSzZ3BkGLx0 786w, https://miro.medium.com/v2/resize:fit:828/0*VsqNyQSzZ3BkGLx0 828w, https://miro.medium.com/v2/resize:fit:1100/0*VsqNyQSzZ3BkGLx0 1100w, https://miro.medium.com/v2/resize:fit:798/0*VsqNyQSzZ3BkGLx0 798w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 399px"/><img alt="" class="bg nr ns c" width="399" height="77" loading="lazy" role="presentation"/></picture></div></figure><p id="5294" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">You can also see this reflected in the FX graph visualization</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf sy"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*b7gdHy_XZ3sBuoFI 640w, https://miro.medium.com/v2/resize:fit:720/0*b7gdHy_XZ3sBuoFI 720w, https://miro.medium.com/v2/resize:fit:750/0*b7gdHy_XZ3sBuoFI 750w, https://miro.medium.com/v2/resize:fit:786/0*b7gdHy_XZ3sBuoFI 786w, https://miro.medium.com/v2/resize:fit:828/0*b7gdHy_XZ3sBuoFI 828w, https://miro.medium.com/v2/resize:fit:1100/0*b7gdHy_XZ3sBuoFI 1100w, https://miro.medium.com/v2/resize:fit:1400/0*b7gdHy_XZ3sBuoFI 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*b7gdHy_XZ3sBuoFI 640w, https://miro.medium.com/v2/resize:fit:720/0*b7gdHy_XZ3sBuoFI 720w, https://miro.medium.com/v2/resize:fit:750/0*b7gdHy_XZ3sBuoFI 750w, https://miro.medium.com/v2/resize:fit:786/0*b7gdHy_XZ3sBuoFI 786w, https://miro.medium.com/v2/resize:fit:828/0*b7gdHy_XZ3sBuoFI 828w, https://miro.medium.com/v2/resize:fit:1100/0*b7gdHy_XZ3sBuoFI 1100w, https://miro.medium.com/v2/resize:fit:1400/0*b7gdHy_XZ3sBuoFI 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="720" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="0ca6" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Now let’s decompose it further into Prims IR which is a much smaller subset of ~250 operators. Again, I’ll only share the relevant code snippet and output here since you can find the full notebook on GitHub.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf sz"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*kCulwywR5xzP8xwl 640w, https://miro.medium.com/v2/resize:fit:720/0*kCulwywR5xzP8xwl 720w, https://miro.medium.com/v2/resize:fit:750/0*kCulwywR5xzP8xwl 750w, https://miro.medium.com/v2/resize:fit:786/0*kCulwywR5xzP8xwl 786w, https://miro.medium.com/v2/resize:fit:828/0*kCulwywR5xzP8xwl 828w, https://miro.medium.com/v2/resize:fit:1100/0*kCulwywR5xzP8xwl 1100w, https://miro.medium.com/v2/resize:fit:1400/0*kCulwywR5xzP8xwl 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*kCulwywR5xzP8xwl 640w, https://miro.medium.com/v2/resize:fit:720/0*kCulwywR5xzP8xwl 720w, https://miro.medium.com/v2/resize:fit:750/0*kCulwywR5xzP8xwl 750w, https://miro.medium.com/v2/resize:fit:786/0*kCulwywR5xzP8xwl 786w, https://miro.medium.com/v2/resize:fit:828/0*kCulwywR5xzP8xwl 828w, https://miro.medium.com/v2/resize:fit:1100/0*kCulwywR5xzP8xwl 1100w, https://miro.medium.com/v2/resize:fit:1400/0*kCulwywR5xzP8xwl 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="513" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="abde" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">The output of the prim IR decomposition is below. All the aten ops in RED are replaced or decomposed to use prim operators in green.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rt"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*jviXTeQJMK0SvcKd 640w, https://miro.medium.com/v2/resize:fit:720/0*jviXTeQJMK0SvcKd 720w, https://miro.medium.com/v2/resize:fit:750/0*jviXTeQJMK0SvcKd 750w, https://miro.medium.com/v2/resize:fit:786/0*jviXTeQJMK0SvcKd 786w, https://miro.medium.com/v2/resize:fit:828/0*jviXTeQJMK0SvcKd 828w, https://miro.medium.com/v2/resize:fit:1100/0*jviXTeQJMK0SvcKd 1100w, https://miro.medium.com/v2/resize:fit:1400/0*jviXTeQJMK0SvcKd 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*jviXTeQJMK0SvcKd 640w, https://miro.medium.com/v2/resize:fit:720/0*jviXTeQJMK0SvcKd 720w, https://miro.medium.com/v2/resize:fit:750/0*jviXTeQJMK0SvcKd 750w, https://miro.medium.com/v2/resize:fit:786/0*jviXTeQJMK0SvcKd 786w, https://miro.medium.com/v2/resize:fit:828/0*jviXTeQJMK0SvcKd 828w, https://miro.medium.com/v2/resize:fit:1100/0*jviXTeQJMK0SvcKd 1100w, https://miro.medium.com/v2/resize:fit:1400/0*jviXTeQJMK0SvcKd 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="113" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><h1 id="a6da" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">Graph optimization: Layer and operator fusion and C++/GPU code generation</h1><p id="2813" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj"><strong class="oa gr">PyTorch technologies discussed:</strong> TorchInductor, OpenAI Triton (default) other compilers</p><p id="f9d5" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">In this final section of the blog post we’ll discuss operator fusion and automatic code generation for CPUs and GPUs using TorchInductor. First some basics:</p><h2 id="d1a9" class="ry ov gq be ow rz sa dx oz sb sc dz pc oh sd se sf ol sg sh si op sj sk sl sm bj"><strong class="al">What is a deep learning optimizing compiler?</strong></h2><p id="39f4" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">An optimizing compiler for deep learning is good at finding performance gaps in code and addressing them by transforming the code to reduce code attributes such as memory access, kernel launches, data layout optimizations for a target backend. TorchInductor is the default optimizing compiler with torch.compile() that can generate optimized kernels for GPUs using OpenAI Triton and CPUs using OpenMP pragma directives.</p><h2 id="f4b9" class="ry ov gq be ow rz sa dx oz sb sc dz pc oh sd se sf ol sg sh si op sj sk sl sm bj"><strong class="al">What is operator fusion in deep learning?</strong></h2><p id="a7ea" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">Deep learning is composed of many fundamental operations such as matrix-matrix and matrix-vector multiplications. In PyTorch eager mode of execution each operation will result in separate function calls or kernel launches on hardware. This leads to CPU overhead of launching kernels and results in more memory reads and writes between kernel launches. A deep learning optimizing compiler like TorchInductor can fuse multiple operations into a single compound operator in python and generate low-level GPU kernels or C++/OpenMP code for it. This results in faster computation due to fewer kernel launches and fewer memory read/writes.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf ta"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*y-UZc2j1yJQxZHIC 640w, https://miro.medium.com/v2/resize:fit:720/0*y-UZc2j1yJQxZHIC 720w, https://miro.medium.com/v2/resize:fit:750/0*y-UZc2j1yJQxZHIC 750w, https://miro.medium.com/v2/resize:fit:786/0*y-UZc2j1yJQxZHIC 786w, https://miro.medium.com/v2/resize:fit:828/0*y-UZc2j1yJQxZHIC 828w, https://miro.medium.com/v2/resize:fit:1100/0*y-UZc2j1yJQxZHIC 1100w, https://miro.medium.com/v2/resize:fit:1400/0*y-UZc2j1yJQxZHIC 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*y-UZc2j1yJQxZHIC 640w, https://miro.medium.com/v2/resize:fit:720/0*y-UZc2j1yJQxZHIC 720w, https://miro.medium.com/v2/resize:fit:750/0*y-UZc2j1yJQxZHIC 750w, https://miro.medium.com/v2/resize:fit:786/0*y-UZc2j1yJQxZHIC 786w, https://miro.medium.com/v2/resize:fit:828/0*y-UZc2j1yJQxZHIC 828w, https://miro.medium.com/v2/resize:fit:1100/0*y-UZc2j1yJQxZHIC 1100w, https://miro.medium.com/v2/resize:fit:1400/0*y-UZc2j1yJQxZHIC 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="538" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="a033" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">The computational graph from the output of AOTAutograd in the previous section is composed of many Aten operators represented in an FX graph. TorchInductor optimizations doesn’t change the underlying computation in the graph but merely restructures it with operator and layer fusion, and generates CPU or GPU code for it. Since TorchInductor can see the full forward and backward computational graph ahead of time, it can take decisions on out-of-order execution of operations that don’t have dependence on each other, and maximize hardware resource utilization.</p><p id="5116" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Under the hood, for GPU targets, TorchInductor uses OpenAI’s Triton to generate fused GPU kernels. Triton itself is a separate Python based framework and compiler for writing optimized low-level GPU code which is otherwise written in CUDA C/C++. But the only difference is that TorchInductor will generate Triton code which is compiled into low level PTX code.</p><p id="c6e4" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">For multi-core CPU targets, TorchInductor generates C++ code and injects OpenMP pragma directives to generate parallel kernels. From the PyTorch user level world view, this is the IR transformation flow:</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf tb"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*bHIRpgT9w4hOQR9v 640w, https://miro.medium.com/v2/resize:fit:720/0*bHIRpgT9w4hOQR9v 720w, https://miro.medium.com/v2/resize:fit:750/0*bHIRpgT9w4hOQR9v 750w, https://miro.medium.com/v2/resize:fit:786/0*bHIRpgT9w4hOQR9v 786w, https://miro.medium.com/v2/resize:fit:828/0*bHIRpgT9w4hOQR9v 828w, https://miro.medium.com/v2/resize:fit:1100/0*bHIRpgT9w4hOQR9v 1100w, https://miro.medium.com/v2/resize:fit:1400/0*bHIRpgT9w4hOQR9v 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*bHIRpgT9w4hOQR9v 640w, https://miro.medium.com/v2/resize:fit:720/0*bHIRpgT9w4hOQR9v 720w, https://miro.medium.com/v2/resize:fit:750/0*bHIRpgT9w4hOQR9v 750w, https://miro.medium.com/v2/resize:fit:786/0*bHIRpgT9w4hOQR9v 786w, https://miro.medium.com/v2/resize:fit:828/0*bHIRpgT9w4hOQR9v 828w, https://miro.medium.com/v2/resize:fit:1100/0*bHIRpgT9w4hOQR9v 1100w, https://miro.medium.com/v2/resize:fit:1400/0*bHIRpgT9w4hOQR9v 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="428" loading="lazy" role="presentation"/></picture></div></div></figure><p id="14d0" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Of course this being the high-level view, I’m omitting some details here and I encourage you to read the <a class="af qq" href="https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747" rel="noopener ugc nofollow" target="_blank">TorchInductor forum post</a> and <a class="af qq" href="https://openai.com/research/triton" rel="noopener ugc nofollow" target="_blank">OpenAI’s triton blog post for triton</a>.</p><p id="0a67" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">We’ll now throw away our fake compiler which we used in our previous section, and use the full PyTorch compiler stack that uses TorchInductor.</p><figure class="nh ni nj nk nl nm"><div class="ru jt l ff"><div class="rv rw l"></div></div></figure><p id="b046" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">Notice that I’ve passed optional argument that enables two debug features:</p><ul class=""><li id="896b" class="ny nz gq oa b ho ob oc od hr oe of og qr oi oj ok qs om on oo qt oq or os ot tc qv qw bj"><code class="cw rd re rf rg b">trace.enabled</code>: Generates intermediate code to inspect code generated by TorchInductor</li><li id="dbb3" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot tc qv qw bj"><code class="cw rd re rf rg b">trace.graph_enabled</code>: Generates the optimized computational graph visualization after operator fusion</li></ul><p id="65da" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">For our simple example TorchInductor is able to fuse all intermediate operations in our function into a single custom operator, and you can see below how that simplifies the forward and backward computational graphs.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf td"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*zVp2otO0g7QKlasj 640w, https://miro.medium.com/v2/resize:fit:720/0*zVp2otO0g7QKlasj 720w, https://miro.medium.com/v2/resize:fit:750/0*zVp2otO0g7QKlasj 750w, https://miro.medium.com/v2/resize:fit:786/0*zVp2otO0g7QKlasj 786w, https://miro.medium.com/v2/resize:fit:828/0*zVp2otO0g7QKlasj 828w, https://miro.medium.com/v2/resize:fit:1100/0*zVp2otO0g7QKlasj 1100w, https://miro.medium.com/v2/resize:fit:1400/0*zVp2otO0g7QKlasj 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*zVp2otO0g7QKlasj 640w, https://miro.medium.com/v2/resize:fit:720/0*zVp2otO0g7QKlasj 720w, https://miro.medium.com/v2/resize:fit:750/0*zVp2otO0g7QKlasj 750w, https://miro.medium.com/v2/resize:fit:786/0*zVp2otO0g7QKlasj 786w, https://miro.medium.com/v2/resize:fit:828/0*zVp2otO0g7QKlasj 828w, https://miro.medium.com/v2/resize:fit:1100/0*zVp2otO0g7QKlasj 1100w, https://miro.medium.com/v2/resize:fit:1400/0*zVp2otO0g7QKlasj 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="413" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="0797" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">You must surely be wondering what this fused operator looks like in code. The code for the fused operator is automatically generated by TorchInductor and it’s in C++ or Triton based on the target device — CPU or GPU. You don’t need to explicitly specify to TorchInductor which device to target, it can infer it from the data and model device type.</p><p id="8d3c" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">To view the generated code, you have to enable debugging using trace.enabled=True and this creates a director called torch_compile_debug with debug information.</p><p id="5c20" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">The full path to forward and backward graph code are:</p><ul class=""><li id="64eb" class="ny nz gq oa b ho ob oc od hr oe of og qr oi oj ok qs om on oo qt oq or os ot tc qv qw bj"><code class="cw rd re rf rg b">torch_compile_debug/run_&lt;DATE_TIME_PID&gt;/aot_torchinductor/model__XX_forward_XX/output_code.py</code></li><li id="4eea" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot tc qv qw bj"><code class="cw rd re rf rg b">torch_compile_debug/run_&lt;DATE_TIME_PID&gt;/aot_torchinductor/model__XX_backward_XX/output_code.py</code></li></ul><p id="eea8" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">If you set device = ‘cuda’ (assuming your computer has a GPU device) then the generated code in the forward folder is in Open AI Triton</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rt"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*eEvqQIeejh-cl8CK 640w, https://miro.medium.com/v2/resize:fit:720/0*eEvqQIeejh-cl8CK 720w, https://miro.medium.com/v2/resize:fit:750/0*eEvqQIeejh-cl8CK 750w, https://miro.medium.com/v2/resize:fit:786/0*eEvqQIeejh-cl8CK 786w, https://miro.medium.com/v2/resize:fit:828/0*eEvqQIeejh-cl8CK 828w, https://miro.medium.com/v2/resize:fit:1100/0*eEvqQIeejh-cl8CK 1100w, https://miro.medium.com/v2/resize:fit:1400/0*eEvqQIeejh-cl8CK 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*eEvqQIeejh-cl8CK 640w, https://miro.medium.com/v2/resize:fit:720/0*eEvqQIeejh-cl8CK 720w, https://miro.medium.com/v2/resize:fit:750/0*eEvqQIeejh-cl8CK 750w, https://miro.medium.com/v2/resize:fit:786/0*eEvqQIeejh-cl8CK 786w, https://miro.medium.com/v2/resize:fit:828/0*eEvqQIeejh-cl8CK 828w, https://miro.medium.com/v2/resize:fit:1100/0*eEvqQIeejh-cl8CK 1100w, https://miro.medium.com/v2/resize:fit:1400/0*eEvqQIeejh-cl8CK 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="461" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><p id="bf5e" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">If you set device = ‘CPU’ then the generated code is in C++ with OpenMP pragmas</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rt"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*fx4AsAhd8760yyXb 640w, https://miro.medium.com/v2/resize:fit:720/0*fx4AsAhd8760yyXb 720w, https://miro.medium.com/v2/resize:fit:750/0*fx4AsAhd8760yyXb 750w, https://miro.medium.com/v2/resize:fit:786/0*fx4AsAhd8760yyXb 786w, https://miro.medium.com/v2/resize:fit:828/0*fx4AsAhd8760yyXb 828w, https://miro.medium.com/v2/resize:fit:1100/0*fx4AsAhd8760yyXb 1100w, https://miro.medium.com/v2/resize:fit:1400/0*fx4AsAhd8760yyXb 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*fx4AsAhd8760yyXb 640w, https://miro.medium.com/v2/resize:fit:720/0*fx4AsAhd8760yyXb 720w, https://miro.medium.com/v2/resize:fit:750/0*fx4AsAhd8760yyXb 750w, https://miro.medium.com/v2/resize:fit:786/0*fx4AsAhd8760yyXb 786w, https://miro.medium.com/v2/resize:fit:828/0*fx4AsAhd8760yyXb 828w, https://miro.medium.com/v2/resize:fit:1100/0*fx4AsAhd8760yyXb 1100w, https://miro.medium.com/v2/resize:fit:1400/0*fx4AsAhd8760yyXb 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="357" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><h1 id="60cf" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">Recap</h1><p id="9eb4" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">Deep learning compilers are complex with intricate inner workings that rival a swiss watch. In this blog post, I hope I provided you with a gentle and easy to follow primer on this topic and how these technologies power PyTorch 2.0.</p><figure class="nh ni nj nk nl nm ne nf paragraph-image"><div role="button" tabindex="0" class="nn no ff np bg nq"><div class="ne nf rc"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/0*17doYgsRQQThdi6a 640w, https://miro.medium.com/v2/resize:fit:720/0*17doYgsRQQThdi6a 720w, https://miro.medium.com/v2/resize:fit:750/0*17doYgsRQQThdi6a 750w, https://miro.medium.com/v2/resize:fit:786/0*17doYgsRQQThdi6a 786w, https://miro.medium.com/v2/resize:fit:828/0*17doYgsRQQThdi6a 828w, https://miro.medium.com/v2/resize:fit:1100/0*17doYgsRQQThdi6a 1100w, https://miro.medium.com/v2/resize:fit:1400/0*17doYgsRQQThdi6a 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*17doYgsRQQThdi6a 640w, https://miro.medium.com/v2/resize:fit:720/0*17doYgsRQQThdi6a 720w, https://miro.medium.com/v2/resize:fit:750/0*17doYgsRQQThdi6a 750w, https://miro.medium.com/v2/resize:fit:786/0*17doYgsRQQThdi6a 786w, https://miro.medium.com/v2/resize:fit:828/0*17doYgsRQQThdi6a 828w, https://miro.medium.com/v2/resize:fit:1100/0*17doYgsRQQThdi6a 1100w, https://miro.medium.com/v2/resize:fit:1400/0*17doYgsRQQThdi6a 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg nr ns c" width="700" height="398" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nt nu nv ne nf nw nx be b bf z dt">screenshot by author</figcaption></figure><ol class=""><li id="f2c3" class="ny nz gq oa b ho ob oc od hr oe of og qr oi oj ok qs om on oo qt oq or os ot qu qv qw bj">I started with a simple PyTorch function</li><li id="757f" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj">I showed how TorchDynamo captures the graph and represents it in FX IR</li><li id="536f" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj">I showed how AOTAutograd generates the backward pass graph, lowers PyTorch operators into Aten operators and represents it in an FX graph container.</li><li id="43af" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj">I discussed how Aten operators can be further decomposed into Core Aten IR and Prims IR that reduces the number of operators that other compilers can support without supporting the full PyTorch API list.</li><li id="646a" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot qu qv qw bj">I showed how TorchInductor performs operator fusion and generates optimized code for CPU and GPU targets</li></ol><p id="c8f7" class="pw-post-body-paragraph ny nz gq oa b ho ob oc od hr oe of og oh oi oj ok ol om on oo op oq or os ot gj bj">If you followed along you should be able to provide a high-level response to the following questions:</p><ul class=""><li id="5f5b" class="ny nz gq oa b ho ob oc od hr oe of og qr oi oj ok qs om on oo qt oq or os ot tc qv qw bj">What is a deep learning compiler?</li><li id="2bbd" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot tc qv qw bj">What does a PyTorch 2.0 compiler do when you call torch.compile()?</li><li id="25f4" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot tc qv qw bj">Why do we need a forward and backward pass graph ahead of time?</li><li id="c4df" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot tc qv qw bj">What are the different intermediate representations (IR) in PyTorch</li><li id="2e91" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot tc qv qw bj">What is the difference between ATen IR, Core ATen IR, Prims IR?</li><li id="443d" class="ny nz gq oa b ho qx oc od hr qy of og qr qz oj ok qs ra on oo qt rb or os ot tc qv qw bj">What is operator fusion and why is it important?</li></ul><h1 id="aca2" class="ou ov gq be ow ox oy hq oz pa pb ht pc pd pe pf pg ph pi pj pk pl pm pn po pp bj">Thank you for reading all the way to the end!</h1><p id="607f" class="pw-post-body-paragraph ny nz gq oa b ho pq oc od hr pr of og oh ps oj ok ol pt on oo op pu or os ot gj bj">If you found this article interesting, consider following me on medium to be notified when I publish new articles. Please also check out my other blog posts on <a class="af qq" href="https://medium.com/@shashankprasanna" rel="noopener">medium</a> or follow me on twitter (<a class="af qq" href="https://twitter.com/shshnkp" rel="noopener ugc nofollow" target="_blank">@shshnkp</a>), <a class="af qq" href="https://www.linkedin.com/in/shashankprasanna/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> or leave a comment below. Want me to write on a specific topic I’d love to hear from you!</p></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg fv fw fx fy"></div></div></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="te tf ab jo"><div class="qi ab"><a class="tg ax am ao" href="https://medium.com/tag/pytorch?source=post_page-----35132a85bd26---------------pytorch-----------------" rel="noopener follow"><div class="th ff cw ti tj tk tl be b bf z bj tm">Pytorch</div></a></div><div class="qi ab"><a class="tg ax am ao" href="https://medium.com/tag/deep-learning?source=post_page-----35132a85bd26---------------deep_learning-----------------" rel="noopener follow"><div class="th ff cw ti tj tk tl be b bf z bj tm">Deep Learning</div></a></div><div class="qi ab"><a class="tg ax am ao" href="https://medium.com/tag/machine-learning?source=post_page-----35132a85bd26---------------machine_learning-----------------" rel="noopener follow"><div class="th ff cw ti tj tk tl be b bf z bj tm">Machine Learning</div></a></div><div class="qi ab"><a class="tg ax am ao" href="https://medium.com/tag/gpu?source=post_page-----35132a85bd26---------------gpu-----------------" rel="noopener follow"><div class="th ff cw ti tj tk tl be b bf z bj tm">Gpu</div></a></div><div class="qi ab"><a class="tg ax am ao" href="https://medium.com/tag/deep-dives?source=post_page-----35132a85bd26---------------deep_dives-----------------" rel="noopener follow"><div class="th ff cw ti tj tk tl be b bf z bj tm">Deep Dives</div></a></div></div></div></div><div class="l"></div><footer class="tn to tp tq tr ts tt tu tv ab q tw iy c"><div class="l ae"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="ab co tx"><div class="ab q lj"><div class="ty l"><span class="l tz ua ub e d"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35132a85bd26&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=-----35132a85bd26---------------------clap_footer-----------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div></span><span class="l h g f uc ud"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F35132a85bd26&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=-----35132a85bd26---------------------clap_footer-----------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class="mc"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z dt"><span class="pw-responses-count mg mc">3</span></p></button></div></div></div></div><div class="ab q"><div class="ue l jl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F35132a85bd26&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af fg ah ai aj ak al mj an ao ap eu mk ml mm"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div></div><div class="ue l jl"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button class="af fg ah ai aj ak al mj an ao ap eu mn mo mf mp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="uf ug uh ui uj l bw"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="ck ab uk co"><div class="ab in"><a href="https://medium.com/@shashankprasanna?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><div class="l ul um bx un ir"><div class="l ff"><img alt="Shashank Prasanna" class="l fa bx uo up cw" src="https://miro.medium.com/v2/resize:fill:144:144/2*LXFHFkYQQR1tyNWoHIcSXQ.jpeg" width="72" height="72" loading="lazy"/><div class="is bx l uo up fo n it iu"></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><div class="uq ab ff"><div><div class="bl" aria-hidden="false"><div class="l ur us bx un iy"><div class="l ff"><img alt="Towards Data Science" class="l fa bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="32" height="32" loading="lazy"/><div class="is bx l by bz fo n it iu"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><span><a class="be b bf z el th em eo ep eq er es et eu ev ew ex ut ey ez fa bl fb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0c596ca35b5&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=post_page-e0c596ca35b5----35132a85bd26---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd48ce4d9cb5c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;newsletterV3=e0c596ca35b5&amp;newsletterV3Id=d48ce4d9cb5c&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=-----35132a85bd26---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z uv am uw ux uy uz va vb vc vd et eu ev ew ex ey ez fa bl fb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="uu us ur"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@shashankprasanna?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><h2 class="pw-author-name be ve vf vg vh bj"><span class="gj">Written by <!-- -->Shashank Prasanna</span></h2></a></div><div class="qi ab"><div class="l jl"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar je" href="https://medium.com/@shashankprasanna/followers?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow">720 Followers</a></span></div><div class="be b bf z jt ju jv ab jx jy jz ka dt jr"><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span class="l jl">Writer for </span><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b bf z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="vi l"><p class="be b bf z bj">Talking Engineer. Runner. Coffee Connoisseur. Formerly Machine learning @Meta, AWS, NVIDIA, MATLAB, posts are my own opinions. website: <a class="af ag ah ai aj ak al am an ao ap aq ar qq gk" href="http://shashankprasanna.com" rel="noopener  ugc nofollow">shashankprasanna.com</a></p></div></div><div class="h k"><div class="ab"><span><a class="be b bf z el th em eo ep eq er es et eu ev ew ex ut ey ez fa bl fb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe0c596ca35b5&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=post_page-e0c596ca35b5----35132a85bd26---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fd48ce4d9cb5c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26&amp;newsletterV3=e0c596ca35b5&amp;newsletterV3Id=d48ce4d9cb5c&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=-----35132a85bd26---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z uv am uw ux uy uz va vb vc vd et eu ev ew ex ey ez fa bl fb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="uu us ur"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="vj bg vk vl vm vn vo vp"></div></div></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="wa wb l"><h2 class="be ve jc z gp bj">More from <!-- -->Shashank Prasanna<!-- --> and Towards Data Science</h2></div><div class="wc ab lj jo wd we wf wg wh wi wj wk wl wm wn wo wp wq wr"><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86?source=author_recirc-----35132a85bd26----0---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo yp yq" src="https://miro.medium.com/v2/resize:fit:1358/1*qAx5CnFbebRR_bOyQbSGYw.png" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@shashankprasanna?source=author_recirc-----35132a85bd26----0---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="l ff"><img alt="Shashank Prasanna" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/2*LXFHFkYQQR1tyNWoHIcSXQ.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@shashankprasanna?source=author_recirc-----35132a85bd26----0---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Shashank Prasanna</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----35132a85bd26----0---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86?source=author_recirc-----35132a85bd26----0---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div title=""><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">Choosing the right GPU for deep learning on AWS</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">How to choose the right Amazon EC2 GPU instance for deep learning training and inference — from best performance to the most…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86?source=author_recirc-----35132a85bd26----0---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>25 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Jul 25, 2020</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd69c157d8c86&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=-----d69c157d8c86----0-----------------clap_footer----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86?source=author_recirc-----35132a85bd26----0---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">12</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd69c157d8c86&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchoosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86&amp;source=-----35132a85bd26----0-----------------bookmark_preview----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="vj bg vk abm"></div></div></div></div></div></div></div></article></div></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----35132a85bd26----1---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/1*rsp22rKwFDjiwwCcUly56Q.jpeg" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@jacob_marks?source=author_recirc-----35132a85bd26----1---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="l ff"><img alt="Jacob Marks, Ph.D." class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/0*YukZswf8UB1bQdTV" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@jacob_marks?source=author_recirc-----35132a85bd26----1---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Jacob Marks, Ph.D.</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----35132a85bd26----1---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----35132a85bd26----1---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div title=""><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">How I Turned My Company’s Docs into a Searchable Database with OpenAI</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">And how you can do the same with your docs</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----35132a85bd26----1---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><span class="be b du z dt"><div class="ab q"><span>15 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Apr 25</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&amp;user=Jacob+Marks%2C+Ph.D.&amp;userId=f7dc0c0eae92&amp;source=-----4f2d34bd8736----1-----------------clap_footer----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=author_recirc-----35132a85bd26----1---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">50</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&amp;source=-----35132a85bd26----1-----------------bookmark_preview----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="vj bg vk abm"></div></div></div></div></div></div></div></article></div></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/stop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f?source=author_recirc-----35132a85bd26----2---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/1*ARD8irFbRaBKRNlrFcL6HA.png" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://khuyentran1476.medium.com/?source=author_recirc-----35132a85bd26----2---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="l ff"><img alt="Khuyen Tran" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/2*tiQVZEZxHMPcnVmEmN7UtA.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://khuyentran1476.medium.com/?source=author_recirc-----35132a85bd26----2---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Khuyen Tran</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----35132a85bd26----2---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/stop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f?source=author_recirc-----35132a85bd26----2---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div title=""><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">Stop Hard Coding in a Data Science Project — Use Config Files Instead</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">And How to Efficiently Interact with Config Files in Python</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/stop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f?source=author_recirc-----35132a85bd26----2---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>6 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>May 26</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F479ac8ffc76f&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f&amp;user=Khuyen+Tran&amp;userId=84a02493194a&amp;source=-----479ac8ffc76f----2-----------------clap_footer----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/stop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f?source=author_recirc-----35132a85bd26----2---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">19</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F479ac8ffc76f&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f&amp;source=-----35132a85bd26----2-----------------bookmark_preview----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="vj bg vk abm"></div></div></div></div></div></div></div></article></div></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c?source=author_recirc-----35132a85bd26----3---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/1*AGpm_2l-32AfXUAfOxwUKA.png" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@shashankprasanna?source=author_recirc-----35132a85bd26----3---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="l ff"><img alt="Shashank Prasanna" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/2*LXFHFkYQQR1tyNWoHIcSXQ.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@shashankprasanna?source=author_recirc-----35132a85bd26----3---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Shashank Prasanna</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=author_recirc-----35132a85bd26----3---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c?source=author_recirc-----35132a85bd26----3---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><div title="A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon…"><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon…</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">Learn about CPUs, GPUs, AWS Inferentia, and Amazon Elastic Inference and how to choose the right AI accelerator for inference deployment</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c?source=author_recirc-----35132a85bd26----3---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------"><span class="be b du z dt"><div class="ab q"><span>26 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Oct 21, 2020</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7a5d6804ef1c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c&amp;user=Shashank+Prasanna&amp;userId=e0c596ca35b5&amp;source=-----7a5d6804ef1c----3-----------------clap_footer----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c?source=author_recirc-----35132a85bd26----3---------------------a846acb2_56e4_4ab2_967d_383bdc7168ac-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">4</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7a5d6804ef1c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c&amp;source=-----35132a85bd26----3-----------------bookmark_preview----a846acb2_56e4_4ab2_967d_383bdc7168ac-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="vj bg vk dj dk abo abp abq"></div><div class="ab jm jn abr abs abt"><a class="be b bf z bj th av abu abv abw lp abx es et eu aby abz aca ex acb acc acd ace acf ey ez fa bl fb" href="https://medium.com/@shashankprasanna?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><div class="l nu">See all from <!-- -->Shashank Prasanna</div></a><div class="acg ach aci acj ack acl acm acn aco ma l"><a class="be b bf z bj th av abu abv abw lp abx es et eu aby abz aca ex acb acc acd ace acf ey ez fa bl fb" href="https://towardsdatascience.com/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><div class="l nu">See all from <!-- -->Towards Data Science</div></a></div></div></div></div><div class="vj bg vk acp acq acr acs act"></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="acu acv l"><h2 class="be ve ox hq oz pa ht pc pd pf pg ph pj pk pl pn po bj">Recommended from Medium</h2><div class="nh ni nj nk nl l"><div class="wc ab lj jo wd we wf wg wh wi wj wk wl wm wn wo wp wq wr"><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/1*sP1YmfjnIc5zd5P00rWp-Q@2x.jpeg" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@iamleonie?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="l ff"><img alt="Leonie Monigatti" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*TTIl4oynrJyfIkLbC6fumA.png" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@iamleonie?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Leonie Monigatti</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><div title="10 Exciting Project Ideas Using Large Language Models (LLMs) for Your Portfolio"><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">10 Exciting Project Ideas Using Large Language Models (LLMs) for Your Portfolio</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">Learn how to build apps and showcase your skills with large language models (LLMs). Get started today!</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>11 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>May 15</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F970b7ab4cf9e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e&amp;user=Leonie+Monigatti&amp;userId=3a38da70d8dc&amp;source=-----970b7ab4cf9e----0-----------------clap_footer----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">9</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F970b7ab4cf9e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2F10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e&amp;source=-----35132a85bd26----0-----------------bookmark_preview----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="vj bg vk abm"></div></div></div></div></div></div></div></article></div></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><div class="yh yi yj yk yl"><img alt="Two stochastic parrots sitting on a chain of large language models: LangChain" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg" loading="lazy"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@iamleonie?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="l ff"><img alt="Leonie Monigatti" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*TTIl4oynrJyfIkLbC6fumA.png" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@iamleonie?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Leonie Monigatti</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><div title="Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered Applications"><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered Applications</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">A LangChain tutorial to build anything with large language models in Python</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>12 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Apr 25</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F95fc8898732c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c&amp;user=Leonie+Monigatti&amp;userId=3a38da70d8dc&amp;source=-----95fc8898732c----1-----------------clap_footer----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">19</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F95fc8898732c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgetting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c&amp;source=-----35132a85bd26----1-----------------bookmark_preview----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div><div class="vj bg vk acw"></div><h2 class="be ve jc z gp bj">Lists</h2><div class="abm l"><div class="cm ab lj jo wd we wf wg wh wi wj wk wl wm wn wo wp wq wr"><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@ben.putney/list/predictive-modeling-w-python-e3668ea008e1?source=read_next_recirc-----35132a85bd26--------------------------------" rel="noopener follow"><div class="add ade jt ab jl ff"><div class="ff ym acy bw acz"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/0*zsngbTOmFCy6sUCx.jpeg" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff ym acy bw ada adb"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*EPYpvWdUxGbCkbgwLUAarg.png" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff ym bw iy adc"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/0*4JkYIO0SWzjCCATB.jpg" width="48" height="48" loading="lazy" role="presentation"/></div></div></div><div class="aw l"><h2 class="be ve jc z jt qg jv jw qh jy ka gp bj">Predictive Modeling w/ Python</h2><div class="be b du z dt ab acx">18 stories<span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span>10<!-- --> <!-- -->saves</div></div></a></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@destingong/list/practical-guides-to-machine-learning-a877c2a39884?source=read_next_recirc-----35132a85bd26--------------------------------" rel="noopener follow"><div class="add ade jt ab jl ff"><div class="ff ym acy bw acz"><div class="ym ip jt l"><img alt="Principal Component Analysis for ML" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*swd_PY6vTCyPnsgBYoFZfA.png" width="48" height="48" loading="lazy"/></div></div><div class="ff ym acy bw ada adb"><div class="ym ip jt l"><img alt="Time Series Analysis" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*8sSAHftNwd_RNJ3k4VA0pA.png" width="48" height="48" loading="lazy"/></div></div><div class="ff ym bw iy adc"><div class="ym ip jt l"><img alt="deep learning cheatsheet for beginner" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*uNyD4yNMH-DnOel1wzxOOA.png" width="48" height="48" loading="lazy"/></div></div></div><div class="aw l"><h2 class="be ve jc z jt qg jv jw qh jy ka gp bj">Practical Guides to Machine Learning</h2><div class="be b du z dt ab acx">10 stories<span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span>22<!-- --> <!-- -->saves</div></div></a></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a?source=read_next_recirc-----35132a85bd26--------------------------------" rel="noopener follow"><div class="add ade jt ab jl ff"><div class="ff ym acy bw acz"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*jc4oIBokwfseuI-pmRIPPQ.png" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff ym acy bw ada adb"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*EDndx6q1g7C_doMhMAcOCg.png" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff ym bw iy adc"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*45J3OgIxjgMHUv892eYFvQ.png" width="48" height="48" loading="lazy" role="presentation"/></div></div></div><div class="aw l"><h2 class="be ve jc z jt qg jv jw qh jy ka gp bj">Natural Language Processing</h2><div class="be b du z dt ab acx">345 stories<span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span>7<!-- --> <!-- -->saves</div></div></a></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@MediumStaff/list/the-new-chatbots-chatgpt-bard-and-beyond-5969c7449b7f?source=read_next_recirc-----35132a85bd26--------------------------------" rel="noopener follow"><div class="add ade jt ab jl ff"><div class="ff ym acy bw acz"><div class="ym ip jt l"><img alt="Image by vectorjuice on FreePik" class="" src="https://miro.medium.com/v2/resize:fill:96:96/0*3OsUtsnlTx9Svm4c.jpg" width="48" height="48" loading="lazy"/></div></div><div class="ff ym acy bw ada adb"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*IPZF1hcDWwpPqOz2vL7NxQ.png" width="48" height="48" loading="lazy" role="presentation"/></div></div><div class="ff ym bw iy adc"><div class="ym ip jt l"><img alt="" class="" src="https://miro.medium.com/v2/resize:fill:96:96/1*0fHUKyg3xtpNWpop35PR4g.png" width="48" height="48" loading="lazy" role="presentation"/></div></div></div><div class="aw l"><h2 class="be ve jc z jt qg jv jw qh jy ka gp bj">The New Chatbots: ChatGPT, Bard, and Beyond</h2><div class="be b du z dt ab acx">13 stories<span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span>22<!-- --> <!-- -->saves</div></div></a></div></div></div><div class="vj bg vk ach dj acj dk adf adg adh adi adj adk"></div><div class="wc ab lj jo wd we wf wg wh wi wj wk wl wm wn wo wp wq wr"><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://levelup.gitconnected.com/introducing-pandasai-the-generative-ai-python-library-568a971af014?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/0*EMTJI76mLg61oPbv" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@araujogabe1?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="l ff"><img alt="Gabe Araujo, M.Sc." class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*OhLD6lqReaxOTPITf_3wcg@2x.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@araujogabe1?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Gabe Araujo, M.Sc.</p><div class="adl adm l"><div class="ab adn"><div class="ab"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M15.16 8c0 .65-.46 1.14-.86 1.57-.23.25-.47.5-.56.72-.1.22-.09.55-.1.88 0 .6-.01 1.3-.48 1.78-.48.48-1.16.5-1.75.5-.32 0-.65.01-.86.1-.2.07-.46.33-.7.57-.42.41-.9.88-1.54.88s-1.12-.47-1.54-.88a2.87 2.87 0 0 0-.7-.58c-.22-.09-.54-.08-.87-.09-.59 0-1.27-.02-1.74-.5s-.48-1.17-.49-1.78c0-.33-.01-.67-.1-.88-.07-.2-.32-.47-.55-.71-.4-.44-.87-.93-.87-1.58s.46-1.14.87-1.58c.23-.24.47-.5.56-.71.09-.22.08-.55.09-.88 0-.6.02-1.3.49-1.78s1.15-.5 1.74-.5c.33 0 .66-.01.86-.1.2-.08.47-.33.7-.57.43-.41.91-.88 1.55-.88.63 0 1.12.47 1.54.88.24.24.49.48.7.58.22.09.54.08.86.09.6 0 1.27.02 1.75.5.47.48.48 1.17.49 1.78 0 .33 0 .67.09.88.08.2.33.47.56.71.4.44.86.93.86 1.58z" fill="#437AFF"></path><path d="M7.33 10.5c.2 0 .38.08.52.22.13.14.21.33.21.53 0 .07.03.13.07.18a.24.24 0 0 0 .35 0 .25.25 0 0 0 .07-.18c0-.2.08-.39.22-.53a.73.73 0 0 1 .52-.22h1.96c.13 0 .25-.05.34-.15a.5.5 0 0 0 .15-.35V6a.5.5 0 0 0-.15-.35.48.48 0 0 0-.34-.15H9.78c-.33 0-.64.13-.87.37-.23.23-.36.55-.36.88v2.5c0 .07-.02.13-.07.18a.24.24 0 0 1-.35 0 .25.25 0 0 1-.07-.18v-2.5c0-.33-.13-.65-.36-.88a1.21 1.21 0 0 0-.86-.37H5.37a.48.48 0 0 0-.35.15.5.5 0 0 0-.14.35v4c0 .13.05.26.14.35.1.1.22.15.35.15h1.96z" fill="#fff"></path></svg></div></div></div></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://levelup.gitconnected.com/?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Level Up Coding</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://levelup.gitconnected.com/introducing-pandasai-the-generative-ai-python-library-568a971af014?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div title=""><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">🐼Introducing PandasAI: The Generative AI Python Library 🐼</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">Pandas AI is an additional Python library that enhances Pandas, the widely-used data analysis and manipulation tool, by incorporating…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://levelup.gitconnected.com/introducing-pandasai-the-generative-ai-python-library-568a971af014?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>9 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>May 16</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2F568a971af014&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fintroducing-pandasai-the-generative-ai-python-library-568a971af014&amp;user=Gabe+Araujo%2C+M.Sc.&amp;userId=a34b6e5225b0&amp;source=-----568a971af014----0-----------------clap_footer----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://levelup.gitconnected.com/introducing-pandasai-the-generative-ai-python-library-568a971af014?source=read_next_recirc-----35132a85bd26----0---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">13</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F568a971af014&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Fintroducing-pandasai-the-generative-ai-python-library-568a971af014&amp;source=-----35132a85bd26----0-----------------bookmark_preview----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="vj bg vk abm"></div></div></div></div></div></div></div></article></div></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/0*4ABoFdJClLr8QTK2" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@mattchapmanmsc?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="l ff"><img alt="Matt Chapman" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*4EQrg_kfWhQfHyGeuIunfg.png" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@mattchapmanmsc?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Matt Chapman</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://towardsdatascience.com/?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards Data Science</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><div title="How I Stay Up to Date With the Latest AI Trends as a Full-Time Data Scientist"><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">How I Stay Up to Date With the Latest AI Trends as a Full-Time Data Scientist</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">No, I don’t just ask ChatGPT to tell me</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>8 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>May 1</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1e535dd0cd79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79&amp;user=Matt+Chapman&amp;userId=bf7d13fc53db&amp;source=-----1e535dd0cd79----1-----------------clap_footer----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="/how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79?source=read_next_recirc-----35132a85bd26----1---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">25</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1e535dd0cd79&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79&amp;source=-----35132a85bd26----1-----------------bookmark_preview----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="vj bg vk abm"></div></div></div></div></div></div></div></article></div></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://pub.towardsai.net/how-to-read-machine-learning-papers-effectively-9c2df7906516?source=read_next_recirc-----35132a85bd26----2---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/0*sEYcttGKXNKEWR3e" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://youssefraafat57.medium.com/?source=read_next_recirc-----35132a85bd26----2---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="l ff"><img alt="Youssef Hosni" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*cBxasbWXomjJrHV2_Fh8zw.jpeg" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://youssefraafat57.medium.com/?source=read_next_recirc-----35132a85bd26----2---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Youssef Hosni</p></a></div></div></div><div class="yy l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://pub.towardsai.net/?source=read_next_recirc-----35132a85bd26----2---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Towards AI</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://pub.towardsai.net/how-to-read-machine-learning-papers-effectively-9c2df7906516?source=read_next_recirc-----35132a85bd26----2---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div title=""><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">How to Read Machine Learning Papers Effectively</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">The field of machine and deep learning is evolving very fast, and there are new research outputs every day. Therefore you will need to read…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://pub.towardsai.net/how-to-read-machine-learning-papers-effectively-9c2df7906516?source=read_next_recirc-----35132a85bd26----2---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>10 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Oct 9, 2022</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-artificial-intelligence%2F9c2df7906516&amp;operation=register&amp;redirect=https%3A%2F%2Fpub.towardsai.net%2Fhow-to-read-machine-learning-papers-effectively-9c2df7906516&amp;user=Youssef+Hosni&amp;userId=859af34925b7&amp;source=-----9c2df7906516----2-----------------clap_footer----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://pub.towardsai.net/how-to-read-machine-learning-papers-effectively-9c2df7906516?source=read_next_recirc-----35132a85bd26----2---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">7</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c2df7906516&amp;operation=register&amp;redirect=https%3A%2F%2Fpub.towardsai.net%2Fhow-to-read-machine-learning-papers-effectively-9c2df7906516&amp;source=-----35132a85bd26----2-----------------bookmark_preview----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="vj bg vk abm"></div></div></div></div></div></div></div></article></div></div><div class="ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm"><div class="xn xo xp xq xr dv l"><article class="dv"><div class="dv tv l"><div class="bg dv"><div class="dv l"><div class="dv xs xt xu xv xw xx xy xz ya yb yc yd ye"><div class="yf"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Image" href="https://medium.com/@iamleonie/understanding-llmops-large-language-model-operations-4253820922?source=read_next_recirc-----35132a85bd26----3---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="yh yi yj yk yl"><img alt="" class="bg ym yn yo abn yq" src="https://miro.medium.com/v2/resize:fit:1358/1*p-VVVzppuy-B87U8FfcHTA@2x.jpeg" loading="lazy" role="presentation"/></div></a></div><div class="yg ab ca cn"><div class="yr ys yt yu yv ab"><div class="tg l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@iamleonie?source=read_next_recirc-----35132a85bd26----3---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="l ff"><img alt="Leonie Monigatti" class="l fa bx yw yx cw" src="https://miro.medium.com/v2/resize:fill:40:40/1*TTIl4oynrJyfIkLbC6fumA.png" width="20" height="20" loading="lazy"/><div class="fn bx l yw yx fo n ax iu"></div></div></a></div></div></div><div class="yy l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar je ab q" href="https://medium.com/@iamleonie?source=read_next_recirc-----35132a85bd26----3---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><p class="be b du z jt ju jv jw jx jy jz ka bj">Leonie Monigatti</p></a></div></div></div></div><div class="yz za zb zc zd ze zf zg zh zi l gj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview Title" href="https://medium.com/@iamleonie/understanding-llmops-large-language-model-operations-4253820922?source=read_next_recirc-----35132a85bd26----3---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div title=""><h2 class="be gr ox hq zj zk oz pa ht zl zm pc oh se zn zo sf ol sh zp zq si op sk zr zs sl jt jv jw jy ka bj">Understanding LLMOps: Large Language Model Operations</h2></div><div class="zt l"><h3 class="be b jc z jt qg jv jw qh jy ka dt">How LLMs are changing the way we build AI-powered products and the landscape of MLOps</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Post Preview memebership and reading time information" href="https://medium.com/@iamleonie/understanding-llmops-large-language-model-operations-4253820922?source=read_next_recirc-----35132a85bd26----3---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="tv ab"><div class="bl" aria-hidden="false"><button class="l ax ao am"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>12 min read</span><span class="jf l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>May 2</span></div></span></a><div class="zu zv zw zx zy l"><div class="ab co"><div class="am zz aba abb abc abd abe abf abg abh abi ab q"><div class="ab q lj"><div class="pw-multi-vote-icon ff js lk ll lm"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4253820922&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40iamleonie%2Funderstanding-llmops-large-language-model-operations-4253820922&amp;user=Leonie+Monigatti&amp;userId=3a38da70d8dc&amp;source=-----4253820922----3-----------------clap_footer----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><div class="ln ao fg lo lp lq am lr ls lt lm"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="be b du z dt"><span class="mb">--</span></p></div></div><div class="abj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@iamleonie/understanding-llmops-large-language-model-operations-4253820922?source=read_next_recirc-----35132a85bd26----3---------------------fb9d4798_4576_4d7d_ad27_17c73f835d1f-------&amp;responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><div><div class="bl" aria-hidden="false"><button class="ao ln md me ab q fg lp mf" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mg mc">6</span></p></button></div></div></a></div></div><div class="ab q abk abl"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4253820922&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40iamleonie%2Funderstanding-llmops-large-language-model-operations-4253820922&amp;source=-----35132a85bd26----3-----------------bookmark_preview----fb9d4798_4576_4d7d_ad27_17c73f835d1f-------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mi"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="vj bg vk dj dk abo abp abq"></div><a class="be b bf z bj th av abu abv abw lp abx es et eu aby abz aca ex acb acc acd ace acf ey ez fa bl fb" href="https://medium.com/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><div class="l nu">See more recommendations</div></a></div></div></div><div class="h k j"><div class="vj bg vk vq"></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="vr ab lj jo"><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Help</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Status</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://about.medium.com/creators/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Writers</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Blog</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Careers</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Privacy</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Terms</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">About</p></a></div><div class="vs vt l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Text to speech</p></a></div><div class="vs l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----35132a85bd26--------------------------------" rel="noopener follow"><p class="be b du z dt">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20230621-203724-29e1406050"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"auroraPage":{"isAuroraPageEnabled":false},"cache":{"experimentGroupSet":true,"reason":"This request is not using the cache middleware worker","group":"disabled","tags":["group-edgeCachePosts","post-35132a85bd26","user-e0c596ca35b5","collection-7f60cf5620c9"],"serverVariantState":"","middlewareEnabled":false,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"inDisabledExperiment":false,"topicPortalsEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"7473ea05-092f-495c-aa9c-4be14715e566","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"341edcca1a9ecef5","ot-tracer-traceid":"502b8bb6b6b442f","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"config":{"nodeEnv":"production","version":"main-20230621-203724-29e1406050","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20230621-203724-29e1406050","commit":"29e14060503f2f372575a934ad9295b9390f4f48"}},"datacenter":"us"},"googleAnalyticsCode":"UA-24232453-2","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks: Juneteenth","catalogId":"14c7443645fd"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"variantFlags":[{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_edge_cache","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_follower_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bevy_rds_double_write","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"explicit_signals_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"lo_non_moc_upsell","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"enable_twitter_auth_suggestions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_stripe_plan_upgrades","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_monthly","valueType":{"__typename":"VariantFlagString","value":"10"}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"author_fair_distribution_non_qp3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"custom_moc_preview_weight_threshold","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"web_enable_syntax_highlighting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_easy_resubscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_user_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_plan_upgrades","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_generation_pipeline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_boosted_notification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_dashboard_referred_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_yearly","valueType":{"__typename":"VariantFlagString","value":"60"}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sanity_check_aa_experiment_2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_triton_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"35132a85bd26\"})":{"__ref":"Post:35132a85bd26"},"post({\"id\":\"35132a85bd26\"})":{"__ref":"Post:35132a85bd26"},"authorCollectionRecircFeed({\"input\":{\"authorId\":\"e0c596ca35b5\",\"collectionId\":\"7f60cf5620c9\",\"paging\":{\"limit\":4},\"postId\":\"35132a85bd26\"}})":{"__typename":"AuthorCollectionRecircFeedResult","items":[{"__typename":"HomeFeedItem","post":{"__ref":"Post:d69c157d8c86"},"feedId":"a846acb2-56e4-4ab2-967d-383bdc7168ac"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:4f2d34bd8736"},"feedId":"a846acb2-56e4-4ab2-967d-383bdc7168ac"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:479ac8ffc76f"},"feedId":"a846acb2-56e4-4ab2-967d-383bdc7168ac"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:7a5d6804ef1c"},"feedId":"a846acb2-56e4-4ab2-967d-383bdc7168ac"}]},"recirc({\"paging\":{\"limit\":6},\"postId\":\"35132a85bd26\"})":{"__typename":"RexRecircResult","items":[{"__typename":"RexRecircItem","feedId":"fb9d4798-4576-4d7d-ad27-17c73f835d1f","post":{"__ref":"Post:970b7ab4cf9e"}},{"__typename":"RexRecircItem","feedId":"fb9d4798-4576-4d7d-ad27-17c73f835d1f","post":{"__ref":"Post:95fc8898732c"}},{"__typename":"RexRecircItem","feedId":"fb9d4798-4576-4d7d-ad27-17c73f835d1f","post":{"__ref":"Post:568a971af014"}},{"__typename":"RexRecircItem","feedId":"fb9d4798-4576-4d7d-ad27-17c73f835d1f","post":{"__ref":"Post:1e535dd0cd79"}},{"__typename":"RexRecircItem","feedId":"fb9d4798-4576-4d7d-ad27-17c73f835d1f","post":{"__ref":"Post:9c2df7906516"}},{"__typename":"RexRecircItem","feedId":"fb9d4798-4576-4d7d-ad27-17c73f835d1f","post":{"__ref":"Post:4253820922"}}]},"postCatalogRecirc({\"pagingOptions\":{\"limit\":4},\"postId\":\"35132a85bd26\"})":{"__typename":"CatalogsConnection","catalogs":[{"__ref":"Catalog:e3668ea008e1"},{"__ref":"Catalog:a877c2a39884"},{"__ref":"Catalog:0a856388a93a"},{"__ref":"Catalog:5969c7449b7f"}]}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":{"__ref":"CustomStyleSheet:514038af8f2f"},"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:7e12c71dfa81"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:e6ad8abedec9"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:2155e1f99318"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:895063a310f4"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:29c9531ee6f5"}}],"name":"Towards Data Science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"domain":"towardsdatascience.com","slug":"towards-data-science","description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","subscriberCount":664552,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_ef872433409d"},"twitterUsername":"TDataScience","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","status":"ACTIVE","isSubdomain":false}},"creator":{"__ref":"User:7e12c71dfa81"},"ptsQualifiedAt":1616092952992},"CustomStyleSheet:514038af8f2f":{"__typename":"CustomStyleSheet","id":"514038af8f2f","global":{"__typename":"GlobalStyles","colorPalette":{"__typename":"StyleSheetColorPalette","primary":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}}},"background":null},"fonts":{"__typename":"StyleSheetFonts","font1":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font2":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font3":{"__typename":"StyleSheetFont","name":"SERIF_2"}}}},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81","atsQualifiedAt":1612205680542},"User:e6ad8abedec9":{"__typename":"User","id":"e6ad8abedec9"},"User:2155e1f99318":{"__typename":"User","id":"2155e1f99318"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4"},"User:29c9531ee6f5":{"__typename":"User","id":"29c9531ee6f5"},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"LinkedAccounts:e0c596ca35b5":{"__typename":"LinkedAccounts","mastodon":null,"id":"e0c596ca35b5"},"UserViewerEdge:userId:e0c596ca35b5-viewerId:lo_ef872433409d":{"__typename":"UserViewerEdge","id":"userId:e0c596ca35b5-viewerId:lo_ef872433409d","isFollowing":false,"isUser":false},"NewsletterV3:d48ce4d9cb5c":{"__typename":"NewsletterV3","id":"d48ce4d9cb5c","type":"NEWSLETTER_TYPE_AUTHOR","slug":"e0c596ca35b5","name":"e0c596ca35b5","collection":null,"user":{"__ref":"User:e0c596ca35b5"}},"User:e0c596ca35b5":{"__typename":"User","id":"e0c596ca35b5","name":"Shashank Prasanna","username":"shashankprasanna","newsletterV3":{"__ref":"NewsletterV3:d48ce4d9cb5c"},"linkedAccounts":{"__ref":"LinkedAccounts:e0c596ca35b5"},"isSuspended":false,"imageId":"2*LXFHFkYQQR1tyNWoHIcSXQ.jpeg","mediumMemberAt":0,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":720},"customDomainState":null,"hasSubdomain":false,"bio":"Talking Engineer. Runner. Coffee Connoisseur. Formerly Machine learning @Meta, AWS, NVIDIA, MATLAB, posts are my own opinions. website: shashankprasanna.com","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:e0c596ca35b5-viewerId:lo_ef872433409d"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"twitterScreenName":"","atsQualifiedAt":1612205492611},"Topic:1eca0103fff3":{"__typename":"Topic","slug":"machine-learning","id":"1eca0103fff3","name":"Machine Learning"},"Paragraph:ba9e2e578391_0":{"__typename":"Paragraph","id":"ba9e2e578391_0","name":"8b2a","type":"H3","href":null,"layout":null,"metadata":null,"text":"How Pytorch 2.0 Accelerates Deep Learning with Operator Fusion and CPU\u002FGPU Code-Generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_1":{"__typename":"Paragraph","id":"ba9e2e578391_1","name":"d316","type":"H4","href":null,"layout":null,"metadata":null,"text":"A primer on deep learning compiler technologies in PyTorch for graph capture, intermediate representations, operator fusion, and optimized C++ and GPU code generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*m3hHjaqAY_Rqwcvgfg4IoQ.png":{"__typename":"ImageMetadata","id":"1*m3hHjaqAY_Rqwcvgfg4IoQ.png","originalHeight":575,"originalWidth":1003,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_2":{"__typename":"Paragraph","id":"ba9e2e578391_2","name":"8277","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*m3hHjaqAY_Rqwcvgfg4IoQ.png"},"text":"illustration by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_3":{"__typename":"Paragraph","id":"ba9e2e578391_3","name":"f273","type":"P","href":null,"layout":null,"metadata":null,"text":"Computer programming is magical. We write code in human readable languages, and as though by magic, it gets translated into electric currents through silicon transistors making them behave like switches and allowing them to implement complex logic — just so we can enjoy cat videos on the internet. Between the programming language and hardware processors that run it, is an important piece of technology — the compiler. A compiler’s job is to translate and simplify our human readable language code into instructions that a processor understands.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_4":{"__typename":"Paragraph","id":"ba9e2e578391_4","name":"b65d","type":"P","href":null,"layout":null,"metadata":null,"text":"Compilers play a very important role in deep learning to improve training and inference performance, improve energy efficiency, and target diverse AI accelerator hardware. In this blog post I’m going to discuss deep learning compiler technologies that powers PyTorch 2.0. I’ll walk you through the different phases of the compilation process and discuss various underlying technologies with code examples and visualizations.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_5":{"__typename":"Paragraph","id":"ba9e2e578391_5","name":"f83b","type":"H3","href":null,"layout":null,"metadata":null,"text":"What is a deep learning compiler?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_6":{"__typename":"Paragraph","id":"ba9e2e578391_6","name":"77b2","type":"P","href":null,"layout":null,"metadata":null,"text":"A deep learning compiler translates high-level code written in deep learning frameworks into optimized lower level hardware specific code to accelerate training and inference. It finds opportunities in deep learning models to optimize for performance by performing layer and operator fusion, better memory planning, and generating target specific optimized fused kernels to reduce function call overhead.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*a1hW4NU7glf5AATR":{"__typename":"ImageMetadata","id":"0*a1hW4NU7glf5AATR","originalHeight":365,"originalWidth":945,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_7":{"__typename":"Paragraph","id":"ba9e2e578391_7","name":"17a9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*a1hW4NU7glf5AATR"},"text":"illustration by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_8":{"__typename":"Paragraph","id":"ba9e2e578391_8","name":"86af","type":"P","href":null,"layout":null,"metadata":null,"text":"Unlike traditional software compilers, deep learning compilers have to work with highly-parallelizable code often accelerated on specialized AI accelerator hardware (GPUs, TPUs, AWS Trainium\u002FInferentia, Intel Habana Gaudi etc.). To improve performance, a deep learning compiler has to take advantage of hardware specific features such as mixed precision support, performance optimized kernels and minimize communication between host (CPU) and AI accelerator.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_9":{"__typename":"Paragraph","id":"ba9e2e578391_9","name":"6c4a","type":"P","href":null,"layout":null,"metadata":null,"text":"While deep learning algorithms are continuing to advance at a rapid pace, hardware AI accelerators have also been evolving alongside to keep up with deep learning algorithm performance and efficiency needs. I discuss the co-evolution of algorithms and AI accelerators in an earlier blog post:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_10":{"__typename":"Paragraph","id":"ba9e2e578391_10","name":"76bb","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"AI accelerators, machine learning algorithms and their co-design and evolution\nEfficient algorithms and methods in machine learning for AI accelerators — NVIDIA GPUs, Intel Habana Gaudi and AWS…towardsdatascience.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":216,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fai-accelerators-machine-learning-algorithms-and-their-co-design-and-evolution-2676efd47179","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":78,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":79,"end":194,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fai-accelerators-machine-learning-algorithms-and-their-co-design-and-evolution-2676efd47179","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"1*SAgQSIEprO1looCxAdf52w.png"}},"Paragraph:ba9e2e578391_11":{"__typename":"Paragraph","id":"ba9e2e578391_11","name":"76a6","type":"P","href":null,"layout":null,"metadata":null,"text":"In this blog post I’ll focus on the software side of things, and particularly the subset of software closer to the hardware — deep learning compilers. First, let’s start by taking a look at different functions in a deep learning compiler.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_12":{"__typename":"Paragraph","id":"ba9e2e578391_12","name":"4a83","type":"H3","href":null,"layout":null,"metadata":null,"text":"Deep learning compiler in PyTorch 2.0","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_13":{"__typename":"Paragraph","id":"ba9e2e578391_13","name":"fd49","type":"P","href":null,"layout":null,"metadata":null,"text":"PyTorch 2.0 includes new compiler technologies to improve model performance and runtime efficiency and target diverse hardware backends with a simple API: torch.compile(). While other blog posts and articles have discussed performance benefits of PyTorch 2.0 in detail, here I’m going to focus on what happens under the hood when you invoke the PyTorch 2.0 compiler. If you’re looking for quantified performance benefits, you can find a performance dashboard of different models from huggingface, timm and torchbench.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":178,"end":194,"href":"https:\u002F\u002Fpytorch.org\u002Fget-started\u002Fpytorch-2.0\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":212,"end":222,"href":"https:\u002F\u002Fpytorch.org\u002Fblog\u002Fpytorch-2.0-release\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":437,"end":458,"href":"https:\u002F\u002Fgithub.com\u002Fpytorch\u002Fpytorch\u002Fissues\u002F93794","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_14":{"__typename":"Paragraph","id":"ba9e2e578391_14","name":"f7e7","type":"P","href":null,"layout":null,"metadata":null,"text":"At a high-level the default options for PyTorch 2.0 deep learning compiler performs the following key tasks:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_15":{"__typename":"Paragraph","id":"ba9e2e578391_15","name":"675b","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Graph capture: Computational graph representation for your models and functions. PyTorch technologies: TorchDynamo, Torch FX, FX IR","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_16":{"__typename":"Paragraph","id":"ba9e2e578391_16","name":"9406","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Automatic differentiation: Backward graph tracing using automatic differentiation and lowering to primitives operators. PyTorch technologies: AOTAutograd, Aten IR","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_17":{"__typename":"Paragraph","id":"ba9e2e578391_17","name":"a58b","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Optimizations: Forward and backward graph-level optimizations and operator fusion. PyTorch technologies: TorchInductor (default) or other compilers","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_18":{"__typename":"Paragraph","id":"ba9e2e578391_18","name":"143e","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Code generation: Generating hardware specific C++\u002FGPU Code. PyTorch technologies: TorchInductor, OpenAI Triton (default) other compilers","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_19":{"__typename":"Paragraph","id":"ba9e2e578391_19","name":"fba1","type":"P","href":null,"layout":null,"metadata":null,"text":"Through these steps, the compiler transforms your code and generates intermediate representations (IRs) that are progressively “lowered”. Lowering is a term in the compiler lexicon that refers to mapping a broad set of operations (such as supported by PyTorch API) to a narrow set of operations (such as supported by hardware) through automatic transformation and re-writing by the compiler. The PyTorch 2.0 compiler flow:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*RHLzCi133K-GjD1U":{"__typename":"ImageMetadata","id":"0*RHLzCi133K-GjD1U","originalHeight":589,"originalWidth":1036,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_20":{"__typename":"Paragraph","id":"ba9e2e578391_20","name":"2982","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*RHLzCi133K-GjD1U"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_21":{"__typename":"Paragraph","id":"ba9e2e578391_21","name":"a69b","type":"P","href":null,"layout":null,"metadata":null,"text":"If you are new to compiler terminology don’t let all of this scare you yet. I’m not a compiler engineer either. Keep reading and things will become clear as I’ll break the process down using a simple example and visualizations.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_22":{"__typename":"Paragraph","id":"ba9e2e578391_22","name":"8938","type":"H3","href":null,"layout":null,"metadata":null,"text":"A walk through the torch.compile() compiler process","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":19,"end":34,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_23":{"__typename":"Paragraph","id":"ba9e2e578391_23","name":"7ffb","type":"P","href":null,"layout":null,"metadata":null,"text":"Note: This whole walkthrough is in a Jupyter Notebook hosted here","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":37,"end":65,"href":"https:\u002F\u002Fgithub.com\u002Fshashankprasanna\u002Fpytorch-examples\u002Fblob\u002Fmain\u002Fpytorch-compile-blogpost\u002Ftorch-compile-under-the-hood.ipynb","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_24":{"__typename":"Paragraph","id":"ba9e2e578391_24","name":"3b6e","type":"P","href":null,"layout":null,"metadata":null,"text":"For the sake of simplicity, I’ll define a very simple function and run it through the PyTorch 2.0 compiler process. You can replace this function with a deep neural network model or an nn.Module subclass, but this example should help you appreciate what’s going on under the hood much better than a complex multi-million parameter model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*liAw71ABihW7bz7M":{"__typename":"ImageMetadata","id":"0*liAw71ABihW7bz7M","originalHeight":62,"originalWidth":454,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_25":{"__typename":"Paragraph","id":"ba9e2e578391_25","name":"509f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*liAw71ABihW7bz7M"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_26":{"__typename":"Paragraph","id":"ba9e2e578391_26","name":"dc1f","type":"P","href":null,"layout":null,"metadata":null,"text":"PyTorch code for that function:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_27":{"__typename":"Paragraph","id":"ba9e2e578391_27","name":"588a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def f(x):\n  return torch.sin(x)**2 + torch.cos(x)**2","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_28":{"__typename":"Paragraph","id":"ba9e2e578391_28","name":"4c95","type":"P","href":null,"layout":null,"metadata":null,"text":"If you paid attention in high-school trigonometry class, you know that the value of our function is always going to be 1 for all real valued x. Which means it’s derivative, a derivative of a constant, and must be equal to zero. This will come in handy to verify what the function and its derivatives are doing.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_29":{"__typename":"Paragraph","id":"ba9e2e578391_29","name":"4be5","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, it’s time to call torch.compile() . First let’s convince ourselves that compiling this function doesn’t change its output. For the same 1x1000 random vector the mean squared error between the output of our function and a vector of 1s should be zero for both the compiled and the uncompiled function (under some error tolerance).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":23,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*96eA9Gw2_gXvuJfD":{"__typename":"ImageMetadata","id":"0*96eA9Gw2_gXvuJfD","originalHeight":589,"originalWidth":1373,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_30":{"__typename":"Paragraph","id":"ba9e2e578391_30","name":"fe51","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*96eA9Gw2_gXvuJfD"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_31":{"__typename":"Paragraph","id":"ba9e2e578391_31","name":"7c12","type":"P","href":null,"layout":null,"metadata":null,"text":"All we did was add a single line of extra code torch.compile() to invoke our compiler. Let’s now take a look at what’s happening under the hood at each stage.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":47,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_32":{"__typename":"Paragraph","id":"ba9e2e578391_32","name":"f8a1","type":"H3","href":null,"layout":null,"metadata":null,"text":"Graph capture: Computational graph representation for your PyTorch models or functions","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_33":{"__typename":"Paragraph","id":"ba9e2e578391_33","name":"3a23","type":"P","href":null,"layout":null,"metadata":null,"text":"PyTorch technologies: TorchDynamo, FX Graphs, FX IR","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_34":{"__typename":"Paragraph","id":"ba9e2e578391_34","name":"8930","type":"P","href":null,"layout":null,"metadata":null,"text":"The first step for the compiler is to determine what to compile. Enter TorchDynamo. TorchDynamo intercepts the execution of your Python code and transforms it into FX intermediate representation (IR), and stores it in a special data structure called FX Graph. What does this look like you ask? Glad you asked. Below, we’ll take a looks the code we use to generate this, but here is the transformation and output:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*dynQHA0FTypCdlYm":{"__typename":"ImageMetadata","id":"0*dynQHA0FTypCdlYm","originalHeight":594,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_35":{"__typename":"Paragraph","id":"ba9e2e578391_35","name":"f97f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*dynQHA0FTypCdlYm"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_36":{"__typename":"Paragraph","id":"ba9e2e578391_36","name":"3641","type":"P","href":null,"layout":null,"metadata":null,"text":"It’s important to note that Torch FX graphs are just containers for IR and don’t really specify what operators it should hold. In the next section we’ll see the FX graph container come up again with a different set of IRs. If you compare the function code and FX IR there’s very little difference between the two. In fact, it’s the same PyTorch code you wrote, but laid out in a format that the FX graph data structure expects. They both will provide the same result when executed.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_37":{"__typename":"Paragraph","id":"ba9e2e578391_37","name":"3781","type":"P","href":null,"layout":null,"metadata":null,"text":"If you call torch.compile() without any arguments, it’ll use the default settings which runs the entire compiler stack which includes the default hardware backend compiler called TorchInductor. But we’d be jumping ahead if we discussed TorchInductor now, so let’s park that topic for now, and we’ll come back to it when we’re ready. First we need to discuss graph capture and we can do that by intercepting the calls from torch.compile(). Here’s how we’ll do that: torch.compile() allows you to provide your own compiler too, but because I’m not a compiler engineer, and I don’t have the slightest clue how to write a compiler, I’ll provide a fake compiler function to capture the FX graph IR that TorchDynamo generates.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_38":{"__typename":"Paragraph","id":"ba9e2e578391_38","name":"c265","type":"P","href":null,"layout":null,"metadata":null,"text":"Below is our fake compiler backend function called inspect_backend to torch.compile() and within that function I do two things:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_39":{"__typename":"Paragraph","id":"ba9e2e578391_39","name":"3632","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Print the FX IR code that was captured by TorchDynamo","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_40":{"__typename":"Paragraph","id":"ba9e2e578391_40","name":"7b55","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Save the FX graph visualization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:293521e54190d80aeb1654585590e898":{"__typename":"MediaResource","id":"293521e54190d80aeb1654585590e898","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"Paragraph:ba9e2e578391_41":{"__typename":"Paragraph","id":"ba9e2e578391_41","name":"8c15","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:293521e54190d80aeb1654585590e898"}},"mixtapeMetadata":null},"Paragraph:ba9e2e578391_42":{"__typename":"Paragraph","id":"ba9e2e578391_42","name":"8e3c","type":"P","href":null,"layout":null,"metadata":null,"text":"The output of that above code snippet are the FX IR code and the graph diagram showing our function sin^2(x)+cos^2(x)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":100,"end":117,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*yLlH36oYOsG-7_UN":{"__typename":"ImageMetadata","id":"0*yLlH36oYOsG-7_UN","originalHeight":837,"originalWidth":1330,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_43":{"__typename":"Paragraph","id":"ba9e2e578391_43","name":"5c02","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*yLlH36oYOsG-7_UN"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_44":{"__typename":"Paragraph","id":"ba9e2e578391_44","name":"1056","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that our fake compiler inspect_backend function is only invoked when we call the compiled function with some data i.e. when we call compiled_model(x). In the above code snippet, we’re only evaluating the function or in deep learning terminology, doing a “forward-pass”. In the next section we’ll take advantage of the PyTorch’s automatic differentiation engine called torch.autograd to compute the derivative and the “backward-pass” graph.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":137,"end":154,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_45":{"__typename":"Paragraph","id":"ba9e2e578391_45","name":"f05b","type":"H3","href":null,"layout":null,"metadata":null,"text":"Automatic differentiation: Forward and backward computational graphs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_46":{"__typename":"Paragraph","id":"ba9e2e578391_46","name":"7f6a","type":"P","href":null,"layout":null,"metadata":null,"text":"PyTorch technologies: AOTAutograd, Core Aten IR","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_47":{"__typename":"Paragraph","id":"ba9e2e578391_47","name":"afb1","type":"P","href":null,"layout":null,"metadata":null,"text":"TorchDynamo gave us the forward pass function evaluation as an FX graph, but what about the backward pass? For the sake of completeness, I’m going to digress from our primary topic and talk a bit about why we need to evaluate the gradients of a function with respect to its weights. If you’re already familiar with how mathematical optimization works skip this immediate section.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_48":{"__typename":"Paragraph","id":"ba9e2e578391_48","name":"5f8b","type":"H4","href":null,"layout":null,"metadata":null,"text":"What is backward pass and backward graph?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_49":{"__typename":"Paragraph","id":"ba9e2e578391_49","name":"9992","type":"P","href":null,"layout":null,"metadata":null,"text":"The “learning” part of deep learning and machine learning is a mathematical optimization problem which is simply stated as: Find the value of a variable w that yields the lowest value of some function of w. Or more succinctly:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*E99X6t0uLFW15wBiIJzUsw.png":{"__typename":"ImageMetadata","id":"1*E99X6t0uLFW15wBiIJzUsw.png","originalHeight":84,"originalWidth":340,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_50":{"__typename":"Paragraph","id":"ba9e2e578391_50","name":"0620","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*E99X6t0uLFW15wBiIJzUsw.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_51":{"__typename":"Paragraph","id":"ba9e2e578391_51","name":"c825","type":"P","href":null,"layout":null,"metadata":null,"text":"In machine learning f(w) is the loss function parametrized by weights. f(w) can be more clearly represented as some measure of error between the training labels and the model’s prediction labels based on the training data:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*3U_yTT5OHnFPjUJs":{"__typename":"ImageMetadata","id":"0*3U_yTT5OHnFPjUJs","originalHeight":114,"originalWidth":1214,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_52":{"__typename":"Paragraph","id":"ba9e2e578391_52","name":"1390","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*3U_yTT5OHnFPjUJs"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_53":{"__typename":"Paragraph","id":"ba9e2e578391_53","name":"5dd7","type":"P","href":null,"layout":null,"metadata":null,"text":"Turns out, if we can calculate the “rate of reduction” of loss with respect to weights, we can update our weights to move one step closer to a smaller and smaller loss f(w). In other words, we must move closer to a model that better fits our training dataset. We can find next values of weights by calculating the steepest slope of the loss f(w) at a given w and perturb w to head in that direction. The slope of a function with respect to the weights, is its derivative with respect to the weights. Since there are more than one weight values, the derivative becomes a vector quantity called the gradient which is a vector of partial derivatives with components for each weight. The weights w are perturbed at each iteration by some function g() of the gradients as follows:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*Lm8u9ZHiyDyIPcgF":{"__typename":"ImageMetadata","id":"0*Lm8u9ZHiyDyIPcgF","originalHeight":66,"originalWidth":376,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_54":{"__typename":"Paragraph","id":"ba9e2e578391_54","name":"f952","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*Lm8u9ZHiyDyIPcgF"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_55":{"__typename":"Paragraph","id":"ba9e2e578391_55","name":"7e58","type":"P","href":null,"layout":null,"metadata":null,"text":"Where the function g(.) depends on the optimizer (e.g. sgd, sgdm, rmsprop, adam etc.).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_56":{"__typename":"Paragraph","id":"ba9e2e578391_56","name":"bd79","type":"P","href":null,"layout":null,"metadata":null,"text":"For SGD the weight update step becomes:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*JUk04O0RfHzlDgK6":{"__typename":"ImageMetadata","id":"0*JUk04O0RfHzlDgK6","originalHeight":65,"originalWidth":380,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_57":{"__typename":"Paragraph","id":"ba9e2e578391_57","name":"b24d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*JUk04O0RfHzlDgK6"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_58":{"__typename":"Paragraph","id":"ba9e2e578391_58","name":"f743","type":"H4","href":null,"layout":null,"metadata":null,"text":"How does PyTorch 2.0 trace the backward pass graph?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":51,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_59":{"__typename":"Paragraph","id":"ba9e2e578391_59","name":"b06b","type":"P","href":null,"layout":null,"metadata":null,"text":"First let’s calculate what we expect the backward pass graph should look like and then compare it with what PyTorch generates. For our simple function, the forward graph and the backward graph should implement the following function. If sin and cos bother you, you can imagine f(x) being the loss function applied to a neural network.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*q5Ia6sZqz6dQ5_6h":{"__typename":"ImageMetadata","id":"0*q5Ia6sZqz6dQ5_6h","originalHeight":161,"originalWidth":1034,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_60":{"__typename":"Paragraph","id":"ba9e2e578391_60","name":"dfb0","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*q5Ia6sZqz6dQ5_6h"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_61":{"__typename":"Paragraph","id":"ba9e2e578391_61","name":"f6fb","type":"P","href":null,"layout":null,"metadata":null,"text":"PyTorch uses reverse-mode automatic differentiation to compute the gradients, and PyTorch’s implementation of automation differentiation is called Autograd. PyTorch 2.0 introduces AOTAutograd which traces the forward and backward graph ahead of time, i.e. prior to execution, and generates a joint forward and backward graph. It then partitions the forward and the backward graph into two separate graphs. Both the forward and the backward graphs are stored in the FX graph data structure and can be visualized as shown below.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":26,"end":51,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FAutomatic_differentiation","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*xoGZ022j8SEMGofJ":{"__typename":"ImageMetadata","id":"0*xoGZ022j8SEMGofJ","originalHeight":919,"originalWidth":1371,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_62":{"__typename":"Paragraph","id":"ba9e2e578391_62","name":"2760","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*xoGZ022j8SEMGofJ"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_63":{"__typename":"Paragraph","id":"ba9e2e578391_63","name":"8b6a","type":"P","href":null,"layout":null,"metadata":null,"text":"You can verify that the math checks out by working through the nodes on the graph. AOTAutograd generated backward pass indeed computes the derivative shown in the equation I shared earlier, which should equal zero since the original function only produces the identity.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_64":{"__typename":"Paragraph","id":"ba9e2e578391_64","name":"1433","type":"P","href":null,"layout":null,"metadata":null,"text":"We’ll now run AOTAutograd by extending our fake compiler function inspect_backend to call AOTAutograd and generate our backward graph. The updated inspect_backed defines a forward (fw) and backward (bw) compiler capture function that reads the forward and backward graph from AOTAutograd and prints the lowered ATen IR and saves the FX graph for the forward and backward graphs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:9aa2acbe3ed336a2e17a48b97cf6a695":{"__typename":"MediaResource","id":"9aa2acbe3ed336a2e17a48b97cf6a695","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"Paragraph:ba9e2e578391_65":{"__typename":"Paragraph","id":"ba9e2e578391_65","name":"0757","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:9aa2acbe3ed336a2e17a48b97cf6a695"}},"mixtapeMetadata":null},"Paragraph:ba9e2e578391_66":{"__typename":"Paragraph","id":"ba9e2e578391_66","name":"c0e9","type":"P","href":null,"layout":null,"metadata":null,"text":"This will generate the following forward AND backward graphs. Notice that the forward graph also looks slightly different from what we saw earlier in Figure x. For example torch.sin(x) in the FX graph IR and in our original code has been replaced by torch.ops.aten.sin.default(). What’s this funny thing called aten, you might ask, if you’re not already familiar with it. ATen stands for A Tensor library, which is a very creatively named low level library with a C++ interface that implements many of the fundamental operations that run on CPU and GPU.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_67":{"__typename":"Paragraph","id":"ba9e2e578391_67","name":"e678","type":"P","href":null,"layout":null,"metadata":null,"text":"In eager mode operation, your PyTorch operations are routed to this library which then calls the appropriate CPU or GPU implementation. AOTAutograd automatically generates code that replaces the higher level PyTorch API with ATen IR for the forward and backward graph which you can see in the output below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*GkmAQooTat3ZRpsx":{"__typename":"ImageMetadata","id":"0*GkmAQooTat3ZRpsx","originalHeight":732,"originalWidth":1223,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_68":{"__typename":"Paragraph","id":"ba9e2e578391_68","name":"fba6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*GkmAQooTat3ZRpsx"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_69":{"__typename":"Paragraph","id":"ba9e2e578391_69","name":"dac2","type":"P","href":null,"layout":null,"metadata":null,"text":"You can also see that in addition to the output of the forward pass, the forward graph outputs some additional tensors [add, sin, cos, primals_1] . These tensors are saved for the backward pass for gradient calculation. You can also see this in the computational graphs for the forward and backward pass in the figure shared earlier.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_70":{"__typename":"Paragraph","id":"ba9e2e578391_70","name":"21e2","type":"H3","href":null,"layout":null,"metadata":null,"text":"What are the different types of IR in PyTorch?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_71":{"__typename":"Paragraph","id":"ba9e2e578391_71","name":"df49","type":"P","href":null,"layout":null,"metadata":null,"text":"ATen IR is a list of operators supported by the ATen library as we discussed in the previous section, and you can see the full list of operations implemented in ATen library here. There are two other IR concepts in PyTorch you should be aware of: 1\u002F Core Aten IR 2\u002F Prims IR. Core Aten IR is a subset of the broader Aten IR and Prims IR and an even smaller subset of Core Aten IR. Let’s say you are designing a processor and want to support PyTorch code acceleration on your hardware. It’d be near impossible to support the full list of PyTorch API in hardware, so what you can do is build a compiler that only supports the smaller subset of fundamental operators defined in Core Aten IR or Prims IR, and let AOTAutograd decompose compound operators into the core operators as we’ll see in the next section.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":161,"end":178,"href":"https:\u002F\u002Fpytorch.org\u002Fcppdocs\u002Fapi\u002Fnamespace_at.html","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_72":{"__typename":"Paragraph","id":"ba9e2e578391_72","name":"5d2c","type":"H3","href":null,"layout":null,"metadata":null,"text":"What’s the difference between ATen IR, Core ATen IR, Prims IR?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*08kXPkgYt-RuI1rV":{"__typename":"ImageMetadata","id":"0*08kXPkgYt-RuI1rV","originalHeight":520,"originalWidth":751,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_73":{"__typename":"Paragraph","id":"ba9e2e578391_73","name":"679a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*08kXPkgYt-RuI1rV"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_74":{"__typename":"Paragraph","id":"ba9e2e578391_74","name":"a7a5","type":"P","href":null,"layout":null,"metadata":null,"text":"Core Aten IR (formerly canonical Aten IR) is a subset of the Aten IR that can be used to compose all other operators in the Aten IR. Compilers that target specific hardware accelerators can focus on supporting only the Core Aten IR and mapping it to their low level hardware API. This makes it easier to add hardware support to PyTorch since they don’t have to implement support for the full PyTorch API which will continue to grow with more and more abstractions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":12,"href":"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Fir.html#core-aten-ir","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_75":{"__typename":"Paragraph","id":"ba9e2e578391_75","name":"0dea","type":"P","href":null,"layout":null,"metadata":null,"text":"Prims IR is an even smaller subset of the Core Aten IR that further decomposes Core Aten IR ops into fundamental operations making it even easier for compilers that target specific hardware to support PyTorch. But decomposing operators into lower and lower operations will most definitely lead to performance degradation due to excess memory writes and function call overhead. But the expectation is that hardware compilers can take these operators and fuse them back together to support hardware API to get back performance.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":8,"href":"https:\u002F\u002Fpytorch.org\u002Fdocs\u002Fstable\u002Fir.html#prims-ir","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_76":{"__typename":"Paragraph","id":"ba9e2e578391_76","name":"296a","type":"P","href":null,"layout":null,"metadata":null,"text":"While we don’t need to further decompose our function into Core Aten IR and Prims IR I’ll demonstrate how below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_77":{"__typename":"Paragraph","id":"ba9e2e578391_77","name":"cc1a","type":"H3","href":null,"layout":null,"metadata":null,"text":"(Optional topic) Decomposition to Core Aten IR and Prims IR","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_78":{"__typename":"Paragraph","id":"ba9e2e578391_78","name":"b825","type":"P","href":null,"layout":null,"metadata":null,"text":"If you’re designing hardware or hardware compilers, it’d be near impossible to support the full list of PyTorch API in hardware, especially given the pace at which deep learning and AI are advancing. But the advantage for a hardware designer is that most deep learning functionality can be mapped into very few basic mathematical operations and the most computationally intensive ones are matrix-matrix and matrix-vector operations. Compound operators like those supported by PyTorch API can be decomposed into these fundamental operations using AOTAutograd as we’ll discuss in this section. If you don’t deal with low level hardware, you can skip this section.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_79":{"__typename":"Paragraph","id":"ba9e2e578391_79","name":"c3ad","type":"P","href":null,"layout":null,"metadata":null,"text":"You can update the AOTAutograd function to pass in a dictionary of decompositions that can lower the Aten IR into Core Aten IR and Prims IR. I’ll only share the relevant code snippet and output here since you can find the full notebook on GitHub. By default operators are not decomposed into Core Aten IR or Prims IR, but you can pass a dictionary of decompositions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_80":{"__typename":"Paragraph","id":"ba9e2e578391_80","name":"ddf6","type":"P","href":null,"layout":null,"metadata":null,"text":"In the code snippet below, I’ve converted our function f into a loss function f_loss by including the computation of mean squared error (MSE) into our function. I’m doing this to demonstrate how AOTAutograd can decompose MSE into its fundamental operators.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*57O6alQXLfSRFf16":{"__typename":"ImageMetadata","id":"0*57O6alQXLfSRFf16","originalHeight":550,"originalWidth":898,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_81":{"__typename":"Paragraph","id":"ba9e2e578391_81","name":"b1b8","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*57O6alQXLfSRFf16"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_82":{"__typename":"Paragraph","id":"ba9e2e578391_82","name":"7def","type":"P","href":null,"layout":null,"metadata":null,"text":"The output of the decomposition is that mse_loss gets decomposed into more fundamental operations: subtract , power(2) , mean.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*dy_DIS_oy-WdQKCD":{"__typename":"ImageMetadata","id":"0*dy_DIS_oy-WdQKCD","originalHeight":701,"originalWidth":1198,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_83":{"__typename":"Paragraph","id":"ba9e2e578391_83","name":"9d91","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*dy_DIS_oy-WdQKCD"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_84":{"__typename":"Paragraph","id":"ba9e2e578391_84","name":"a49f","type":"P","href":null,"layout":null,"metadata":null,"text":"This is because MSE or mean square error between two vectors x and y is defined as the following which only needs those 3 operations subtract, where power is an element-wise operation. If you write a compiler for your hardware, you likely already support these 3 operations and by decomposition your PyTorch code would run without further modifications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*VsqNyQSzZ3BkGLx0":{"__typename":"ImageMetadata","id":"0*VsqNyQSzZ3BkGLx0","originalHeight":77,"originalWidth":399,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_85":{"__typename":"Paragraph","id":"ba9e2e578391_85","name":"165a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*VsqNyQSzZ3BkGLx0"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_86":{"__typename":"Paragraph","id":"ba9e2e578391_86","name":"5294","type":"P","href":null,"layout":null,"metadata":null,"text":"You can also see this reflected in the FX graph visualization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*b7gdHy_XZ3sBuoFI":{"__typename":"ImageMetadata","id":"0*b7gdHy_XZ3sBuoFI","originalHeight":1600,"originalWidth":1556,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_87":{"__typename":"Paragraph","id":"ba9e2e578391_87","name":"9f29","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*b7gdHy_XZ3sBuoFI"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_88":{"__typename":"Paragraph","id":"ba9e2e578391_88","name":"0ca6","type":"P","href":null,"layout":null,"metadata":null,"text":"Now let’s decompose it further into Prims IR which is a much smaller subset of ~250 operators. Again, I’ll only share the relevant code snippet and output here since you can find the full notebook on GitHub.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*kCulwywR5xzP8xwl":{"__typename":"ImageMetadata","id":"0*kCulwywR5xzP8xwl","originalHeight":644,"originalWidth":879,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_89":{"__typename":"Paragraph","id":"ba9e2e578391_89","name":"f934","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*kCulwywR5xzP8xwl"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_90":{"__typename":"Paragraph","id":"ba9e2e578391_90","name":"abde","type":"P","href":null,"layout":null,"metadata":null,"text":"The output of the prim IR decomposition is below. All the aten ops in RED are replaced or decomposed to use prim operators in green.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*jviXTeQJMK0SvcKd":{"__typename":"ImageMetadata","id":"0*jviXTeQJMK0SvcKd","originalHeight":257,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_91":{"__typename":"Paragraph","id":"ba9e2e578391_91","name":"282f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*jviXTeQJMK0SvcKd"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_92":{"__typename":"Paragraph","id":"ba9e2e578391_92","name":"a6da","type":"H3","href":null,"layout":null,"metadata":null,"text":"Graph optimization: Layer and operator fusion and C++\u002FGPU code generation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_93":{"__typename":"Paragraph","id":"ba9e2e578391_93","name":"2813","type":"P","href":null,"layout":null,"metadata":null,"text":"PyTorch technologies discussed: TorchInductor, OpenAI Triton (default) other compilers","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_94":{"__typename":"Paragraph","id":"ba9e2e578391_94","name":"f9d5","type":"P","href":null,"layout":null,"metadata":null,"text":"In this final section of the blog post we’ll discuss operator fusion and automatic code generation for CPUs and GPUs using TorchInductor. First some basics:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_95":{"__typename":"Paragraph","id":"ba9e2e578391_95","name":"d1a9","type":"H4","href":null,"layout":null,"metadata":null,"text":"What is a deep learning optimizing compiler?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_96":{"__typename":"Paragraph","id":"ba9e2e578391_96","name":"39f4","type":"P","href":null,"layout":null,"metadata":null,"text":"An optimizing compiler for deep learning is good at finding performance gaps in code and addressing them by transforming the code to reduce code attributes such as memory access, kernel launches, data layout optimizations for a target backend. TorchInductor is the default optimizing compiler with torch.compile() that can generate optimized kernels for GPUs using OpenAI Triton and CPUs using OpenMP pragma directives.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_97":{"__typename":"Paragraph","id":"ba9e2e578391_97","name":"f4b9","type":"H4","href":null,"layout":null,"metadata":null,"text":"What is operator fusion in deep learning?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_98":{"__typename":"Paragraph","id":"ba9e2e578391_98","name":"a7ea","type":"P","href":null,"layout":null,"metadata":null,"text":"Deep learning is composed of many fundamental operations such as matrix-matrix and matrix-vector multiplications. In PyTorch eager mode of execution each operation will result in separate function calls or kernel launches on hardware. This leads to CPU overhead of launching kernels and results in more memory reads and writes between kernel launches. A deep learning optimizing compiler like TorchInductor can fuse multiple operations into a single compound operator in python and generate low-level GPU kernels or C++\u002FOpenMP code for it. This results in faster computation due to fewer kernel launches and fewer memory read\u002Fwrites.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*y-UZc2j1yJQxZHIC":{"__typename":"ImageMetadata","id":"0*y-UZc2j1yJQxZHIC","originalHeight":700,"originalWidth":912,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_99":{"__typename":"Paragraph","id":"ba9e2e578391_99","name":"4c40","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*y-UZc2j1yJQxZHIC"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_100":{"__typename":"Paragraph","id":"ba9e2e578391_100","name":"a033","type":"P","href":null,"layout":null,"metadata":null,"text":"The computational graph from the output of AOTAutograd in the previous section is composed of many Aten operators represented in an FX graph. TorchInductor optimizations doesn’t change the underlying computation in the graph but merely restructures it with operator and layer fusion, and generates CPU or GPU code for it. Since TorchInductor can see the full forward and backward computational graph ahead of time, it can take decisions on out-of-order execution of operations that don’t have dependence on each other, and maximize hardware resource utilization.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_101":{"__typename":"Paragraph","id":"ba9e2e578391_101","name":"5116","type":"P","href":null,"layout":null,"metadata":null,"text":"Under the hood, for GPU targets, TorchInductor uses OpenAI’s Triton to generate fused GPU kernels. Triton itself is a separate Python based framework and compiler for writing optimized low-level GPU code which is otherwise written in CUDA C\u002FC++. But the only difference is that TorchInductor will generate Triton code which is compiled into low level PTX code.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_102":{"__typename":"Paragraph","id":"ba9e2e578391_102","name":"c6e4","type":"P","href":null,"layout":null,"metadata":null,"text":"For multi-core CPU targets, TorchInductor generates C++ code and injects OpenMP pragma directives to generate parallel kernels. From the PyTorch user level world view, this is the IR transformation flow:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*bHIRpgT9w4hOQR9v":{"__typename":"ImageMetadata","id":"0*bHIRpgT9w4hOQR9v","originalHeight":735,"originalWidth":1203,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_103":{"__typename":"Paragraph","id":"ba9e2e578391_103","name":"8eea","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*bHIRpgT9w4hOQR9v"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_104":{"__typename":"Paragraph","id":"ba9e2e578391_104","name":"14d0","type":"P","href":null,"layout":null,"metadata":null,"text":"Of course this being the high-level view, I’m omitting some details here and I encourage you to read the TorchInductor forum post and OpenAI’s triton blog post for triton.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":105,"end":129,"href":"https:\u002F\u002Fdev-discuss.pytorch.org\u002Ft\u002Ftorchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes\u002F747","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":134,"end":170,"href":"https:\u002F\u002Fopenai.com\u002Fresearch\u002Ftriton","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_105":{"__typename":"Paragraph","id":"ba9e2e578391_105","name":"0a67","type":"P","href":null,"layout":null,"metadata":null,"text":"We’ll now throw away our fake compiler which we used in our previous section, and use the full PyTorch compiler stack that uses TorchInductor.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:b3cbdaacee841338849d9dafb98a67f6":{"__typename":"MediaResource","id":"b3cbdaacee841338849d9dafb98a67f6","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"Paragraph:ba9e2e578391_106":{"__typename":"Paragraph","id":"ba9e2e578391_106","name":"643f","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:b3cbdaacee841338849d9dafb98a67f6"}},"mixtapeMetadata":null},"Paragraph:ba9e2e578391_107":{"__typename":"Paragraph","id":"ba9e2e578391_107","name":"b046","type":"P","href":null,"layout":null,"metadata":null,"text":"Notice that I’ve passed optional argument that enables two debug features:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_108":{"__typename":"Paragraph","id":"ba9e2e578391_108","name":"896b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"trace.enabled: Generates intermediate code to inspect code generated by TorchInductor","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_109":{"__typename":"Paragraph","id":"ba9e2e578391_109","name":"dbb3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"trace.graph_enabled: Generates the optimized computational graph visualization after operator fusion","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_110":{"__typename":"Paragraph","id":"ba9e2e578391_110","name":"65da","type":"P","href":null,"layout":null,"metadata":null,"text":"For our simple example TorchInductor is able to fuse all intermediate operations in our function into a single custom operator, and you can see below how that simplifies the forward and backward computational graphs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*zVp2otO0g7QKlasj":{"__typename":"ImageMetadata","id":"0*zVp2otO0g7QKlasj","originalHeight":734,"originalWidth":1245,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_111":{"__typename":"Paragraph","id":"ba9e2e578391_111","name":"66f4","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*zVp2otO0g7QKlasj"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_112":{"__typename":"Paragraph","id":"ba9e2e578391_112","name":"0797","type":"P","href":null,"layout":null,"metadata":null,"text":"You must surely be wondering what this fused operator looks like in code. The code for the fused operator is automatically generated by TorchInductor and it’s in C++ or Triton based on the target device — CPU or GPU. You don’t need to explicitly specify to TorchInductor which device to target, it can infer it from the data and model device type.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_113":{"__typename":"Paragraph","id":"ba9e2e578391_113","name":"8d3c","type":"P","href":null,"layout":null,"metadata":null,"text":"To view the generated code, you have to enable debugging using trace.enabled=True and this creates a director called torch_compile_debug with debug information.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_114":{"__typename":"Paragraph","id":"ba9e2e578391_114","name":"5c20","type":"P","href":null,"layout":null,"metadata":null,"text":"The full path to forward and backward graph code are:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_115":{"__typename":"Paragraph","id":"ba9e2e578391_115","name":"64eb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"torch_compile_debug\u002Frun_\u003CDATE_TIME_PID\u003E\u002Faot_torchinductor\u002Fmodel__XX_forward_XX\u002Foutput_code.py","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":93,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_116":{"__typename":"Paragraph","id":"ba9e2e578391_116","name":"4eea","type":"ULI","href":null,"layout":null,"metadata":null,"text":"torch_compile_debug\u002Frun_\u003CDATE_TIME_PID\u003E\u002Faot_torchinductor\u002Fmodel__XX_backward_XX\u002Foutput_code.py","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":94,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_117":{"__typename":"Paragraph","id":"ba9e2e578391_117","name":"eea8","type":"P","href":null,"layout":null,"metadata":null,"text":"If you set device = ‘cuda’ (assuming your computer has a GPU device) then the generated code in the forward folder is in Open AI Triton","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*eEvqQIeejh-cl8CK":{"__typename":"ImageMetadata","id":"0*eEvqQIeejh-cl8CK","originalHeight":1052,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_118":{"__typename":"Paragraph","id":"ba9e2e578391_118","name":"5428","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*eEvqQIeejh-cl8CK"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_119":{"__typename":"Paragraph","id":"ba9e2e578391_119","name":"bf5e","type":"P","href":null,"layout":null,"metadata":null,"text":"If you set device = ‘CPU’ then the generated code is in C++ with OpenMP pragmas","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*fx4AsAhd8760yyXb":{"__typename":"ImageMetadata","id":"0*fx4AsAhd8760yyXb","originalHeight":815,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_120":{"__typename":"Paragraph","id":"ba9e2e578391_120","name":"3bbe","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*fx4AsAhd8760yyXb"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_121":{"__typename":"Paragraph","id":"ba9e2e578391_121","name":"60cf","type":"H3","href":null,"layout":null,"metadata":null,"text":"Recap","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_122":{"__typename":"Paragraph","id":"ba9e2e578391_122","name":"9eb4","type":"P","href":null,"layout":null,"metadata":null,"text":"Deep learning compilers are complex with intricate inner workings that rival a swiss watch. In this blog post, I hope I provided you with a gentle and easy to follow primer on this topic and how these technologies power PyTorch 2.0.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*17doYgsRQQThdi6a":{"__typename":"ImageMetadata","id":"0*17doYgsRQQThdi6a","originalHeight":589,"originalWidth":1036,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:ba9e2e578391_123":{"__typename":"Paragraph","id":"ba9e2e578391_123","name":"08b8","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*17doYgsRQQThdi6a"},"text":"screenshot by author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_124":{"__typename":"Paragraph","id":"ba9e2e578391_124","name":"f2c3","type":"OLI","href":null,"layout":null,"metadata":null,"text":"I started with a simple PyTorch function","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_125":{"__typename":"Paragraph","id":"ba9e2e578391_125","name":"757f","type":"OLI","href":null,"layout":null,"metadata":null,"text":"I showed how TorchDynamo captures the graph and represents it in FX IR","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_126":{"__typename":"Paragraph","id":"ba9e2e578391_126","name":"536f","type":"OLI","href":null,"layout":null,"metadata":null,"text":"I showed how AOTAutograd generates the backward pass graph, lowers PyTorch operators into Aten operators and represents it in an FX graph container.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_127":{"__typename":"Paragraph","id":"ba9e2e578391_127","name":"43af","type":"OLI","href":null,"layout":null,"metadata":null,"text":"I discussed how Aten operators can be further decomposed into Core Aten IR and Prims IR that reduces the number of operators that other compilers can support without supporting the full PyTorch API list.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_128":{"__typename":"Paragraph","id":"ba9e2e578391_128","name":"646a","type":"OLI","href":null,"layout":null,"metadata":null,"text":"I showed how TorchInductor performs operator fusion and generates optimized code for CPU and GPU targets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_129":{"__typename":"Paragraph","id":"ba9e2e578391_129","name":"c8f7","type":"P","href":null,"layout":null,"metadata":null,"text":"If you followed along you should be able to provide a high-level response to the following questions:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_130":{"__typename":"Paragraph","id":"ba9e2e578391_130","name":"5f5b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"What is a deep learning compiler?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_131":{"__typename":"Paragraph","id":"ba9e2e578391_131","name":"2bbd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"What does a PyTorch 2.0 compiler do when you call torch.compile()?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_132":{"__typename":"Paragraph","id":"ba9e2e578391_132","name":"25f4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Why do we need a forward and backward pass graph ahead of time?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_133":{"__typename":"Paragraph","id":"ba9e2e578391_133","name":"c4df","type":"ULI","href":null,"layout":null,"metadata":null,"text":"What are the different intermediate representations (IR) in PyTorch","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_134":{"__typename":"Paragraph","id":"ba9e2e578391_134","name":"2e91","type":"ULI","href":null,"layout":null,"metadata":null,"text":"What is the difference between ATen IR, Core ATen IR, Prims IR?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_135":{"__typename":"Paragraph","id":"ba9e2e578391_135","name":"443d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"What is operator fusion and why is it important?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_136":{"__typename":"Paragraph","id":"ba9e2e578391_136","name":"aca2","type":"H3","href":null,"layout":null,"metadata":null,"text":"Thank you for reading all the way to the end!","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:ba9e2e578391_137":{"__typename":"Paragraph","id":"ba9e2e578391_137","name":"607f","type":"P","href":null,"layout":null,"metadata":null,"text":"If you found this article interesting, consider following me on medium to be notified when I publish new articles. Please also check out my other blog posts on medium or follow me on twitter (@shshnkp), LinkedIn or leave a comment below. Want me to write on a specific topic I’d love to hear from you!","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":160,"end":166,"href":"https:\u002F\u002Fmedium.com\u002F@shashankprasanna","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":192,"end":200,"href":"https:\u002F\u002Ftwitter.com\u002Fshshnkp","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":203,"end":211,"href":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fshashankprasanna\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_ef872433409d":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_ef872433409d","isEditor":false},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"__typename":"ImageMetadata","id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","originalWidth":337,"originalHeight":122},"Tag:pytorch":{"__typename":"Tag","id":"pytorch","displayTitle":"Pytorch","normalizedTagSlug":"pytorch"},"Tag:deep-learning":{"__typename":"Tag","id":"deep-learning","displayTitle":"Deep Learning","normalizedTagSlug":"deep-learning"},"Tag:machine-learning":{"__typename":"Tag","id":"machine-learning","displayTitle":"Machine Learning","normalizedTagSlug":"machine-learning"},"Tag:gpu":{"__typename":"Tag","id":"gpu","displayTitle":"Gpu","normalizedTagSlug":"gpu"},"Tag:deep-dives":{"__typename":"Tag","id":"deep-dives","displayTitle":"Deep Dives","normalizedTagSlug":"deep-dives"},"Post:35132a85bd26":{"__typename":"Post","id":"35132a85bd26","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{\"forceTruncation\":false}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"99c2","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:ba9e2e578391_0"},{"__ref":"Paragraph:ba9e2e578391_1"},{"__ref":"Paragraph:ba9e2e578391_2"},{"__ref":"Paragraph:ba9e2e578391_3"},{"__ref":"Paragraph:ba9e2e578391_4"},{"__ref":"Paragraph:ba9e2e578391_5"},{"__ref":"Paragraph:ba9e2e578391_6"},{"__ref":"Paragraph:ba9e2e578391_7"},{"__ref":"Paragraph:ba9e2e578391_8"},{"__ref":"Paragraph:ba9e2e578391_9"},{"__ref":"Paragraph:ba9e2e578391_10"},{"__ref":"Paragraph:ba9e2e578391_11"},{"__ref":"Paragraph:ba9e2e578391_12"},{"__ref":"Paragraph:ba9e2e578391_13"},{"__ref":"Paragraph:ba9e2e578391_14"},{"__ref":"Paragraph:ba9e2e578391_15"},{"__ref":"Paragraph:ba9e2e578391_16"},{"__ref":"Paragraph:ba9e2e578391_17"},{"__ref":"Paragraph:ba9e2e578391_18"},{"__ref":"Paragraph:ba9e2e578391_19"},{"__ref":"Paragraph:ba9e2e578391_20"},{"__ref":"Paragraph:ba9e2e578391_21"},{"__ref":"Paragraph:ba9e2e578391_22"},{"__ref":"Paragraph:ba9e2e578391_23"},{"__ref":"Paragraph:ba9e2e578391_24"},{"__ref":"Paragraph:ba9e2e578391_25"},{"__ref":"Paragraph:ba9e2e578391_26"},{"__ref":"Paragraph:ba9e2e578391_27"},{"__ref":"Paragraph:ba9e2e578391_28"},{"__ref":"Paragraph:ba9e2e578391_29"},{"__ref":"Paragraph:ba9e2e578391_30"},{"__ref":"Paragraph:ba9e2e578391_31"},{"__ref":"Paragraph:ba9e2e578391_32"},{"__ref":"Paragraph:ba9e2e578391_33"},{"__ref":"Paragraph:ba9e2e578391_34"},{"__ref":"Paragraph:ba9e2e578391_35"},{"__ref":"Paragraph:ba9e2e578391_36"},{"__ref":"Paragraph:ba9e2e578391_37"},{"__ref":"Paragraph:ba9e2e578391_38"},{"__ref":"Paragraph:ba9e2e578391_39"},{"__ref":"Paragraph:ba9e2e578391_40"},{"__ref":"Paragraph:ba9e2e578391_41"},{"__ref":"Paragraph:ba9e2e578391_42"},{"__ref":"Paragraph:ba9e2e578391_43"},{"__ref":"Paragraph:ba9e2e578391_44"},{"__ref":"Paragraph:ba9e2e578391_45"},{"__ref":"Paragraph:ba9e2e578391_46"},{"__ref":"Paragraph:ba9e2e578391_47"},{"__ref":"Paragraph:ba9e2e578391_48"},{"__ref":"Paragraph:ba9e2e578391_49"},{"__ref":"Paragraph:ba9e2e578391_50"},{"__ref":"Paragraph:ba9e2e578391_51"},{"__ref":"Paragraph:ba9e2e578391_52"},{"__ref":"Paragraph:ba9e2e578391_53"},{"__ref":"Paragraph:ba9e2e578391_54"},{"__ref":"Paragraph:ba9e2e578391_55"},{"__ref":"Paragraph:ba9e2e578391_56"},{"__ref":"Paragraph:ba9e2e578391_57"},{"__ref":"Paragraph:ba9e2e578391_58"},{"__ref":"Paragraph:ba9e2e578391_59"},{"__ref":"Paragraph:ba9e2e578391_60"},{"__ref":"Paragraph:ba9e2e578391_61"},{"__ref":"Paragraph:ba9e2e578391_62"},{"__ref":"Paragraph:ba9e2e578391_63"},{"__ref":"Paragraph:ba9e2e578391_64"},{"__ref":"Paragraph:ba9e2e578391_65"},{"__ref":"Paragraph:ba9e2e578391_66"},{"__ref":"Paragraph:ba9e2e578391_67"},{"__ref":"Paragraph:ba9e2e578391_68"},{"__ref":"Paragraph:ba9e2e578391_69"},{"__ref":"Paragraph:ba9e2e578391_70"},{"__ref":"Paragraph:ba9e2e578391_71"},{"__ref":"Paragraph:ba9e2e578391_72"},{"__ref":"Paragraph:ba9e2e578391_73"},{"__ref":"Paragraph:ba9e2e578391_74"},{"__ref":"Paragraph:ba9e2e578391_75"},{"__ref":"Paragraph:ba9e2e578391_76"},{"__ref":"Paragraph:ba9e2e578391_77"},{"__ref":"Paragraph:ba9e2e578391_78"},{"__ref":"Paragraph:ba9e2e578391_79"},{"__ref":"Paragraph:ba9e2e578391_80"},{"__ref":"Paragraph:ba9e2e578391_81"},{"__ref":"Paragraph:ba9e2e578391_82"},{"__ref":"Paragraph:ba9e2e578391_83"},{"__ref":"Paragraph:ba9e2e578391_84"},{"__ref":"Paragraph:ba9e2e578391_85"},{"__ref":"Paragraph:ba9e2e578391_86"},{"__ref":"Paragraph:ba9e2e578391_87"},{"__ref":"Paragraph:ba9e2e578391_88"},{"__ref":"Paragraph:ba9e2e578391_89"},{"__ref":"Paragraph:ba9e2e578391_90"},{"__ref":"Paragraph:ba9e2e578391_91"},{"__ref":"Paragraph:ba9e2e578391_92"},{"__ref":"Paragraph:ba9e2e578391_93"},{"__ref":"Paragraph:ba9e2e578391_94"},{"__ref":"Paragraph:ba9e2e578391_95"},{"__ref":"Paragraph:ba9e2e578391_96"},{"__ref":"Paragraph:ba9e2e578391_97"},{"__ref":"Paragraph:ba9e2e578391_98"},{"__ref":"Paragraph:ba9e2e578391_99"},{"__ref":"Paragraph:ba9e2e578391_100"},{"__ref":"Paragraph:ba9e2e578391_101"},{"__ref":"Paragraph:ba9e2e578391_102"},{"__ref":"Paragraph:ba9e2e578391_103"},{"__ref":"Paragraph:ba9e2e578391_104"},{"__ref":"Paragraph:ba9e2e578391_105"},{"__ref":"Paragraph:ba9e2e578391_106"},{"__ref":"Paragraph:ba9e2e578391_107"},{"__ref":"Paragraph:ba9e2e578391_108"},{"__ref":"Paragraph:ba9e2e578391_109"},{"__ref":"Paragraph:ba9e2e578391_110"},{"__ref":"Paragraph:ba9e2e578391_111"},{"__ref":"Paragraph:ba9e2e578391_112"},{"__ref":"Paragraph:ba9e2e578391_113"},{"__ref":"Paragraph:ba9e2e578391_114"},{"__ref":"Paragraph:ba9e2e578391_115"},{"__ref":"Paragraph:ba9e2e578391_116"},{"__ref":"Paragraph:ba9e2e578391_117"},{"__ref":"Paragraph:ba9e2e578391_118"},{"__ref":"Paragraph:ba9e2e578391_119"},{"__ref":"Paragraph:ba9e2e578391_120"},{"__ref":"Paragraph:ba9e2e578391_121"},{"__ref":"Paragraph:ba9e2e578391_122"},{"__ref":"Paragraph:ba9e2e578391_123"},{"__ref":"Paragraph:ba9e2e578391_124"},{"__ref":"Paragraph:ba9e2e578391_125"},{"__ref":"Paragraph:ba9e2e578391_126"},{"__ref":"Paragraph:ba9e2e578391_127"},{"__ref":"Paragraph:ba9e2e578391_128"},{"__ref":"Paragraph:ba9e2e578391_129"},{"__ref":"Paragraph:ba9e2e578391_130"},{"__ref":"Paragraph:ba9e2e578391_131"},{"__ref":"Paragraph:ba9e2e578391_132"},{"__ref":"Paragraph:ba9e2e578391_133"},{"__ref":"Paragraph:ba9e2e578391_134"},{"__ref":"Paragraph:ba9e2e578391_135"},{"__ref":"Paragraph:ba9e2e578391_136"},{"__ref":"Paragraph:ba9e2e578391_137"}]},"validatedShareKey":""},"creator":{"__ref":"User:e0c596ca35b5"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26","primaryTopic":{"__ref":"Topic:1eca0103fff3"},"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"software-engineering"},{"__typename":"Topic","slug":"programming"}],"isPublished":true,"latestPublishedVersion":"ba9e2e578391","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":3},"createdAt":1681904792472,"firstPublishedAt":1682012124245,"latestPublishedAt":1682012124245,"clapCount":348,"allowResponses":true,"isLimitedState":false,"title":"How Pytorch 2.0 accelerates deep learning with operator fusion and CPU\u002FGPU code-generation","isSeries":false,"sequence":null,"uniqueSlug":"how-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":16.296226415094342,"previewContent":{"__typename":"PreviewContent","subtitle":"A primer on deep learning compiler technologies in PyTorch for graph capture, intermediate representations, operator fusion, and more"},"previewImage":{"__ref":"ImageMetadata:1*m3hHjaqAY_Rqwcvgfg4IoQ.png"},"isShortform":false,"seoTitle":"","updatedAt":1682148380877,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","curationStatus":"CURATION_STATUS_DISTRIBUTED","isIndexable":true,"isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:pytorch"},{"__ref":"Tag:deep-learning"},{"__ref":"Tag:machine-learning"},{"__ref":"Tag:gpu"},{"__ref":"Tag:deep-dives"}],"pendingCollection":null,"statusForCollection":"APPROVED","layerCake":1,"detectedLanguage":"en","wordCount":3762},"ImageMetadata:1*qAx5CnFbebRR_bOyQbSGYw.png":{"__typename":"ImageMetadata","id":"1*qAx5CnFbebRR_bOyQbSGYw.png","focusPercentX":49,"focusPercentY":48,"alt":null},"Post:d69c157d8c86":{"__typename":"Post","id":"d69c157d8c86","title":"Choosing the right GPU for deep learning on AWS","previewImage":{"__ref":"ImageMetadata:1*qAx5CnFbebRR_bOyQbSGYw.png"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"How to choose the right Amazon EC2 GPU instance for deep learning training and inference — from best performance to the most…","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fchoosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86","isPublished":true,"creator":{"__ref":"User:e0c596ca35b5"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":1124,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":12},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1682961650132,"firstPublishedAt":1595684992723,"readingTime":24.65188679245283,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86"},"ImageMetadata:1*rsp22rKwFDjiwwCcUly56Q.jpeg":{"__typename":"ImageMetadata","id":"1*rsp22rKwFDjiwwCcUly56Q.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:f7dc0c0eae92":{"__typename":"User","id":"f7dc0c0eae92","name":"Jacob Marks, Ph.D.","username":"jacob_marks","mediumMemberAt":0,"socialStats":{"__typename":"SocialStats","followerCount":1432},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"ML @ Voxel51 | Stanford Theoretical Physics PhD https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fjacob-marks","imageId":"0*YukZswf8UB1bQdTV"},"Post:4f2d34bd8736":{"__typename":"Post","id":"4f2d34bd8736","title":"How I Turned My Company’s Docs into a Searchable Database with OpenAI","previewImage":{"__ref":"ImageMetadata:1*rsp22rKwFDjiwwCcUly56Q.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"And how you can do the same with your docs","isFullContent":false},"visibility":"PUBLIC","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736","isPublished":true,"creator":{"__ref":"User:f7dc0c0eae92"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":4091,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":50},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1682620803812,"firstPublishedAt":1682406666156,"readingTime":14.189622641509434,"isLocked":false,"sequence":null,"isSeries":false,"uniqueSlug":"how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736"},"ImageMetadata:1*ARD8irFbRaBKRNlrFcL6HA.png":{"__typename":"ImageMetadata","id":"1*ARD8irFbRaBKRNlrFcL6HA.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:84a02493194a":{"__typename":"User","id":"84a02493194a","name":"Khuyen Tran","username":"khuyentran1476","mediumMemberAt":1573916133000,"socialStats":{"__typename":"SocialStats","followerCount":38163},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"khuyentran1476.medium.com"}},"hasSubdomain":true,"bio":"MLOps Engineer. Website: https:\u002F\u002Fmathdatasimplified.com","imageId":"2*tiQVZEZxHMPcnVmEmN7UtA.jpeg"},"Post:479ac8ffc76f":{"__typename":"Post","id":"479ac8ffc76f","title":"Stop Hard Coding in a Data Science Project — Use Config Files Instead","previewImage":{"__ref":"ImageMetadata:1*ARD8irFbRaBKRNlrFcL6HA.png"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"And How to Efficiently Interact with Config Files in Python","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fstop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f","isPublished":true,"creator":{"__ref":"User:84a02493194a"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":1577,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":19},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1685549035713,"firstPublishedAt":1685065444611,"readingTime":5.453773584905661,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"stop-hard-coding-in-a-data-science-project-use-config-files-instead-479ac8ffc76f"},"ImageMetadata:1*AGpm_2l-32AfXUAfOxwUKA.png":{"__typename":"ImageMetadata","id":"1*AGpm_2l-32AfXUAfOxwUKA.png","focusPercentX":null,"focusPercentY":null,"alt":null},"Post:7a5d6804ef1c":{"__typename":"Post","id":"7a5d6804ef1c","title":"A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon…","previewImage":{"__ref":"ImageMetadata:1*AGpm_2l-32AfXUAfOxwUKA.png"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Learn about CPUs, GPUs, AWS Inferentia, and Amazon Elastic Inference and how to choose the right AI accelerator for inference deployment","isFullContent":false},"visibility":"PUBLIC","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fa-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c","isPublished":true,"creator":{"__ref":"User:e0c596ca35b5"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":512,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":4},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1603498630064,"firstPublishedAt":1603287313193,"readingTime":25.662264150943393,"isLocked":false,"sequence":null,"isSeries":false,"uniqueSlug":"a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c"},"ImageMetadata:1*sP1YmfjnIc5zd5P00rWp-Q@2x.jpeg":{"__typename":"ImageMetadata","id":"1*sP1YmfjnIc5zd5P00rWp-Q@2x.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:3a38da70d8dc":{"__typename":"User","id":"3a38da70d8dc","name":"Leonie Monigatti","username":"iamleonie","mediumMemberAt":1635398706000,"socialStats":{"__typename":"SocialStats","followerCount":3752},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"Professional software dev & data science hobbyist. Follow for practical data science guides - whether you're a data scientist or not. linkedin.com\u002Fin\u002F804250ab","imageId":"1*TTIl4oynrJyfIkLbC6fumA.png"},"Post:970b7ab4cf9e":{"__typename":"Post","id":"970b7ab4cf9e","title":"10 Exciting Project Ideas Using Large Language Models (LLMs) for Your Portfolio","previewImage":{"__ref":"ImageMetadata:1*sP1YmfjnIc5zd5P00rWp-Q@2x.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Learn how to build apps and showcase your skills with large language models (LLMs). Get started today!","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002F10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e","isPublished":true,"creator":{"__ref":"User:3a38da70d8dc"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":1442,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":9},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1684161878645,"firstPublishedAt":1684161878645,"readingTime":10.032075471698114,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"10-exciting-project-ideas-using-large-language-models-llms-for-your-portfolio-970b7ab4cf9e"},"ImageMetadata:1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg":{"__typename":"ImageMetadata","id":"1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg","focusPercentX":null,"focusPercentY":null,"alt":"Two stochastic parrots sitting on a chain of large language models: LangChain"},"Post:95fc8898732c":{"__typename":"Post","id":"95fc8898732c","title":"Getting Started with LangChain: A Beginner’s Guide to Building LLM-Powered Applications","previewImage":{"__ref":"ImageMetadata:1*4C54ZxHRM1dOlAvlvoEJZg@2x.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"A LangChain tutorial to build anything with large language models in Python","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fgetting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c","isPublished":true,"creator":{"__ref":"User:3a38da70d8dc"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":2933,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":19},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1682431758625,"firstPublishedAt":1682431758625,"readingTime":11.031446540880502,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"getting-started-with-langchain-a-beginners-guide-to-building-llm-powered-applications-95fc8898732c"},"ImageMetadata:0*EMTJI76mLg61oPbv":{"__typename":"ImageMetadata","id":"0*EMTJI76mLg61oPbv","focusPercentX":null,"focusPercentY":null,"alt":null},"User:a34b6e5225b0":{"__typename":"User","id":"a34b6e5225b0","name":"Gabe Araujo, M.Sc.","username":"araujogabe1","mediumMemberAt":1678718057000,"socialStats":{"__typename":"SocialStats","followerCount":2834},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":true},"customDomainState":null,"hasSubdomain":false,"bio":"👑 5X Top Writer | 💰 Free E-Book https:\u002F\u002Fcodeeliteintprep.gumroad.com\u002F |🤝 Support my writing by Joining Medium: https:\u002F\u002Fmedium.com\u002F@araujogabe1\u002Fmembership","imageId":"1*OhLD6lqReaxOTPITf_3wcg@2x.jpeg"},"Collection:5517fd7b58a6":{"__typename":"Collection","id":"5517fd7b58a6","slug":"gitconnected","name":"Level Up Coding","domain":"levelup.gitconnected.com","description":"Coding tutorials and news. The developer homepage gitconnected.com && skilled.dev && levelup.dev","subscriberCount":89485,"avatar":{"__ref":"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"}},"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg":{"__typename":"ImageMetadata","id":"1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"},"Post:568a971af014":{"__typename":"Post","id":"568a971af014","title":"🐼Introducing PandasAI: The Generative AI Python Library 🐼","previewImage":{"__ref":"ImageMetadata:0*EMTJI76mLg61oPbv"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Pandas AI is an additional Python library that enhances Pandas, the widely-used data analysis and manipulation tool, by incorporating…","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Flevelup.gitconnected.com\u002Fintroducing-pandasai-the-generative-ai-python-library-568a971af014","isPublished":true,"creator":{"__ref":"User:a34b6e5225b0"},"collection":{"__ref":"Collection:5517fd7b58a6"},"clapCount":1265,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":13},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1687357267974,"firstPublishedAt":1684266619178,"readingTime":8.761320754716982,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"introducing-pandasai-the-generative-ai-python-library-568a971af014"},"ImageMetadata:0*4ABoFdJClLr8QTK2":{"__typename":"ImageMetadata","id":"0*4ABoFdJClLr8QTK2","focusPercentX":null,"focusPercentY":null,"alt":null},"User:bf7d13fc53db":{"__typename":"User","id":"bf7d13fc53db","name":"Matt Chapman","username":"mattchapmanmsc","mediumMemberAt":1681163683000,"socialStats":{"__typename":"SocialStats","followerCount":2851},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"Data Scientist based in Oxford, UK. I write about DS, AI and try (& sometimes succeed) to give careers advice. Support me: medium.com\u002F@mattchapmanmsc\u002Fmembership","imageId":"1*4EQrg_kfWhQfHyGeuIunfg.png"},"Post:1e535dd0cd79":{"__typename":"Post","id":"1e535dd0cd79","title":"How I Stay Up to Date With the Latest AI Trends as a Full-Time Data Scientist","previewImage":{"__ref":"ImageMetadata:0*4ABoFdJClLr8QTK2"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"No, I don’t just ask ChatGPT to tell me","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79","isPublished":true,"creator":{"__ref":"User:bf7d13fc53db"},"collection":{"__ref":"Collection:7f60cf5620c9"},"clapCount":1947,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":25},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1682957864648,"firstPublishedAt":1682957864648,"readingTime":7.111635220125787,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"how-i-stay-up-to-date-with-the-latest-ai-trends-as-a-full-time-data-scientist-1e535dd0cd79"},"ImageMetadata:0*sEYcttGKXNKEWR3e":{"__typename":"ImageMetadata","id":"0*sEYcttGKXNKEWR3e","focusPercentX":null,"focusPercentY":null,"alt":null},"User:859af34925b7":{"__typename":"User","id":"859af34925b7","name":"Youssef Hosni","username":"youssefraafat57","mediumMemberAt":0,"socialStats":{"__typename":"SocialStats","followerCount":14148},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"youssefraafat57.medium.com"}},"hasSubdomain":true,"bio":"Computer Vision Researcher & Data Scientist | I Write to Understand | Looking for data science mentoring, let's chat: https:\u002F\u002Ftopmate.io\u002Fyoussef_hosni","imageId":"1*cBxasbWXomjJrHV2_Fh8zw.jpeg"},"Collection:98111c9905da":{"__typename":"Collection","id":"98111c9905da","slug":"towards-artificial-intelligence","name":"Towards AI","domain":"pub.towardsai.net","description":"The leading AI community and content platform focused on making AI accessible to all","subscriberCount":30917,"avatar":{"__ref":"ImageMetadata:1*JyIThO-cLjlChQLb6kSlVQ.png"}},"ImageMetadata:1*JyIThO-cLjlChQLb6kSlVQ.png":{"__typename":"ImageMetadata","id":"1*JyIThO-cLjlChQLb6kSlVQ.png"},"Post:9c2df7906516":{"__typename":"Post","id":"9c2df7906516","title":"How to Read Machine Learning Papers Effectively","previewImage":{"__ref":"ImageMetadata:0*sEYcttGKXNKEWR3e"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"The field of machine and deep learning is evolving very fast, and there are new research outputs every day. Therefore you will need to read…","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Fpub.towardsai.net\u002Fhow-to-read-machine-learning-papers-effectively-9c2df7906516","isPublished":true,"creator":{"__ref":"User:859af34925b7"},"collection":{"__ref":"Collection:98111c9905da"},"clapCount":863,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":7},"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1675142916829,"firstPublishedAt":1665345708767,"readingTime":9.535220125786164,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"how-to-read-machine-learning-papers-effectively-9c2df7906516"},"ImageMetadata:1*p-VVVzppuy-B87U8FfcHTA@2x.jpeg":{"__typename":"ImageMetadata","id":"1*p-VVVzppuy-B87U8FfcHTA@2x.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"Post:4253820922":{"__typename":"Post","id":"4253820922","title":"Understanding LLMOps: Large Language Model Operations","previewImage":{"__ref":"ImageMetadata:1*p-VVVzppuy-B87U8FfcHTA@2x.jpeg"},"extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"How LLMs are changing the way we build AI-powered products and the landscape of MLOps","isFullContent":false},"visibility":"LOCKED","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@iamleonie\u002Funderstanding-llmops-large-language-model-operations-4253820922","isPublished":true,"creator":{"__ref":"User:3a38da70d8dc"},"collection":null,"clapCount":644,"allowResponses":true,"isLimitedState":false,"postResponses":{"__typename":"PostResponses","count":6},"pendingCollection":null,"statusForCollection":null,"pinnedAt":0,"latestPublishedAt":1683025331281,"firstPublishedAt":1683025331281,"readingTime":11.410691823899372,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"understanding-llmops-large-language-model-operations-4253820922"},"User:65e22f4ac01c":{"__typename":"User","username":"ben.putney","id":"65e22f4ac01c"},"CatalogViewerEdge:catalogId:e3668ea008e1-viewerId:lo_ef872433409d":{"__typename":"CatalogViewerEdge","followersCount":10,"id":"catalogId:e3668ea008e1-viewerId:lo_ef872433409d"},"ImageMetadata:0*zsngbTOmFCy6sUCx.jpeg":{"__typename":"ImageMetadata","id":"0*zsngbTOmFCy6sUCx.jpeg","alt":null},"Post:e377af0ffdaa":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*zsngbTOmFCy6sUCx.jpeg"},"id":"e377af0ffdaa"},"CatalogItemV2:{\"catalogItemId\":\"63d0199b5330ca62c672fa8e\"}":{"__typename":"CatalogItemV2","catalogItemId":"63d0199b5330ca62c672fa8e","entity":{"__ref":"Post:e377af0ffdaa"}},"ImageMetadata:1*EPYpvWdUxGbCkbgwLUAarg.png":{"__typename":"ImageMetadata","id":"1*EPYpvWdUxGbCkbgwLUAarg.png","alt":null},"Post:5f40d55184c4":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*EPYpvWdUxGbCkbgwLUAarg.png"},"id":"5f40d55184c4"},"CatalogItemV2:{\"catalogItemId\":\"63d0182884e5c1fa7c270bcb\"}":{"__typename":"CatalogItemV2","catalogItemId":"63d0182884e5c1fa7c270bcb","entity":{"__ref":"Post:5f40d55184c4"}},"ImageMetadata:0*4JkYIO0SWzjCCATB.jpg":{"__typename":"ImageMetadata","id":"0*4JkYIO0SWzjCCATB.jpg","alt":null},"Post:a432aa037ee1":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*4JkYIO0SWzjCCATB.jpg"},"id":"a432aa037ee1"},"CatalogItemV2:{\"catalogItemId\":\"63d0162d64907a64cb199dff\"}":{"__typename":"CatalogItemV2","catalogItemId":"63d0162d64907a64cb199dff","entity":{"__ref":"Post:a432aa037ee1"}},"ImageMetadata:1*kTxFxHrvDH35Hyd3ifDMpQ.png":{"__typename":"ImageMetadata","id":"1*kTxFxHrvDH35Hyd3ifDMpQ.png","alt":null},"Post:397a65b74051":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*kTxFxHrvDH35Hyd3ifDMpQ.png"},"id":"397a65b74051"},"CatalogItemV2:{\"catalogItemId\":\"63d013a064907a64cb199d9b\"}":{"__typename":"CatalogItemV2","catalogItemId":"63d013a064907a64cb199d9b","entity":{"__ref":"Post:397a65b74051"}},"ImageMetadata:1*Y9N6_GjWYI9eIfrpqZ24GA.png":{"__typename":"ImageMetadata","id":"1*Y9N6_GjWYI9eIfrpqZ24GA.png","alt":null},"Post:2c67f2a52788":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*Y9N6_GjWYI9eIfrpqZ24GA.png"},"id":"2c67f2a52788"},"CatalogItemV2:{\"catalogItemId\":\"63d00c0264907a64cb199cfc\"}":{"__typename":"CatalogItemV2","catalogItemId":"63d00c0264907a64cb199cfc","entity":{"__ref":"Post:2c67f2a52788"}},"Catalog:e3668ea008e1":{"__typename":"Catalog","id":"e3668ea008e1","name":"Predictive Modeling w\u002F Python","postItemsCount":18,"predefined":null,"creator":{"__ref":"User:65e22f4ac01c"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:e3668ea008e1-viewerId:lo_ef872433409d"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"63d0199b5330ca62c672fa8e\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"63d0182884e5c1fa7c270bcb\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"63d0162d64907a64cb199dff\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"63d013a064907a64cb199d9b\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"63d00c0264907a64cb199cfc\"}"}]}},"User:fa1913854e95":{"__typename":"User","username":"destingong","id":"fa1913854e95"},"CatalogViewerEdge:catalogId:a877c2a39884-viewerId:lo_ef872433409d":{"__typename":"CatalogViewerEdge","followersCount":22,"id":"catalogId:a877c2a39884-viewerId:lo_ef872433409d"},"ImageMetadata:1*swd_PY6vTCyPnsgBYoFZfA.png":{"__typename":"ImageMetadata","id":"1*swd_PY6vTCyPnsgBYoFZfA.png","alt":"Principal Component Analysis for ML"},"Post:cc9b345b75be":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*swd_PY6vTCyPnsgBYoFZfA.png"},"id":"cc9b345b75be"},"CatalogItemV2:{\"catalogItemId\":\"63d605ee074d62a19d55a5c6\"}":{"__typename":"CatalogItemV2","catalogItemId":"63d605ee074d62a19d55a5c6","entity":{"__ref":"Post:cc9b345b75be"}},"ImageMetadata:1*8sSAHftNwd_RNJ3k4VA0pA.png":{"__typename":"ImageMetadata","id":"1*8sSAHftNwd_RNJ3k4VA0pA.png","alt":"Time Series Analysis"},"Post:eea5cbf43c73":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*8sSAHftNwd_RNJ3k4VA0pA.png"},"id":"eea5cbf43c73"},"CatalogItemV2:{\"catalogItemId\":\"63a63a59ff47a8eae4844f6e\"}":{"__typename":"CatalogItemV2","catalogItemId":"63a63a59ff47a8eae4844f6e","entity":{"__ref":"Post:eea5cbf43c73"}},"ImageMetadata:1*uNyD4yNMH-DnOel1wzxOOA.png":{"__typename":"ImageMetadata","id":"1*uNyD4yNMH-DnOel1wzxOOA.png","alt":"deep learning cheatsheet for beginner"},"Post:3b976d0ee084":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*uNyD4yNMH-DnOel1wzxOOA.png"},"id":"3b976d0ee084"},"CatalogItemV2:{\"catalogItemId\":\"62acf84915e600098fe2ff8a\"}":{"__typename":"CatalogItemV2","catalogItemId":"62acf84915e600098fe2ff8a","entity":{"__ref":"Post:3b976d0ee084"}},"ImageMetadata:1*0V_GsMAi2zN0OcNi7hm-vw.png":{"__typename":"ImageMetadata","id":"1*0V_GsMAi2zN0OcNi7hm-vw.png","alt":null},"Post:c67258a2c0ac":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*0V_GsMAi2zN0OcNi7hm-vw.png"},"id":"c67258a2c0ac"},"CatalogItemV2:{\"catalogItemId\":\"62395f6adf59488c243c8439\"}":{"__typename":"CatalogItemV2","catalogItemId":"62395f6adf59488c243c8439","entity":{"__ref":"Post:c67258a2c0ac"}},"ImageMetadata:1*R6Rbcks-pGO0SkhCINrP0g.png":{"__typename":"ImageMetadata","id":"1*R6Rbcks-pGO0SkhCINrP0g.png","alt":"machine learning algorithms"},"Post:2197870ff501":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*R6Rbcks-pGO0SkhCINrP0g.png"},"id":"2197870ff501"},"CatalogItemV2:{\"catalogItemId\":\"6215d886744a1f187cd32093\"}":{"__typename":"CatalogItemV2","catalogItemId":"6215d886744a1f187cd32093","entity":{"__ref":"Post:2197870ff501"}},"Catalog:a877c2a39884":{"__typename":"Catalog","id":"a877c2a39884","name":"Practical Guides to Machine Learning","postItemsCount":10,"predefined":null,"creator":{"__ref":"User:fa1913854e95"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:a877c2a39884-viewerId:lo_ef872433409d"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"63d605ee074d62a19d55a5c6\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"63a63a59ff47a8eae4844f6e\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"62acf84915e600098fe2ff8a\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"62395f6adf59488c243c8439\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6215d886744a1f187cd32093\"}"}]}},"User:2eb23a991a63":{"__typename":"User","username":"AMGAS14","id":"2eb23a991a63"},"CatalogViewerEdge:catalogId:0a856388a93a-viewerId:lo_ef872433409d":{"__typename":"CatalogViewerEdge","followersCount":7,"id":"catalogId:0a856388a93a-viewerId:lo_ef872433409d"},"ImageMetadata:1*jc4oIBokwfseuI-pmRIPPQ.png":{"__typename":"ImageMetadata","id":"1*jc4oIBokwfseuI-pmRIPPQ.png","alt":null},"Post:dc9feb60ecc4":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*jc4oIBokwfseuI-pmRIPPQ.png"},"id":"dc9feb60ecc4"},"CatalogItemV2:{\"catalogItemId\":\"6492da2a8370022dd9b58ea7\"}":{"__typename":"CatalogItemV2","catalogItemId":"6492da2a8370022dd9b58ea7","entity":{"__ref":"Post:dc9feb60ecc4"}},"ImageMetadata:1*EDndx6q1g7C_doMhMAcOCg.png":{"__typename":"ImageMetadata","id":"1*EDndx6q1g7C_doMhMAcOCg.png","alt":null},"Post:1288ef3c4929":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*EDndx6q1g7C_doMhMAcOCg.png"},"id":"1288ef3c4929"},"CatalogItemV2:{\"catalogItemId\":\"6492d6036cd506d81665167f\"}":{"__typename":"CatalogItemV2","catalogItemId":"6492d6036cd506d81665167f","entity":{"__ref":"Post:1288ef3c4929"}},"ImageMetadata:1*45J3OgIxjgMHUv892eYFvQ.png":{"__typename":"ImageMetadata","id":"1*45J3OgIxjgMHUv892eYFvQ.png","alt":null},"Post:f3841119e357":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*45J3OgIxjgMHUv892eYFvQ.png"},"id":"f3841119e357"},"CatalogItemV2:{\"catalogItemId\":\"6492d5b43450302633afc411\"}":{"__typename":"CatalogItemV2","catalogItemId":"6492d5b43450302633afc411","entity":{"__ref":"Post:f3841119e357"}},"ImageMetadata:0*aHmqK4GcDurHC0GG.gif":{"__typename":"ImageMetadata","id":"0*aHmqK4GcDurHC0GG.gif","alt":"Image taken from GitHub LLM repository: https:\u002F\u002Fgithub.com\u002FHannibal046\u002FAwesome-LLM"},"Post:b922097c9acd":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*aHmqK4GcDurHC0GG.gif"},"id":"b922097c9acd"},"CatalogItemV2:{\"catalogItemId\":\"6492d309fad93f6d233cb800\"}":{"__typename":"CatalogItemV2","catalogItemId":"6492d309fad93f6d233cb800","entity":{"__ref":"Post:b922097c9acd"}},"ImageMetadata:1*-Lh9dASZepSTvUPys8ABCg.png":{"__typename":"ImageMetadata","id":"1*-Lh9dASZepSTvUPys8ABCg.png","alt":null},"Post:a4dc59b373d4":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*-Lh9dASZepSTvUPys8ABCg.png"},"id":"a4dc59b373d4"},"CatalogItemV2:{\"catalogItemId\":\"649176f661bdc3b698ce1d82\"}":{"__typename":"CatalogItemV2","catalogItemId":"649176f661bdc3b698ce1d82","entity":{"__ref":"Post:a4dc59b373d4"}},"Catalog:0a856388a93a":{"__typename":"Catalog","id":"0a856388a93a","name":"Natural Language Processing","postItemsCount":345,"predefined":null,"creator":{"__ref":"User:2eb23a991a63"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:0a856388a93a-viewerId:lo_ef872433409d"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6492da2a8370022dd9b58ea7\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6492d6036cd506d81665167f\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6492d5b43450302633afc411\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6492d309fad93f6d233cb800\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"649176f661bdc3b698ce1d82\"}"}]}},"User:a32c340ea342":{"__typename":"User","username":"MediumStaff","id":"a32c340ea342"},"CatalogViewerEdge:catalogId:5969c7449b7f-viewerId:lo_ef872433409d":{"__typename":"CatalogViewerEdge","followersCount":22,"id":"catalogId:5969c7449b7f-viewerId:lo_ef872433409d"},"ImageMetadata:0*3OsUtsnlTx9Svm4c.jpg":{"__typename":"ImageMetadata","id":"0*3OsUtsnlTx9Svm4c.jpg","alt":"Image by vectorjuice on FreePik"},"Post:23a2173eecae":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*3OsUtsnlTx9Svm4c.jpg"},"id":"23a2173eecae"},"CatalogItemV2:{\"catalogItemId\":\"6482363e212e6c41a481d903\"}":{"__typename":"CatalogItemV2","catalogItemId":"6482363e212e6c41a481d903","entity":{"__ref":"Post:23a2173eecae"}},"ImageMetadata:1*IPZF1hcDWwpPqOz2vL7NxQ.png":{"__typename":"ImageMetadata","id":"1*IPZF1hcDWwpPqOz2vL7NxQ.png","alt":null},"Post:3bc2644d4507":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*IPZF1hcDWwpPqOz2vL7NxQ.png"},"id":"3bc2644d4507"},"CatalogItemV2:{\"catalogItemId\":\"641cac35672446f81159a840\"}":{"__typename":"CatalogItemV2","catalogItemId":"641cac35672446f81159a840","entity":{"__ref":"Post:3bc2644d4507"}},"ImageMetadata:1*0fHUKyg3xtpNWpop35PR4g.png":{"__typename":"ImageMetadata","id":"1*0fHUKyg3xtpNWpop35PR4g.png","alt":null},"Post:59c16ae76e3e":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*0fHUKyg3xtpNWpop35PR4g.png"},"id":"59c16ae76e3e"},"CatalogItemV2:{\"catalogItemId\":\"6422e78d7bc8cca169b3ce68\"}":{"__typename":"CatalogItemV2","catalogItemId":"6422e78d7bc8cca169b3ce68","entity":{"__ref":"Post:59c16ae76e3e"}},"ImageMetadata:1*FS8L4XLW_3mHDyRKNwjKvA.jpeg":{"__typename":"ImageMetadata","id":"1*FS8L4XLW_3mHDyRKNwjKvA.jpeg","alt":null},"Post:2bf00851551e":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*FS8L4XLW_3mHDyRKNwjKvA.jpeg"},"id":"2bf00851551e"},"CatalogItemV2:{\"catalogItemId\":\"6421a9dc3b730f2980719d64\"}":{"__typename":"CatalogItemV2","catalogItemId":"6421a9dc3b730f2980719d64","entity":{"__ref":"Post:2bf00851551e"}},"ImageMetadata:1*OhWzHPkxXbslpwYyCZ2HKA.png":{"__typename":"ImageMetadata","id":"1*OhWzHPkxXbslpwYyCZ2HKA.png","alt":null},"Post:1ce5fca96286":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*OhWzHPkxXbslpwYyCZ2HKA.png"},"id":"1ce5fca96286"},"CatalogItemV2:{\"catalogItemId\":\"641cac41b70e26f89f868177\"}":{"__typename":"CatalogItemV2","catalogItemId":"641cac41b70e26f89f868177","entity":{"__ref":"Post:1ce5fca96286"}},"Catalog:5969c7449b7f":{"__typename":"Catalog","id":"5969c7449b7f","name":"The New Chatbots: ChatGPT, Bard, and Beyond","postItemsCount":13,"predefined":null,"creator":{"__ref":"User:a32c340ea342"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:5969c7449b7f-viewerId:lo_ef872433409d"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6482363e212e6c41a481d903\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"641cac35672446f81159a840\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6422e78d7bc8cca169b3ce68\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6421a9dc3b730f2980719d64\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"641cac41b70e26f89f868177\"}"}]}}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.5f7f097d.js"></script><script src="https://cdn-client.medium.com/lite/static/js/965.29850e6c.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.876a5fe9.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.c71f0248.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.bbdcaa9d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6068.97073e64.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/799.361fd2fb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6009.ba54f1f2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5144.5af60acf.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2905.d9e40b36.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8695.30866c8d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9683.5d196d22.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3154.030f8ff6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5203.07da4f7e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1957.c6467b3a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9599.e514d6da.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1711.95897de3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7855.96c3f468.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5510.02d75113.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9174.8fc1edff.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4129.578ca1ed.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9225.9cfbe85d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8580.1dc03c85.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6804.e7c3c5af.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1802.33a279a3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4078.9fb8a750.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9408.3fccb642.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1743.6e6d929f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8883.1cf2e6d4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5563.b8bbd146.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5649.2506f253.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9150.d1ab820d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5005.4ccc91b2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2031.deba5bab.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7129.d81553d9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.5d0c29e1.chunk.js"></script><script>window.main();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v52afc6f149f6479b8c77fa569edb01181681764108816" integrity="sha512-jGCTpDpBAYDGNYR5ztKt4BQPGef1P0giN6ZGVUi835kFF88FOmmn8jBQWNgrNd8g/Yu421NdgWhwQoaOPFflDw==" data-cf-beacon='{"rayId":"7daf60b04b829695","version":"2023.4.0","b":1,"token":"0b5f665943484354a59c39c6833f7078","si":100}' crossorigin="anonymous"></script>
</body></html>